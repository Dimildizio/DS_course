{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/dvZwNiEoHkObl0USmtM8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimildizio/DS_course/blob/main/Neural_networks/Agents/pydantic_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSsF4jJv_OM7"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install 'pydantic-ai-slim[openai]'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Basic model connector\n"
      ],
      "metadata": {
        "id": "gsd-lJXxFq8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and env variables\n",
        "\n",
        "First we import libs and create env variable for `OpenAIChatModel` to be able to get `OPENROUTER_API_KEY` from env variables"
      ],
      "metadata": {
        "id": "V0skyl4KJQIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "from pydantic import BaseModel\n",
        "from pydantic_ai import Agent, RunContext\n",
        "from pydantic_ai.models.openai import OpenAIChatModel\n",
        "from pydantic_ai.providers.openrouter import OpenRouterProvider\n",
        "\n",
        "\n",
        "OPENROUTER_API_KEY = userdata.get('openrouter')\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = OPENROUTER_API_KEY"
      ],
      "metadata": {
        "id": "ok0WrhoM_gy6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initiating model and agent\n"
      ],
      "metadata": {
        "id": "csrqrPYKGcuk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create an agent output scheme"
      ],
      "metadata": {
        "id": "VVCre3yXGWmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Result(BaseModel):\n",
        "    answer: str\n",
        "    confidence: float"
      ],
      "metadata": {
        "id": "vlU2QgxF_pv4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Write system prompt\n",
        "\n",
        "> create model\n",
        "\n",
        "> create agent"
      ],
      "metadata": {
        "id": "gS4CEynmJXpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sys_prompt = \"You're a study assistant agent. Your answer should be brief and structured. Avoid emoji and slang.\"\n",
        "\n",
        "model = OpenAIChatModel(\"deepseek/deepseek-chat-v3.1:free\",\n",
        "                        provider=OpenRouterProvider())\n",
        "\n",
        "\n",
        "agent = Agent[None, Result](model=model,\n",
        "                            system_prompt=sys_prompt)"
      ],
      "metadata": {
        "id": "iAxFdvZw_dD6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling `agent.run` and memory\n",
        "\n",
        "Simple async run function with an agent decorator. In Pydantic AI the context \"lives\" while the `agent.run` is being executed (unlike usual LLM request `model.complete` or `model.generate` when it doesn't have access to it's own history/tool use), however between requests there is no memory.\n",
        "\n",
        "The agent has access to `ctx.deps` - like ram and `ctx.memory_history` - all prompts to the model in current run, after `agent.run` return result the session is closed and the memory is erased."
      ],
      "metadata": {
        "id": "HgQCXYu3Go1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@agent.run\n",
        "async def run(ctx: RunContext[None], question: str) -> Result:\n",
        "    draft = await ctx.llm.complete(question)\n",
        "    return Result(answer=draft.data, confidence=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXEYA24WAIMp",
        "outputId": "18a77285-053d-498e-e39e-fa091a8c4d70"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1231992350.py:2: RuntimeWarning: coroutine 'AbstractAgent.run' was never awaited\n",
            "  async def run(ctx: RunContext[None], question: str) -> Result:\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try it"
      ],
      "metadata": {
        "id": "jslYkqdfGtwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = await agent.run(\"Привет, кто ты?\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NVCKX_vAn-l",
        "outputId": "64b849ae-47c5-4d77-ac9b-977793b9ab39"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AgentRunResult(output='Я — ваш помощник-ассистент, предназначенный для ответов на вопросы и помощи в учёбе. Чем могу помочь?')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: add tools"
      ],
      "metadata": {
        "id": "Yl_5HvUvGveq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More imports"
      ],
      "metadata": {
        "id": "zEJS9pwyJcgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Any, Optional, List\n",
        "from pydantic import Field\n",
        "import ast, operator as op"
      ],
      "metadata": {
        "id": "iZERBMTWG20-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create schema for dependencies - data accessible to the Agent during agent.run\n",
        "We create pydantic model so it would follow typisation, and get validated\n",
        "When `agent.run` is executed `Deps` gets instantiated and is accessible via `ctx.deps`\n",
        "\n",
        "> `scratch` - is just a field for the agent to dump info to: numbers, dates, notes, any important data\n",
        "> `tool_call` - logging of all tool calls: tool, args, results.\n",
        "\n",
        "*Class attributes above could be any other names*"
      ],
      "metadata": {
        "id": "szaEso2KJgiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Deps(BaseModel):\n",
        "    scratch: Dict[str, Any] = Field(default_factory=dict)\n",
        "    tool_calls: List[Dict[str, Any]] = Field(default_factory=list)"
      ],
      "metadata": {
        "id": "bkj6ah0OHDIt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a new system prompt and agent"
      ],
      "metadata": {
        "id": "AvB5esvtG9sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sys_prompt = \"\"\"You are a calculation agent.\n",
        "- Always use the provided tools (calculator, unit converter, evaluator) to verify answers.\n",
        "- First, generate a draft answer for the user’s question.\n",
        "- Then compare the draft to the tool’s result.\n",
        "- If they match, return the draft as final.\n",
        "- If they differ, correct the answer using the tool result and explain briefly.\n",
        "Keep answers short and precise.\"\"\"\n",
        "\n",
        "\n",
        "agent = Agent[Deps, Result](model=model,\n",
        "                            system_prompt=sys_prompt)"
      ],
      "metadata": {
        "id": "1fxUrtT9OIP0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool 1: calculator"
      ],
      "metadata": {
        "id": "HOgEN4jdPWdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CalcInput(BaseModel):\n",
        "    expression: str\n",
        "\n",
        "class CalcOutput(BaseModel):\n",
        "    value: float"
      ],
      "metadata": {
        "id": "AU98IjsFTRsT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ALLOWED_OPS = {\n",
        "    ast.Add: op.add, ast.Sub: op.sub, ast.Mult: op.mul,\n",
        "    ast.Div: op.truediv, ast.Pow: op.pow, ast.Mod: op.mod,\n",
        "    ast.USub: op.neg, ast.UAdd: op.pos,\n",
        "}\n",
        "\n",
        "def _safe_eval(node):\n",
        "    if isinstance(node, ast.Num):  # py<=3.7\n",
        "        return node.n\n",
        "    if isinstance(node, ast.Constant):  # py 3.8+\n",
        "        if isinstance(node.value, (int, float)):\n",
        "            return node.value\n",
        "        raise ValueError(\"constants other than numbers are not allowed\")\n",
        "    if isinstance(node, ast.UnaryOp) and type(node.op) in _ALLOWED_OPS:\n",
        "        return _ALLOWED_OPS[type(node.op)](_safe_eval(node.operand))\n",
        "    if isinstance(node, ast.BinOp) and type(node.op) in _ALLOWED_OPS:\n",
        "        return _ALLOWED_OPS[type(node.op)](_safe_eval(node.left), _safe_eval(node.right))\n",
        "    if isinstance(node, ast.Expr):\n",
        "        return _safe_eval(node.value)\n",
        "    raise ValueError(\"unsupported expression\")\n"
      ],
      "metadata": {
        "id": "RCLDI1o1QCMh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@agent.tool\n",
        "def calc_expr(ctx: RunContext[Deps], data: CalcInput) -> CalcOutput:\n",
        "    # + - * / ** %\n",
        "    tree = ast.parse(data.expression, mode=\"eval\")\n",
        "    val = float(_safe_eval(tree.body))\n",
        "    ctx.deps.tool_calls.append({\"tool\": \"calc_expr\", \"expr\": data.expression, \"value\": val})\n",
        "    return CalcOutput(value=val)"
      ],
      "metadata": {
        "id": "FUkr9q30QDu_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}