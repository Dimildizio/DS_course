{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSLYm0v8iMnmybFr1SAzxa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimildizio/DS_course/blob/main/Neural_networks/Autoencoders/AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autoencoders"
      ],
      "metadata": {
        "id": "11X1gxcFPMS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoencoders are used for unsupervised learning. The primary goal is to learn efficient representations of data, typically by compressing the input into a lower-dimensional latent space and then reconstructing the input from that representation."
      ],
      "metadata": {
        "id": "VnOifM6WPb6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autoencoder components"
      ],
      "metadata": {
        "id": "qpHE8yy9PmZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder"
      ],
      "metadata": {
        "id": "wda-BNpePqcI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoders compress the input to a lower dimensional representation (latent space). Consists of several or more layers that reduce diemnsions."
      ],
      "metadata": {
        "id": "qPf4e3CxP0I5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Latent space"
      ],
      "metadata": {
        "id": "QLXdMaVLPsYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lower-dim representation of inputs. Basically - condensed information."
      ],
      "metadata": {
        "id": "AkbZY_DQQHy9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decoder"
      ],
      "metadata": {
        "id": "xsxtKz63PupS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reconstructs the data form latent space, mirrors encoder structure in reverse."
      ],
      "metadata": {
        "id": "nWRFyy-hQIcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 [10 points]"
      ],
      "metadata": {
        "id": "euxGOLXGPwHJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preparation [1 point]"
      ],
      "metadata": {
        "id": "yMCjFsldQs4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports"
      ],
      "metadata": {
        "id": "XdOByMyNQ8W9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ld9zU0U9PJHn"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import skimage.io\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "from google.colab import userdata, files\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets\n",
        "from typing import Callable, Dict, List, Tuple\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set config"
      ],
      "metadata": {
        "id": "HZijm5VZQOSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "  SEED = 42"
      ],
      "metadata": {
        "id": "Ovw6ufwhQRoj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Freeze seeds"
      ],
      "metadata": {
        "id": "KTzPmI-KRRKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed: int=CFG.seed) -> None:\n",
        "  np.random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  #torch.backends.cudnn.benchmark = True\n",
        "\n",
        "  def seed_wrapper(func: Callable) -> Callable:\n",
        "    \"\"\"\n",
        "    A wrapper function for repeatability and reproducibility.\n",
        "\n",
        "    Args:\n",
        "        func (Callable): The function to be wrapped.\n",
        "\n",
        "    Returns:\n",
        "        Callable: The wrapped function.\n",
        "    \"\"\"\n",
        "    def wrapped_function(*args, **kwargs):\n",
        "        seed_everything()\n",
        "        result = func(*args, **kwargs)\n",
        "        return result\n",
        "    return wrapped_function"
      ],
      "metadata": {
        "id": "72nsw3QGQWYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set WandB"
      ],
      "metadata": {
        "id": "UfscuI01RUb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_wandb()\n",
        "  try:\n",
        "    CFG.wandbapi = userdata.get('wandb')\n",
        "    project=\"Semantic_segmentation_dermoscopic\"\n",
        "    entity='dimildizio'\n",
        "    wandb.login(key=CFG.wandbapi)\n",
        "\n",
        "  except Exception as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "8QBKC_3rRWk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wandb_wrapper(func: Callable) -> Callable:\n",
        "    \"\"\"\n",
        "    A wrapper function for integrating with Weights & Biases (wandb).\n",
        "\n",
        "    Args:\n",
        "        func (Callable): The function to be wrapped.\n",
        "\n",
        "    Returns:\n",
        "        Callable: The wrapped function.\n",
        "    \"\"\"\n",
        "    def wrapped_function(*args, **kwargs):\n",
        "        print('wrapper works')\n",
        "        if CFG.wandbapi:\n",
        "            wandb.init(project=project, entity=entity, config=wandb_config())\n",
        "            print('Logging wandb')\n",
        "        try:\n",
        "          result = func(*args, **kwargs)\n",
        "        except Exception as e:\n",
        "          if CFG.wandbapi:\n",
        "            wandb.log({\"error_message\": str(e)}, commit=False)\n",
        "            wandb.finish()\n",
        "          raise e\n",
        "        finally:\n",
        "          if CFG.wandbapi:\n",
        "            wandb.finish()\n",
        "        return result\n",
        "    return wrapped_function"
      ],
      "metadata": {
        "id": "SdsYzsvnRjsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download data"
      ],
      "metadata": {
        "id": "z22Rk6uDQ_FJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_dataset(attrs_name = \"lfw_attributes.txt\",\n",
        "                      images_name = \"lfw-deepfunneled\",\n",
        "                      dx=80,dy=80,\n",
        "                      dimx=64,dimy=64\n",
        "    ):\n",
        "\n",
        "    #download if not exists\n",
        "    if not os.path.exists(images_name):\n",
        "        print(\"images not found, donwloading...\")\n",
        "        os.system(\"wget http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz -O tmp.tgz\")\n",
        "        print(\"extracting...\")\n",
        "        os.system(\"tar xvzf tmp.tgz && rm tmp.tgz\")\n",
        "        print(\"done\")\n",
        "        assert os.path.exists(images_name)\n",
        "\n",
        "    if not os.path.exists(attrs_name):\n",
        "        print(\"attributes not found, downloading...\")\n",
        "        os.system(\"wget http://www.cs.columbia.edu/CAVE/databases/pubfig/download/%s\" % attrs_name)\n",
        "        print(\"done\")\n",
        "\n",
        "    #read attrs\n",
        "    df_attrs = pd.read_csv(\"lfw_attributes.txt\",sep='\\t',skiprows=1,)\n",
        "    df_attrs = pd.DataFrame(df_attrs.iloc[:,:-1].values, columns = df_attrs.columns[1:])\n",
        "\n",
        "\n",
        "    #read photos\n",
        "    photo_ids = []\n",
        "    for dirpath, dirnames, filenames in os.walk(images_name):\n",
        "        for fname in filenames:\n",
        "            if fname.endswith(\".jpg\"):\n",
        "                fpath = os.path.join(dirpath,fname)\n",
        "                photo_id = fname[:-4].replace('_',' ').split()\n",
        "                person_id = ' '.join(photo_id[:-1])\n",
        "                photo_number = int(photo_id[-1])\n",
        "                photo_ids.append({'person':person_id,'imagenum':photo_number,'photo_path':fpath})\n",
        "\n",
        "    photo_ids = pd.DataFrame(photo_ids)\n",
        "    # print(photo_ids)\n",
        "    #mass-merge\n",
        "    #(photos now have same order as attributes)\n",
        "    df = pd.merge(df_attrs,photo_ids,on=('person','imagenum'))\n",
        "\n",
        "    assert len(df)==len(df_attrs),\"lost some data when merging dataframes\"\n",
        "\n",
        "    # print(df.shape)\n",
        "    #image preprocessing\n",
        "    all_photos =df['photo_path'].apply(skimage.io.imread)\\\n",
        "                                .apply(lambda img:img[dy:-dy,dx:-dx])\\\n",
        "                                .apply(lambda img: resize(img,[dimx,dimy]))\n",
        "\n",
        "    all_photos = np.stack(all_photos.values)#.astype('uint8')\n",
        "    all_attrs = df.drop([\"photo_path\",\"person\",\"imagenum\"],axis=1)\n",
        "\n",
        "    return all_photos, all_attrs"
      ],
      "metadata": {
        "id": "nxWQqh6ARDWg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, attrs = fetch_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOiQZ6x9RGIw",
        "outputId": "c2b102dd-e516-405c-b6bd-fb19dcc66a95"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images not found, donwloading...\n",
            "extracting...\n",
            "done\n",
            "attributes not found, downloading...\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "zt2EtRJYPugx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QcTFQ3uKRvtv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}