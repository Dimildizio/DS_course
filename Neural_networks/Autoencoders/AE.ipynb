{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSte3ISi7SibwsLR/2PaDZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimildizio/DS_course/blob/main/Neural_networks/Autoencoders/AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autoencoders"
      ],
      "metadata": {
        "id": "11X1gxcFPMS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoencoders are used for unsupervised learning. The primary goal is to learn efficient representations of data, typically by compressing the input into a lower-dimensional latent space and then reconstructing the input from that representation."
      ],
      "metadata": {
        "id": "VnOifM6WPb6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autoencoder components"
      ],
      "metadata": {
        "id": "qpHE8yy9PmZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder"
      ],
      "metadata": {
        "id": "wda-BNpePqcI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoders compress the input to a lower dimensional representation (latent space). Consists of several or more layers that reduce diemnsions."
      ],
      "metadata": {
        "id": "qPf4e3CxP0I5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Latent space"
      ],
      "metadata": {
        "id": "QLXdMaVLPsYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lower-dim representation of inputs. Basically - condensed information."
      ],
      "metadata": {
        "id": "AkbZY_DQQHy9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decoder"
      ],
      "metadata": {
        "id": "xsxtKz63PupS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reconstructs the data form latent space, mirrors encoder structure in reverse."
      ],
      "metadata": {
        "id": "nWRFyy-hQIcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 [10 points]"
      ],
      "metadata": {
        "id": "euxGOLXGPwHJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preparation [1 point]"
      ],
      "metadata": {
        "id": "yMCjFsldQs4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports"
      ],
      "metadata": {
        "id": "XdOByMyNQ8W9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ld9zU0U9PJHn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data_utils\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import skimage.io\n",
        "from skimage.transform import resize\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download data"
      ],
      "metadata": {
        "id": "z22Rk6uDQ_FJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_dataset(attrs_name = \"lfw_attributes.txt\",\n",
        "                      images_name = \"lfw-deepfunneled\",\n",
        "                      dx=80,dy=80,\n",
        "                      dimx=64,dimy=64\n",
        "    ):\n",
        "\n",
        "    #download if not exists\n",
        "    if not os.path.exists(images_name):\n",
        "        print(\"images not found, donwloading...\")\n",
        "        os.system(\"wget http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz -O tmp.tgz\")\n",
        "        print(\"extracting...\")\n",
        "        os.system(\"tar xvzf tmp.tgz && rm tmp.tgz\")\n",
        "        print(\"done\")\n",
        "        assert os.path.exists(images_name)\n",
        "\n",
        "    if not os.path.exists(attrs_name):\n",
        "        print(\"attributes not found, downloading...\")\n",
        "        os.system(\"wget http://www.cs.columbia.edu/CAVE/databases/pubfig/download/%s\" % attrs_name)\n",
        "        print(\"done\")\n",
        "\n",
        "    #read attrs\n",
        "    df_attrs = pd.read_csv(\"lfw_attributes.txt\",sep='\\t',skiprows=1,)\n",
        "    df_attrs = pd.DataFrame(df_attrs.iloc[:,:-1].values, columns = df_attrs.columns[1:])\n",
        "\n",
        "\n",
        "    #read photos\n",
        "    photo_ids = []\n",
        "    for dirpath, dirnames, filenames in os.walk(images_name):\n",
        "        for fname in filenames:\n",
        "            if fname.endswith(\".jpg\"):\n",
        "                fpath = os.path.join(dirpath,fname)\n",
        "                photo_id = fname[:-4].replace('_',' ').split()\n",
        "                person_id = ' '.join(photo_id[:-1])\n",
        "                photo_number = int(photo_id[-1])\n",
        "                photo_ids.append({'person':person_id,'imagenum':photo_number,'photo_path':fpath})\n",
        "\n",
        "    photo_ids = pd.DataFrame(photo_ids)\n",
        "    # print(photo_ids)\n",
        "    #mass-merge\n",
        "    #(photos now have same order as attributes)\n",
        "    df = pd.merge(df_attrs,photo_ids,on=('person','imagenum'))\n",
        "\n",
        "    assert len(df)==len(df_attrs),\"lost some data when merging dataframes\"\n",
        "\n",
        "    # print(df.shape)\n",
        "    #image preprocessing\n",
        "    all_photos =df['photo_path'].apply(skimage.io.imread)\\\n",
        "                                .apply(lambda img:img[dy:-dy,dx:-dx])\\\n",
        "                                .apply(lambda img: resize(img,[dimx,dimy]))\n",
        "\n",
        "    all_photos = np.stack(all_photos.values)#.astype('uint8')\n",
        "    all_attrs = df.drop([\"photo_path\",\"person\",\"imagenum\"],axis=1)\n",
        "\n",
        "    return all_photos, all_attrs"
      ],
      "metadata": {
        "id": "nxWQqh6ARDWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, attrs = fetch_dataset()"
      ],
      "metadata": {
        "id": "gOiQZ6x9RGIw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}