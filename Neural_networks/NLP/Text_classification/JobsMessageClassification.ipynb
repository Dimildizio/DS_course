{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimildizio/DS_course/blob/main/Neural_networks/NLP/Text_classification/JobsMessageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libs"
      ],
      "metadata": {
        "id": "wlZOb4Dl-Dhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install emoji --upgrade\n",
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alxSWiApUsUd",
        "outputId": "28092f86-026f-429f-ea99-b658db182253"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "iF4iz0A48-vN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "import re\n",
        "import emoji\n",
        "import string\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from pymystem3 import Mystem"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrXVzNn0UzEC",
        "outputId": "7a71310a-4d1b-4805-9750-851d867035d2"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Freeze seeds"
      ],
      "metadata": {
        "id": "Adr7nZLtTrH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "SeqZPHCETtge"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the dataset"
      ],
      "metadata": {
        "id": "5Bc_Iah-_hm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = pd.read_excel('msg_type.xlsx')"
      ],
      "metadata": {
        "id": "GcSsofsF-dMV"
      },
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "orbCX_lh-Wj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = TweetTokenizer()"
      ],
      "metadata": {
        "id": "PCpZOGIf-Wy0"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming"
      ],
      "metadata": {
        "id": "Qz286hbW-pdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = SnowballStemmer(\"russian\")"
      ],
      "metadata": {
        "id": "Eau245xn_Q4N"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmaization"
      ],
      "metadata": {
        "id": "gQ-tCd_W_r8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mystem = Mystem()"
      ],
      "metadata": {
        "id": "rAdp3V8i_tpg"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorize using TFIDF"
      ],
      "metadata": {
        "id": "dXTCd6Lb_3DU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords.words('russian'))"
      ],
      "metadata": {
        "id": "9bS02FX5_5F0"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split dataset to parameters and encode target labels"
      ],
      "metadata": {
        "id": "nyQPCc1bC7Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = text_data.copy()\n",
        "df['category'] = df['category'].replace({'ads': 'message', 'project': 'vacancy'})"
      ],
      "metadata": {
        "id": "9VEDUqDtC-jq"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['category']"
      ],
      "metadata": {
        "id": "Y6hVYWNpv979",
        "outputId": "c6a1dcfa-44ab-4d0b-cf11-4aba8f4e9799",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      message\n",
              "1      message\n",
              "2      message\n",
              "3      message\n",
              "4      message\n",
              "        ...   \n",
              "475    vacancy\n",
              "476    vacancy\n",
              "477    vacancy\n",
              "478    vacancy\n",
              "479    vacancy\n",
              "Name: category, Length: 480, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Label encode categories"
      ],
      "metadata": {
        "id": "PdmxZUdeVnlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "encoded_target = label_encoder.fit_transform(df['category'])"
      ],
      "metadata": {
        "id": "hzhggYegVrIY"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split into params and target values"
      ],
      "metadata": {
        "id": "wRqIDsNJV4Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text']\n",
        "y = encoded_target"
      ],
      "metadata": {
        "id": "e0-QiBASVlxW"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform transformation on df"
      ],
      "metadata": {
        "id": "egQ65yKOCyux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emoji(text: str) -> str:\n",
        "    return emoji.replace_emoji(text, \" \")\n",
        "\n",
        "\n",
        "def remove_links(text: str) -> str:\n",
        "    return re.sub(r\"http\\S+\", \" \", text, flags=re.MULTILINE)\n",
        "\n",
        "\n",
        "def remove_usernames_and_emails(text: str) -> str:\n",
        "    \"\"\"–£–¥–∞–ª–µ—è–µ—Ç —é–∑–µ—Ä–Ω–µ–π–º—ã –∏ email\"\"\"\n",
        "    return re.sub(r\"\\S*@\\S*\", \" \", text, flags=re.MULTILINE)\n",
        "\n",
        "\n",
        "def remove_punctuation(text: str) -> str:\n",
        "    \"\"\"–£–¥–∞–ª—è–µ–º —Å–∏–º–≤–æ–ª—ã –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏\"\"\"\n",
        "    return \"\".join([ch if ch not in string.punctuation else \" \" for ch in text])\n",
        "\n",
        "\n",
        "def remove_numbers(text: str) -> str:\n",
        "    \"\"\"–£–¥–∞–ª—è–µ–º —á–∏—Å–ª–∞\"\"\"\n",
        "    return \"\".join([i if not i.isdigit() else \" \" for i in text])\n",
        "\n",
        "\n",
        "def remove_multiple_spaces(text: str) -> str:\n",
        "    \"\"\"–£–¥–∞–ª—è–µ–º –¥–≤–æ–π–Ω—ã–µ (–∏ –±–æ–ª–µ–µ) –ø—Ä–æ–±–µ–ª—ã\"\"\"\n",
        "    return re.sub(r\"\\s+\", \" \", text, flags=re.I)"
      ],
      "metadata": {
        "id": "kvAuLGg2DeLL"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prep_text(text: str) -> str:\n",
        "  return remove_multiple_spaces(\n",
        "      remove_numbers(\n",
        "          remove_punctuation(\n",
        "              remove_usernames_and_emails(\n",
        "                  remove_links(\n",
        "                      remove_emoji(text)\n",
        "                      )\n",
        "                  )\n",
        "              )\n",
        "          )\n",
        "      )"
      ],
      "metadata": {
        "id": "Ze1Dd5irEFH8"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#our new dataset with stemmed lemmatized and later vectorized texts\n",
        "stemmed_lemma_txts = []\n",
        "\n",
        "for text in X:\n",
        "  tok = tokenizer.tokenize(get_prep_text(text).lower())\n",
        "  stem_tok = [stemmer.stem(token) for token in tok]\n",
        "  # lem_tok = [lem for lem in mystem.lemmatize(\" \".join(stem_tok)) if not lem.isspace()]\n",
        "  # stemmed_lemma_txts.append(' '.join(lem_tok))\n",
        "  stemmed_lemma_txts.append(' '.join(stem_tok))\n",
        "\n",
        "df['text_lemm'] = stemmed_lemma_txts"
      ],
      "metadata": {
        "id": "_AoklUd1CyQu"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TFIDF Vectorize"
      ],
      "metadata": {
        "id": "ao8AJx7yD188"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfd = tfidf_vectorizer.fit_transform(stemmed_lemma_txts)"
      ],
      "metadata": {
        "id": "TPetowxrD0BS"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split dataset"
      ],
      "metadata": {
        "id": "EPEBSiRxAGHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pass tfidf'd and transfromed data instead of texts as X"
      ],
      "metadata": {
        "id": "pS8tzS8AVK66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tfidfd, y, stratify=y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "3FHZ9SUyAHx-"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "7HX96oveEee1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and train baseline model"
      ],
      "metadata": {
        "id": "ZshtoMLyAgcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(C=0.004)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "JzH_z-mPADkt",
        "outputId": "c63e2194-7063-4c03-e63a-4cf02d5f40ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.004)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.004)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.004)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict"
      ],
      "metadata": {
        "id": "Sy2G_blXEcE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "-gapxEVgAfrY"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate"
      ],
      "metadata": {
        "id": "n1Dd5275EjjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy"
      ],
      "metadata": {
        "id": "bS6NmFkhEvw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy:', acc)"
      ],
      "metadata": {
        "id": "UGsDgjo8El3O",
        "outputId": "fc33aaac-250b-4fd2-c975-c3fe6711d00d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Report"
      ],
      "metadata": {
        "id": "bC_2nOceExNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "G3_u5H3RE2ne",
        "outputId": "30a203da-a65c-45c2-fa61-abe7cf402a6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93        60\n",
            "           1       0.95      0.92      0.93        60\n",
            "\n",
            "    accuracy                           0.93       120\n",
            "   macro avg       0.93      0.93      0.93       120\n",
            "weighted avg       0.93      0.93      0.93       120\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sum it up"
      ],
      "metadata": {
        "id": "QJXTDgm66jBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Catboost"
      ],
      "metadata": {
        "id": "l75Q3u20xSLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_model = CatBoostClassifier(iterations=400, depth=6, learning_rate=0.04, loss_function='MultiClass', verbose=False)\n",
        "cat_model.fit(X_train, y_train, eval_set=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRD3V3L5puaX",
        "outputId": "29b1c93a-01cc-4db8-de05-f14b3ecf425c"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7bb432277c70>"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = cat_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_pred, y_test)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "class_names = ['0','1']\n",
        "report = classification_report(y_test, y_pred, target_names=class_names)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB79wrrDsBmo",
        "outputId": "e1d25b57-4598-4dfd-d66c-095cf87978f3"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.94\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94        60\n",
            "           1       0.96      0.92      0.94        60\n",
            "\n",
            "    accuracy                           0.94       120\n",
            "   macro avg       0.94      0.94      0.94       120\n",
            "weighted avg       0.94      0.94      0.94       120\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model):\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  print('Accuracy:', acc)\n",
        "  print(\"Classification Report:\")\n",
        "  print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "Y_7ouuCQ6iXJ"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_model = LogisticRegression(C=0.004)\n",
        "nb_model = MultinomialNB()\n",
        "svm_model = SVC(kernel='linear', random_state=42, gamma=\"auto\", probability=True)\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "ensemble = VotingClassifier(estimators=[\n",
        "                              ('rf', rf_model),\n",
        "                              ('svm', svm_model),\n",
        "                              ('xgb', xgb_model)],\n",
        "                            voting='soft')        # soft for probability-based voting\n",
        "\n",
        "rfensemble = VotingClassifier(estimators=[\n",
        "                              ('rf', rf_model),\n",
        "                              ('svm', svm_model),\n",
        "                              ('rf1', RandomForestClassifier(n_estimators=100, random_state=42))],\n",
        "                            voting='hard')\n",
        "\n",
        "models = [log_model, nb_model, svm_model, rf_model, xgb_model, knn_model, ensemble,rfensemble]\n",
        "model_names = ['logreg', 'bayes', 'SVM', 'RandomForest', 'XGB', 'KNN', 'Ensemble', 'RF_ensemble']"
      ],
      "metadata": {
        "id": "AC9Hns0G68Qs"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(models)):\n",
        "  print(model_names[i])\n",
        "  print()\n",
        "  test_model(models[i])\n",
        "  print('\\n\\n')"
      ],
      "metadata": {
        "id": "TYOo_QZ98p01",
        "outputId": "861d708d-0698-46bc-e6ee-3c9edb4a924d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logreg\n",
            "\n",
            "Accuracy: 0.9333333333333333\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93        60\n",
            "           1       0.95      0.92      0.93        60\n",
            "\n",
            "    accuracy                           0.93       120\n",
            "   macro avg       0.93      0.93      0.93       120\n",
            "weighted avg       0.93      0.93      0.93       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bayes\n",
            "\n",
            "Accuracy: 0.8916666666666667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.82      0.88        60\n",
            "           1       0.84      0.97      0.90        60\n",
            "\n",
            "    accuracy                           0.89       120\n",
            "   macro avg       0.90      0.89      0.89       120\n",
            "weighted avg       0.90      0.89      0.89       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SVM\n",
            "\n",
            "Accuracy: 0.9416666666666667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94        60\n",
            "           1       0.95      0.93      0.94        60\n",
            "\n",
            "    accuracy                           0.94       120\n",
            "   macro avg       0.94      0.94      0.94       120\n",
            "weighted avg       0.94      0.94      0.94       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RandomForest\n",
            "\n",
            "Accuracy: 0.9583333333333334\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96        60\n",
            "           1       0.98      0.93      0.96        60\n",
            "\n",
            "    accuracy                           0.96       120\n",
            "   macro avg       0.96      0.96      0.96       120\n",
            "weighted avg       0.96      0.96      0.96       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "XGB\n",
            "\n",
            "Accuracy: 0.9083333333333333\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.92      0.91        60\n",
            "           1       0.92      0.90      0.91        60\n",
            "\n",
            "    accuracy                           0.91       120\n",
            "   macro avg       0.91      0.91      0.91       120\n",
            "weighted avg       0.91      0.91      0.91       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "KNN\n",
            "\n",
            "Accuracy: 0.8333333333333334\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.82      0.83        60\n",
            "           1       0.82      0.85      0.84        60\n",
            "\n",
            "    accuracy                           0.83       120\n",
            "   macro avg       0.83      0.83      0.83       120\n",
            "weighted avg       0.83      0.83      0.83       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Ensemble\n",
            "\n",
            "Accuracy: 0.9416666666666667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94        60\n",
            "           1       0.93      0.95      0.94        60\n",
            "\n",
            "    accuracy                           0.94       120\n",
            "   macro avg       0.94      0.94      0.94       120\n",
            "weighted avg       0.94      0.94      0.94       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RF_ensemble\n",
            "\n",
            "Accuracy: 0.9583333333333334\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96        60\n",
            "           1       0.98      0.93      0.96        60\n",
            "\n",
            "    accuracy                           0.96       120\n",
            "   macro avg       0.96      0.96      0.96       120\n",
            "weighted avg       0.96      0.96      0.96       120\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder.inverse_transform([0, 1])"
      ],
      "metadata": {
        "id": "FXRPVw4xjZSm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1f275b-5bfd-4bf9-a119-2e24b63102a2"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['message', 'vacancy'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Add Stacking of models"
      ],
      "metadata": {
        "id": "qQe_zR4VkwO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_models = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)),\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42)),\n",
        "    ('svm', SVC(kernel='linear', random_state=42, gamma=\"auto\", probability=True)),\n",
        "     ('logreg', LogisticRegression(C=0.0045)),\n",
        "    ('xgb', xgb.XGBClassifier())]\n",
        "final_model = RandomForestClassifier(n_estimators=100, max_depth=7, random_state=42)\n",
        "\n",
        "stacking_model = StackingClassifier(estimators=base_models, final_estimator=final_model)\n",
        "test_model(stacking_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANjUw6m3hK1Q",
        "outputId": "0f69fd4b-b21b-45ae-f52f-805825af3205"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9583333333333334\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96        60\n",
            "           1       0.97      0.95      0.96        60\n",
            "\n",
            "    accuracy                           0.96       120\n",
            "   macro avg       0.96      0.96      0.96       120\n",
            "weighted avg       0.96      0.96      0.96       120\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural networks solution"
      ],
      "metadata": {
        "id": "sTYi4nuJB2A_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### import NN stuff"
      ],
      "metadata": {
        "id": "TMCtBxEsJFvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras.utils import pad_sequences, to_categorical"
      ],
      "metadata": {
        "id": "RAOb_m7gIVf9"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "LgJOFcxcB5gw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prerocessing"
      ],
      "metadata": {
        "id": "jzuTUm2CCBVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data"
      ],
      "metadata": {
        "id": "1POaf7K8C-Cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "EuLXF6KhM_hq",
        "outputId": "15ed004a-244d-49f7-80ce-9bf264f56e51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text category  \\\n",
              "0    –ò—â—É —ç–∫—Å–ø–µ—Ä—Ç–æ–≤, –∫—Ç–æ —Ö–æ—á–µ—Ç –ø—Ä–æ–¥–∞–≤–∞—Ç—å —Å–≤–æ–∏ —É—Å–ª—É–≥–∏...  message   \n",
              "1    –ü—Ä–æ–¥–∞—é –º–µ—Å—Ç–∞ –≤ —Å–æ–≤—Å–µ–º —Å–≤–µ–∂–µ–º –∫–∞–Ω–∞–ª–µ. \\n\\n–ù–∞–∑–≤–∞...  message   \n",
              "2    üóΩ–í–∞–º –Ω—É–∂–µ–Ω –ê–¥–≤–æ–∫–∞—Ç?\\nBausat Union –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Å...  message   \n",
              "3    –Ø —é—Ä–∏—Å—Ç, –Ω–æ –µ—Å–ª–∏ –Ω—É–∂–µ–Ω —Ö–æ—Ä–æ—à–∏–π –∞–¥–≤–æ–∫–∞—Ç, —Ç–æ –¥–∞–º...  message   \n",
              "4    #–∏—â—É #–ø—Ä–æ–¥—é—Å–µ—Ä #—ç–∫—Å–ø–µ—Ä—Ç #–∑–∞–ø—É—Å–∫–∏ #–ø—Ä–æ–≥—Ä–µ–≤—ã\\n\\n...  message   \n",
              "..                                                 ...      ...   \n",
              "475  –í –∫–∞—Ñ–µ –ß–µ–±—É—Ä–µ—á–Ω–∞—è –≤ –ü–∞—Ä–∫–µ –°–æ–∫–æ–ª—å–Ω–∏–∫–∏ –æ—Ç–∫—Ä—ã—Ç–∞ –≤...  vacancy   \n",
              "476  #–∏—â—É#–∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä\\n\\n‚ùóÔ∏è–í–ê–ö–ê–ù–°–ò–Ø: \"–ö–æ–ø–∏—Ä–∞–π—Ç–µ—Ä / —Å...  vacancy   \n",
              "477  #–∏—â—É#–∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä\\n\\n‚ùóÔ∏è–í–ê–ö–ê–ù–°–ò–Ø: \"–ö–æ–ø–∏—Ä–∞–π—Ç–µ—Ä / —Å...  vacancy   \n",
              "478  #–∏—â—É #–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç\\n\\n–ö–æ–º–ø–∞–Ω–∏—è TURDZEN –≤ –ø–æ–∏—Å–∫–∞—Ö ...  vacancy   \n",
              "479  #–∏—â—É #–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç \\nüìå –ò—â—É —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π —Å—Ç–∞–Ω...  vacancy   \n",
              "\n",
              "                                             text_lemm  \n",
              "0    –∏—â —ç–∫—Å–ø–µ—Ä—Ç –∫—Ç–æ —Ö–æ—á–µ—Ç –ø—Ä–æ–¥–∞–≤–∞ —Å–≤–æ —É—Å–ª—É–≥ –±—ã—Å—Ç—Ä –∏...  \n",
              "1    –ø—Ä–æ–¥–∞ –º–µ—Å—Ç –≤ —Å–æ–≤—Å —Å–≤–µ–∂ –∫–∞–Ω–∞–ª –Ω–∞–∑–≤–∞–Ω –∞–Ω–µ–∫–¥–æ—Ç–Ω —Å...  \n",
              "2    –≤–∞–º –Ω—É–∂ –∞–¥–≤–æ–∫–∞—Ç bausat union –ø—Ä–µ–¥–ª–∞–≥–∞ —Å–ª–µ–¥ —É—Å–ª...  \n",
              "3    —è —é—Ä–∏—Å—Ç –Ω–æ –µ—Å–ª –Ω—É–∂ —Ö–æ—Ä–æ—à –∞–¥–≤–æ–∫–∞—Ç —Ç–æ –¥–∞–º –∫–æ–Ω–µ—á–Ω...  \n",
              "4    –∏—â –ø—Ä–æ–¥—é—Å–µ—Ä —ç–∫—Å–ø–µ—Ä—Ç –∑–∞–ø—É—Å–∫ –ø—Ä–æ–≥—Ä–µ–≤ –∏—â –ø—Ä–æ–¥—é—Å–µ—Ä...  \n",
              "..                                                 ...  \n",
              "475  –≤ –∫–∞—Ñ —á–µ–±—É—Ä–µ—á–Ω –≤ –ø–∞—Ä–∫ —Å–æ–∫–æ–ª—å–Ω–∏–∫ –æ—Ç–∫—Ä—ã—Ç –≤–∞–∫–∞–Ω—Å ...  \n",
              "476  –∏—â –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä –≤–∞–∫–∞–Ω—Å –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä —Å–æ–∑–¥–∞—Ç–µ–ª —Å—Ç–∞—Ç ...  \n",
              "477  –∏—â –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä –≤–∞–∫–∞–Ω—Å –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä —Å–æ–∑–¥–∞—Ç–µ–ª —Å—Ç–∞—Ç ...  \n",
              "478  –∏—â –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫–æ–º–ø–∞–Ω turdzen –≤ –ø–æ–∏—Å–∫ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç ...  \n",
              "479  –∏—â –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∏—â —á–µ–ª–æ–≤–µ–∫ –∫–æ—Ç–æ—Ä —Å—Ç–∞–Ω–µ—Ç –ø—Ä–∞–≤ —Ä—É–∫ ...  \n",
              "\n",
              "[480 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-f2a992fd-ca23-4858-8a2c-a315fe47472e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>text_lemm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>–ò—â—É —ç–∫—Å–ø–µ—Ä—Ç–æ–≤, –∫—Ç–æ —Ö–æ—á–µ—Ç –ø—Ä–æ–¥–∞–≤–∞—Ç—å —Å–≤–æ–∏ —É—Å–ª—É–≥–∏...</td>\n",
              "      <td>message</td>\n",
              "      <td>–∏—â —ç–∫—Å–ø–µ—Ä—Ç –∫—Ç–æ —Ö–æ—á–µ—Ç –ø—Ä–æ–¥–∞–≤–∞ —Å–≤–æ —É—Å–ª—É–≥ –±—ã—Å—Ç—Ä –∏...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>–ü—Ä–æ–¥–∞—é –º–µ—Å—Ç–∞ –≤ —Å–æ–≤—Å–µ–º —Å–≤–µ–∂–µ–º –∫–∞–Ω–∞–ª–µ. \\n\\n–ù–∞–∑–≤–∞...</td>\n",
              "      <td>message</td>\n",
              "      <td>–ø—Ä–æ–¥–∞ –º–µ—Å—Ç –≤ —Å–æ–≤—Å —Å–≤–µ–∂ –∫–∞–Ω–∞–ª –Ω–∞–∑–≤–∞–Ω –∞–Ω–µ–∫–¥–æ—Ç–Ω —Å...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>üóΩ–í–∞–º –Ω—É–∂–µ–Ω –ê–¥–≤–æ–∫–∞—Ç?\\nBausat Union –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Å...</td>\n",
              "      <td>message</td>\n",
              "      <td>–≤–∞–º –Ω—É–∂ –∞–¥–≤–æ–∫–∞—Ç bausat union –ø—Ä–µ–¥–ª–∞–≥–∞ —Å–ª–µ–¥ —É—Å–ª...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>–Ø —é—Ä–∏—Å—Ç, –Ω–æ –µ—Å–ª–∏ –Ω—É–∂–µ–Ω —Ö–æ—Ä–æ—à–∏–π –∞–¥–≤–æ–∫–∞—Ç, —Ç–æ –¥–∞–º...</td>\n",
              "      <td>message</td>\n",
              "      <td>—è —é—Ä–∏—Å—Ç –Ω–æ –µ—Å–ª –Ω—É–∂ —Ö–æ—Ä–æ—à –∞–¥–≤–æ–∫–∞—Ç —Ç–æ –¥–∞–º –∫–æ–Ω–µ—á–Ω...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#–∏—â—É #–ø—Ä–æ–¥—é—Å–µ—Ä #—ç–∫—Å–ø–µ—Ä—Ç #–∑–∞–ø—É—Å–∫–∏ #–ø—Ä–æ–≥—Ä–µ–≤—ã\\n\\n...</td>\n",
              "      <td>message</td>\n",
              "      <td>–∏—â –ø—Ä–æ–¥—é—Å–µ—Ä —ç–∫—Å–ø–µ—Ä—Ç –∑–∞–ø—É—Å–∫ –ø—Ä–æ–≥—Ä–µ–≤ –∏—â –ø—Ä–æ–¥—é—Å–µ—Ä...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>475</th>\n",
              "      <td>–í –∫–∞—Ñ–µ –ß–µ–±—É—Ä–µ—á–Ω–∞—è –≤ –ü–∞—Ä–∫–µ –°–æ–∫–æ–ª—å–Ω–∏–∫–∏ –æ—Ç–∫—Ä—ã—Ç–∞ –≤...</td>\n",
              "      <td>vacancy</td>\n",
              "      <td>–≤ –∫–∞—Ñ —á–µ–±—É—Ä–µ—á–Ω –≤ –ø–∞—Ä–∫ —Å–æ–∫–æ–ª—å–Ω–∏–∫ –æ—Ç–∫—Ä—ã—Ç –≤–∞–∫–∞–Ω—Å ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>#–∏—â—É#–∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä\\n\\n‚ùóÔ∏è–í–ê–ö–ê–ù–°–ò–Ø: \"–ö–æ–ø–∏—Ä–∞–π—Ç–µ—Ä / —Å...</td>\n",
              "      <td>vacancy</td>\n",
              "      <td>–∏—â –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä –≤–∞–∫–∞–Ω—Å –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä —Å–æ–∑–¥–∞—Ç–µ–ª —Å—Ç–∞—Ç ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>#–∏—â—É#–∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä\\n\\n‚ùóÔ∏è–í–ê–ö–ê–ù–°–ò–Ø: \"–ö–æ–ø–∏—Ä–∞–π—Ç–µ—Ä / —Å...</td>\n",
              "      <td>vacancy</td>\n",
              "      <td>–∏—â –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä –≤–∞–∫–∞–Ω—Å –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä —Å–æ–∑–¥–∞—Ç–µ–ª —Å—Ç–∞—Ç ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>#–∏—â—É #–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç\\n\\n–ö–æ–º–ø–∞–Ω–∏—è TURDZEN –≤ –ø–æ–∏—Å–∫–∞—Ö ...</td>\n",
              "      <td>vacancy</td>\n",
              "      <td>–∏—â –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫–æ–º–ø–∞–Ω turdzen –≤ –ø–æ–∏—Å–∫ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479</th>\n",
              "      <td>#–∏—â—É #–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç \\nüìå –ò—â—É —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π —Å—Ç–∞–Ω...</td>\n",
              "      <td>vacancy</td>\n",
              "      <td>–∏—â –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∏—â —á–µ–ª–æ–≤–µ–∫ –∫–æ—Ç–æ—Ä —Å—Ç–∞–Ω–µ—Ç –ø—Ä–∞–≤ —Ä—É–∫ ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>480 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2a992fd-ca23-4858-8a2c-a315fe47472e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-6c07f029-0d8d-4636-b54f-737fdeea0331\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6c07f029-0d8d-4636-b54f-737fdeea0331')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-6c07f029-0d8d-4636-b54f-737fdeea0331 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f2a992fd-ca23-4858-8a2c-a315fe47472e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f2a992fd-ca23-4858-8a2c-a315fe47472e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def k_process(df):\n",
        "    X = df['text'].copy()\n",
        "    y = df['category'].copy()\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(y)\n",
        "    return train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "BxG3kH1UCCny"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize"
      ],
      "metadata": {
        "id": "3d_JVJ1NCXF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def k_tokenize(x1, x2):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(x1)\n",
        "\n",
        "  x_train = tokenizer.texts_to_sequences(x1)\n",
        "  x_test = tokenizer.texts_to_sequences(x2)\n",
        "\n",
        "  return tokenizer, x_train, x_test"
      ],
      "metadata": {
        "id": "pzYvag2QCR0A"
      },
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add padding"
      ],
      "metadata": {
        "id": "th0cjU-yDWQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def k_padme(x1, x2, maxlen=100):\n",
        "  x_train = pad_sequences(x1, maxlen=maxlen, padding='post')\n",
        "  x_test = pad_sequences(x2, maxlen=maxlen, padding='post')\n",
        "  return x_train, x_test"
      ],
      "metadata": {
        "id": "_Gh0rzlmDXsC"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create model"
      ],
      "metadata": {
        "id": "55tAGeDeDoy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMClassifier:\n",
        "  def __init__(self, vocab_size, embedding_dim, maxlen):\n",
        "    self.vocab = vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.maxlen = maxlen\n",
        "    self.model = self._create_model()\n",
        "\n",
        "  def _create_model(self)->Sequential:\n",
        "    '''creates lstm with embedding, rnn and classificator'''\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=self.vocab, output_dim=self.embedding_dim, input_length=self.maxlen))\n",
        "    model.add(LSTM(units=64))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "  def fit(self, X_train:np.array, y_train:np.array, batch_size:int=64, epochs:int=5)->None:\n",
        "    '''trains model'''\n",
        "\n",
        "    self.model.fit(X_train, y_train.astype(int), epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "\n",
        "  def predict(self, X_test:np.array)->np.array:\n",
        "    '''predics values for validation and test'''\n",
        "    print(\"PREDICTING\")\n",
        "    X_test_padded = pad_sequences(X_test, maxlen=self.maxlen)\n",
        "    return self.model.predict(X_test_padded)\n",
        "\n",
        "\n",
        "  def evaluate(self, pred:np.array, y_test:np.array)->None:\n",
        "    '''reports statistics'''\n",
        "    loss, accuracy = self.model.evaluate(pred, y_test)\n",
        "    pred = (pred > 0.5).astype(int)\n",
        "    print(f\"Loss: {loss}\\nAccuracy: {accuracy}\")\n",
        "    print(classification_report(y_test, pred))\n",
        "\n",
        "\n",
        "  def fit_predict(self, X_train, X_test, y_train, y_test, batch=64, epochs=5):\n",
        "    '''fits data into model, predicts values and reports sttistics'''\n",
        "\n",
        "    self.fit(X_train, y_train, batch, epochs)\n",
        "    y_pred = self.predict(X_test)\n",
        "    print('\\n\\n\\n\\n\\ntest binary\\n\\n\\n\\n')\n",
        "    # Convert predicted values to binary values (0 or 1)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "    self.evaluate(y_pred_binary, y_test)"
      ],
      "metadata": {
        "id": "dnGMRpJ9Edxe"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run it"
      ],
      "metadata": {
        "id": "CaDxAODHJMOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kX_train, kX_test, ky_train, ky_test = k_process(df)\n",
        "k_tokenizer, kX_train, kX_test = k_tokenize(kX_train, kX_test)\n",
        "kX_train, kXtest = k_padme(kX_train, kX_test)\n",
        "\n",
        "kX_train = np.array(kX_train)\n",
        "kX_test = np.array(kX_test)\n",
        "ky_train = np.array(ky_train)\n",
        "ky_test = np.array(ky_test)\n"
      ],
      "metadata": {
        "id": "aFuZLDqCJV8-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee822c54-ae93-450e-c66d-95f2d2ea88b4"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-259-47ef54b04943>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  kX_test = np.array(kX_test)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_vocab_size = len(k_tokenizer.word_index) + 1    # num of unique words in all texts +1  for padding token\n",
        "k_embedding_dim = 100                             #vectors representing a word\n",
        "maxlen = 100                                      # sequence length after tokenization. too long - cut it"
      ],
      "metadata": {
        "id": "-xa12nSYJQ8u"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kLSTM = LSTMClassifier(k_vocab_size, k_embedding_dim, maxlen)\n",
        "kLSTM.fit_predict(kX_train, kX_test, ky_train, ky_test, epochs=10)"
      ],
      "metadata": {
        "id": "wl6Tuq9kKA2S",
        "outputId": "27530fc1-b855-457b-d260-de9b4fdfbc12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 3s 115ms/step - loss: 0.6958 - accuracy: 0.4974\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 1s 119ms/step - loss: 0.6901 - accuracy: 0.5807\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 0.6882 - accuracy: 0.6094\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 1s 180ms/step - loss: 0.6844 - accuracy: 0.6120\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 1s 227ms/step - loss: 0.6770 - accuracy: 0.6120\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 1s 191ms/step - loss: 0.6613 - accuracy: 0.5859\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 2s 312ms/step - loss: 0.6227 - accuracy: 0.5885\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 3s 480ms/step - loss: 0.5776 - accuracy: 0.6484\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 2s 300ms/step - loss: 0.5367 - accuracy: 0.6562\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 2s 270ms/step - loss: 0.5202 - accuracy: 0.6797\n",
            "PREDICTING\n",
            "3/3 [==============================] - 2s 22ms/step\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "test binary\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3/3 [==============================] - 1s 7ms/step - loss: 0.6785 - accuracy: 0.7083\n",
            "Loss: 0.6785092949867249\n",
            "Accuracy: 0.7083333134651184\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.50      0.63        48\n",
            "           1       0.65      0.92      0.76        48\n",
            "\n",
            "    accuracy                           0.71        96\n",
            "   macro avg       0.75      0.71      0.70        96\n",
            "weighted avg       0.75      0.71      0.70        96\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try multiclass"
      ],
      "metadata": {
        "id": "LEf6go_Q1f2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class M_LSTMTextClassifier:\n",
        "    def __init__(self, num_classes=4, vocab_size=10000, embedding_dim=128, lstm_units=128):\n",
        "        self.num_classes = num_classes\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.lstm_units = lstm_units\n",
        "        self.model = self.build_model()\n",
        "\n",
        "\n",
        "    def build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim))\n",
        "        model.add(LSTM(self.lstm_units, dropout=0.2, recurrent_dropout=0.2))\n",
        "        model.add(Dense(self.num_classes, activation='softmax'))\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "\n",
        "    def preprocess_data(self, text_data, target):\n",
        "        tokenizer = Tokenizer(num_words=self.vocab_size)\n",
        "        tokenizer.fit_on_texts(text_data)\n",
        "        sequences = tokenizer.texts_to_sequences(text_data)\n",
        "        word_index = tokenizer.word_index\n",
        "\n",
        "        max_sequence_length = max([len(seq) for seq in sequences])\n",
        "        padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "        one_hot_target = tf.keras.utils.to_categorical(target, self.num_classes)\n",
        "\n",
        "        return padded_sequences, one_hot_target\n",
        "\n",
        "\n",
        "    def train(self, X_train, y_train, epochs=10, batch_size=32, validation_split=0.2):\n",
        "        history = self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split)\n",
        "        return history\n",
        "\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        return self.model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "ndGL-mai_Xpd"
      },
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_X_y(df):\n",
        "  mtext_data = df['text']# .drop('category', axis=1) causes dimension problem when passed to the Sequential gotta find a way to solve it if added nontext cols\n",
        "  mtarget = df['category']\n",
        "  return mtext_data, mtarget\n",
        "\n",
        "def get_encoded_lstm(mtarget):\n",
        "  mlabel_encoder = LabelEncoder()\n",
        "  y = mlabel_encoder.fit_transform(mtarget)\n",
        "  return mlabel_encoder, y\n",
        "\n",
        "\n",
        "def split_lstm(params, target):\n",
        "  return train_test_split(params, target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "0L7JB9g3Vg0G"
      },
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_lstm(X_train, y_train, classnum, epochs = 10):\n",
        "  classifier = M_LSTMTextClassifier(num_classes=classnum, vocab_size=10000)\n",
        "  # Preprocess and train the model\n",
        "  X_train_processed, y_train_processed = classifier.preprocess_data(X_train, y_train)\n",
        "  classifier.train(X_train_processed, y_train_processed, epochs=epochs)\n",
        "  return classifier\n",
        "\n",
        "\n",
        "def test_lstm(classifier, label_encoder, mX_test, my_test):\n",
        "  X_test_processed, y_test_processed = classifier.preprocess_data(mX_test, my_test)\n",
        "  loss, accuracy = classifier.evaluate(X_test_processed, y_test_processed)\n",
        "  print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "  # Convert predicted labels to original class names\n",
        "  y_pred = classifier.model.predict(X_test_processed)\n",
        "  predicted_labels = np.argmax(y_pred, axis=1)\n",
        "  predicted_class_names = label_encoder.inverse_transform(predicted_labels)\n",
        "\n",
        "  # Generate classification report\n",
        "  classification_rep = classification_report(y_test_processed.argmax(axis=1), predicted_labels, target_names=label_encoder.classes_)\n",
        "  print(\"Classification Report:\")\n",
        "  print(classification_rep)\n",
        "  return\n"
      ],
      "metadata": {
        "id": "p381taOdBG7P"
      },
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mX, my = lstm_X_y(text_data)\n",
        "multi_encoder, my_labels = get_encoded_lstm(my)\n",
        "mX_train, mX_test, my_train, my_test = split_lstm(mX, my_labels)\n",
        "\n",
        "mclassifier = train_lstm(mX_train, my_train, len(multi_encoder.classes_), 10)\n",
        "\n",
        "test_lstm(mclassifier, multi_encoder, mX_test, my_test)"
      ],
      "metadata": {
        "id": "ctG78p6njEz5",
        "outputId": "ef8f625e-c708-4841-c023-d8898bda30af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 21s 2s/step - loss: 1.3491 - accuracy: 0.3388 - val_loss: 1.3447 - val_accuracy: 0.2727\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 13s 1s/step - loss: 1.1454 - accuracy: 0.5342 - val_loss: 1.1777 - val_accuracy: 0.5195\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.9592 - accuracy: 0.5928 - val_loss: 1.2216 - val_accuracy: 0.4416\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.8543 - accuracy: 0.6059 - val_loss: 1.0138 - val_accuracy: 0.5584\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.6768 - accuracy: 0.7524 - val_loss: 0.9192 - val_accuracy: 0.6364\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.5247 - accuracy: 0.8111 - val_loss: 0.8653 - val_accuracy: 0.6234\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.3591 - accuracy: 0.9251 - val_loss: 0.8481 - val_accuracy: 0.6883\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.1940 - accuracy: 0.9479 - val_loss: 0.9989 - val_accuracy: 0.6234\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.1001 - accuracy: 0.9870 - val_loss: 0.9085 - val_accuracy: 0.7013\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 15s 2s/step - loss: 0.0517 - accuracy: 0.9902 - val_loss: 0.9539 - val_accuracy: 0.7013\n",
            "3/3 [==============================] - 1s 117ms/step - loss: 1.5576 - accuracy: 0.4688\n",
            "Test Loss: 1.5576, Test Accuracy: 0.4688\n",
            "3/3 [==============================] - 1s 111ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ads       0.27      0.14      0.18        29\n",
            "     message       0.53      0.50      0.51        18\n",
            "     project       0.48      0.48      0.48        23\n",
            "     vacancy       0.51      0.81      0.63        26\n",
            "\n",
            "    accuracy                           0.47        96\n",
            "   macro avg       0.45      0.48      0.45        96\n",
            "weighted avg       0.43      0.47      0.44        96\n",
            "\n"
          ]
        }
      ]
    }
  ]
}