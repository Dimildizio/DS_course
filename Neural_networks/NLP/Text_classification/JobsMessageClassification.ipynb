{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimildizio/DS_course/blob/main/Neural_networks/NLP/Text_classification/JobsMessageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libs"
      ],
      "metadata": {
        "id": "wlZOb4Dl-Dhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install nltk\n",
        "!pip install emoji --upgrade\n",
        "!pip install catboost"
      ],
      "metadata": {
        "id": "alxSWiApUsUd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iF4iz0A48-vN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "import re\n",
        "import emoji\n",
        "import string\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords, reuters\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from pymystem3 import Mystem\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download(\"reuters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrXVzNn0UzEC",
        "outputId": "c850a436-36d9-4f35-ad4e-5a525b2a48f3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Freeze seeds"
      ],
      "metadata": {
        "id": "Adr7nZLtTrH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "SeqZPHCETtge"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the dataset"
      ],
      "metadata": {
        "id": "5Bc_Iah-_hm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = pd.read_excel('msg_type.xlsx')"
      ],
      "metadata": {
        "id": "GcSsofsF-dMV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "orbCX_lh-Wj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = TweetTokenizer()"
      ],
      "metadata": {
        "id": "PCpZOGIf-Wy0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming"
      ],
      "metadata": {
        "id": "Qz286hbW-pdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = SnowballStemmer(\"russian\")\n",
        "stemmer_eng = SnowballStemmer(\"english\")"
      ],
      "metadata": {
        "id": "Eau245xn_Q4N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmaization"
      ],
      "metadata": {
        "id": "gQ-tCd_W_r8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mystem = Mystem()"
      ],
      "metadata": {
        "id": "rAdp3V8i_tpg",
        "outputId": "904e08df-3206-475a-d50f-311180973660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer_eng.stem('python')#.analyze('python')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MRhaVWbxfLoR",
        "outputId": "32ebfaf6-7e8e-4850-c63b-926e85fa9557"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'python'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorize using TFIDF"
      ],
      "metadata": {
        "id": "dXTCd6Lb_3DU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords.words('russian'))"
      ],
      "metadata": {
        "id": "9bS02FX5_5F0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split dataset to parameters and encode target labels"
      ],
      "metadata": {
        "id": "nyQPCc1bC7Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = text_data.copy()\n",
        "#df['category'] = df['category'].replace({'ads': 'message', 'project': 'vacancy'})"
      ],
      "metadata": {
        "id": "9VEDUqDtC-jq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['category']"
      ],
      "metadata": {
        "id": "Y6hVYWNpv979",
        "outputId": "bfb62ad3-3015-4b37-f931-03cd9f287163",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          ads\n",
              "1          ads\n",
              "2          ads\n",
              "3          ads\n",
              "4          ads\n",
              "        ...   \n",
              "475    vacancy\n",
              "476    vacancy\n",
              "477    vacancy\n",
              "478    vacancy\n",
              "479    vacancy\n",
              "Name: category, Length: 480, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Label encode categories"
      ],
      "metadata": {
        "id": "PdmxZUdeVnlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "encoded_target = label_encoder.fit_transform(df['category'])"
      ],
      "metadata": {
        "id": "hzhggYegVrIY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split into params and target values"
      ],
      "metadata": {
        "id": "wRqIDsNJV4Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text']\n",
        "y = encoded_target"
      ],
      "metadata": {
        "id": "e0-QiBASVlxW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform transformation on df"
      ],
      "metadata": {
        "id": "egQ65yKOCyux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emoji(text: str) -> str:\n",
        "    return emoji.replace_emoji(text, \" \")\n",
        "\n",
        "\n",
        "def remove_links(text: str) -> str:\n",
        "    return re.sub(r\"http\\S+\", \" \", text, flags=re.MULTILINE)\n",
        "\n",
        "\n",
        "def remove_usernames_and_emails(text: str) -> str:\n",
        "    \"\"\"–£–¥–∞–ª–µ—è–µ—Ç —é–∑–µ—Ä–Ω–µ–π–º—ã –∏ email\"\"\"\n",
        "    return re.sub(r\"\\S*@\\S*\", \" \", text, flags=re.MULTILINE)\n",
        "\n",
        "\n",
        "def remove_punctuation(text: str) -> str:\n",
        "    \"\"\"–£–¥–∞–ª—è–µ–º —Å–∏–º–≤–æ–ª—ã –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏\"\"\"\n",
        "    return \"\".join([ch if ch not in string.punctuation else \" \" for ch in text])\n",
        "\n",
        "\n",
        "def remove_numbers(text: str) -> str:\n",
        "    \"\"\"–£–¥–∞–ª—è–µ–º —á–∏—Å–ª–∞\"\"\"\n",
        "    return \"\".join([i if not i.isdigit() else \" \" for i in text])\n",
        "\n",
        "\n",
        "def remove_multiple_spaces(text: str) -> str:\n",
        "    \"\"\"–£–¥–∞–ª—è–µ–º –¥–≤–æ–π–Ω—ã–µ (–∏ –±–æ–ª–µ–µ) –ø—Ä–æ–±–µ–ª—ã\"\"\"\n",
        "    return re.sub(r\"\\s+\", \" \", text, flags=re.I)"
      ],
      "metadata": {
        "id": "kvAuLGg2DeLL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prep_text(text: str) -> str:\n",
        "  return remove_multiple_spaces(\n",
        "      remove_numbers(\n",
        "          remove_punctuation(\n",
        "              remove_usernames_and_emails(\n",
        "                  remove_links(\n",
        "                      remove_emoji(text)\n",
        "                      )\n",
        "                  )\n",
        "              )\n",
        "          )\n",
        "      )"
      ],
      "metadata": {
        "id": "Ze1Dd5irEFH8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NBR1DSgUWjqw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#our new dataset with stemmed lemmatized and later vectorized texts\n",
        "stemmed_lemma_txts = []\n",
        "\n",
        "for text in X:\n",
        "  tok = tokenizer.tokenize(get_prep_text(text).lower())\n",
        "  stem_tok = [stemmer.stem(token) for token in tok]\n",
        "  # lem_tok = [lem for lem in mystem.lemmatize(\" \".join(stem_tok)) if not lem.isspace()]\n",
        "  # stemmed_lemma_txts.append(' '.join(lem_tok))\n",
        "  stemmed_lemma_txts.append(' '.join(stem_tok))\n",
        "\n",
        "df['text_lemm'] = stemmed_lemma_txts"
      ],
      "metadata": {
        "id": "_AoklUd1CyQu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TFIDF Vectorize"
      ],
      "metadata": {
        "id": "ao8AJx7yD188"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfd = tfidf_vectorizer.fit_transform(stemmed_lemma_txts)"
      ],
      "metadata": {
        "id": "TPetowxrD0BS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split dataset"
      ],
      "metadata": {
        "id": "EPEBSiRxAGHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pass tfidf'd and transfromed data instead of texts as X"
      ],
      "metadata": {
        "id": "pS8tzS8AVK66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tfidfd, y, stratify=y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "3FHZ9SUyAHx-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "7HX96oveEee1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and train baseline model"
      ],
      "metadata": {
        "id": "ZshtoMLyAgcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(C=0.004)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "JzH_z-mPADkt",
        "outputId": "40fbe3db-cbdd-4054-8b53-a90bbd1f9966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.004)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.004)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.004)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict"
      ],
      "metadata": {
        "id": "Sy2G_blXEcE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "-gapxEVgAfrY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate"
      ],
      "metadata": {
        "id": "n1Dd5275EjjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy"
      ],
      "metadata": {
        "id": "bS6NmFkhEvw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy:', acc)"
      ],
      "metadata": {
        "id": "UGsDgjo8El3O",
        "outputId": "f02248a1-c7f9-4bdb-995e-310f1ec0b1b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Report"
      ],
      "metadata": {
        "id": "bC_2nOceExNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "G3_u5H3RE2ne",
        "outputId": "560165b9-3805-4dbc-bd3f-014a9fa7da29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.73      0.79        30\n",
            "           1       0.81      0.97      0.88        30\n",
            "           2       0.88      0.73      0.80        30\n",
            "           3       0.88      0.97      0.92        30\n",
            "\n",
            "    accuracy                           0.85       120\n",
            "   macro avg       0.85      0.85      0.85       120\n",
            "weighted avg       0.85      0.85      0.85       120\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sum it up"
      ],
      "metadata": {
        "id": "QJXTDgm66jBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Catboost"
      ],
      "metadata": {
        "id": "l75Q3u20xSLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_model = CatBoostClassifier(iterations=400, depth=6, learning_rate=0.04, loss_function='MultiClass', verbose=False)\n",
        "cat_model.fit(X_train, y_train, eval_set=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRD3V3L5puaX",
        "outputId": "aecaa330-e540-4444-94c7-d82ba50dae08"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7fc4b537fbe0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = cat_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_pred, y_test)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "class_names = ['ads','message', 'project', 'vacancy']\n",
        "report = classification_report(y_test, y_pred, target_names=class_names)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB79wrrDsBmo",
        "outputId": "8538b569-d1f1-4c46-be62-cd35918aa60b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.82\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ads       0.91      0.67      0.77        30\n",
            "     message       0.74      0.97      0.84        30\n",
            "     project       0.81      0.73      0.77        30\n",
            "     vacancy       0.84      0.90      0.87        30\n",
            "\n",
            "    accuracy                           0.82       120\n",
            "   macro avg       0.83      0.82      0.81       120\n",
            "weighted avg       0.83      0.82      0.81       120\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model):\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  print('Accuracy:', acc)\n",
        "  print(\"Classification Report:\")\n",
        "  print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "Y_7ouuCQ6iXJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_model = LogisticRegression(C=0.004)\n",
        "nb_model = MultinomialNB()\n",
        "svm_model = SVC(kernel='linear', random_state=42, gamma=\"auto\", probability=True)\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "ensemble = VotingClassifier(estimators=[\n",
        "                              ('rf', rf_model),\n",
        "                              ('svm', svm_model),\n",
        "                              ('xgb', xgb_model)],\n",
        "                            voting='soft')        # soft for probability-based voting\n",
        "\n",
        "rfensemble = VotingClassifier(estimators=[\n",
        "                              ('rf', rf_model),\n",
        "                              ('svm', svm_model),\n",
        "                              ('rf1', RandomForestClassifier(n_estimators=100, random_state=42))],\n",
        "                            voting='hard')\n",
        "\n",
        "models = [log_model, nb_model, svm_model, rf_model, xgb_model, knn_model, ensemble,rfensemble]\n",
        "model_names = ['logreg', 'bayes', 'SVM', 'RandomForest', 'XGB', 'KNN', 'Ensemble', 'RF_ensemble']"
      ],
      "metadata": {
        "id": "AC9Hns0G68Qs"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(models)):\n",
        "  print(model_names[i])\n",
        "  print()\n",
        "  test_model(models[i])\n",
        "  print('\\n\\n')"
      ],
      "metadata": {
        "id": "TYOo_QZ98p01",
        "outputId": "980c91e8-29ac-49f3-ad3c-3a69b6a74f62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logreg\n",
            "\n",
            "Accuracy: 0.85\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.73      0.79        30\n",
            "           1       0.81      0.97      0.88        30\n",
            "           2       0.88      0.73      0.80        30\n",
            "           3       0.88      0.97      0.92        30\n",
            "\n",
            "    accuracy                           0.85       120\n",
            "   macro avg       0.85      0.85      0.85       120\n",
            "weighted avg       0.85      0.85      0.85       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bayes\n",
            "\n",
            "Accuracy: 0.775\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.90      0.79        30\n",
            "           1       0.89      0.53      0.67        30\n",
            "           2       0.70      0.70      0.70        30\n",
            "           3       0.85      0.97      0.91        30\n",
            "\n",
            "    accuracy                           0.78       120\n",
            "   macro avg       0.79      0.78      0.77       120\n",
            "weighted avg       0.79      0.78      0.77       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SVM\n",
            "\n",
            "Accuracy: 0.8583333333333333\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.80      0.81        30\n",
            "           1       0.78      0.93      0.85        30\n",
            "           2       0.89      0.80      0.84        30\n",
            "           3       0.96      0.90      0.93        30\n",
            "\n",
            "    accuracy                           0.86       120\n",
            "   macro avg       0.86      0.86      0.86       120\n",
            "weighted avg       0.86      0.86      0.86       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RandomForest\n",
            "\n",
            "Accuracy: 0.85\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.70      0.81        30\n",
            "           1       0.74      0.97      0.84        30\n",
            "           2       0.83      0.83      0.83        30\n",
            "           3       0.93      0.90      0.92        30\n",
            "\n",
            "    accuracy                           0.85       120\n",
            "   macro avg       0.87      0.85      0.85       120\n",
            "weighted avg       0.87      0.85      0.85       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "XGB\n",
            "\n",
            "Accuracy: 0.85\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.73      0.81        30\n",
            "           1       0.78      0.97      0.87        30\n",
            "           2       0.88      0.77      0.82        30\n",
            "           3       0.85      0.93      0.89        30\n",
            "\n",
            "    accuracy                           0.85       120\n",
            "   macro avg       0.86      0.85      0.85       120\n",
            "weighted avg       0.86      0.85      0.85       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "KNN\n",
            "\n",
            "Accuracy: 0.7333333333333333\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.77      0.69        30\n",
            "           1       0.95      0.70      0.81        30\n",
            "           2       0.68      0.70      0.69        30\n",
            "           3       0.77      0.77      0.77        30\n",
            "\n",
            "    accuracy                           0.73       120\n",
            "   macro avg       0.76      0.73      0.74       120\n",
            "weighted avg       0.76      0.73      0.74       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Ensemble\n",
            "\n",
            "Accuracy: 0.8833333333333333\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.73      0.83        30\n",
            "           1       0.81      0.97      0.88        30\n",
            "           2       0.90      0.87      0.88        30\n",
            "           3       0.91      0.97      0.94        30\n",
            "\n",
            "    accuracy                           0.88       120\n",
            "   macro avg       0.89      0.88      0.88       120\n",
            "weighted avg       0.89      0.88      0.88       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RF_ensemble\n",
            "\n",
            "Accuracy: 0.85\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.70      0.81        30\n",
            "           1       0.74      0.97      0.84        30\n",
            "           2       0.83      0.83      0.83        30\n",
            "           3       0.93      0.90      0.92        30\n",
            "\n",
            "    accuracy                           0.85       120\n",
            "   macro avg       0.87      0.85      0.85       120\n",
            "weighted avg       0.87      0.85      0.85       120\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder.inverse_transform([0, 1])"
      ],
      "metadata": {
        "id": "FXRPVw4xjZSm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af8ee11b-32eb-47d9-b2b5-d26d017dbe86"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ads', 'message'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'][0]"
      ],
      "metadata": {
        "id": "kECINKJMZ4Y5",
        "outputId": "474725f0-11d1-4897-d6d5-6eef2b921371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'–ò—â—É —ç–∫—Å–ø–µ—Ä—Ç–æ–≤, –∫—Ç–æ —Ö–æ—á–µ—Ç –ø—Ä–æ–¥–∞–≤–∞—Ç—å —Å–≤–æ–∏ —É—Å–ª—É–≥–∏ –±—ã—Å—Ç—Ä–æ –∏ –ª–µ–≥–∫–æ üî•\\n\\n–ü—Ä–∏–≤–µ—Ç, —è –û–ª–µ—Å—è - –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –∏ –≤–µ–±-–¥–∏–∑–∞–π–Ω–µ—Ä —ç–∫—Å–ø–µ—Ä—Ç–æ–≤. –Ø —Å–æ–∑–¥–∞—é –ª–∞–∫–æ–Ω–∏—á–Ω—ã–µ, —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º –≤–∞–π–±–æ–º —Å–∞–π—Ç—ã –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –Ω–∞ Taplink. \\n\\n–í—Å—è –Ω—É–∂–Ω–∞—è –∏ –≤–∞–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–æ–±—Ä–∞–Ω–∞ –≤ –æ–¥–Ω–æ–º –º–µ—Å—Ç–µ, —á—Ç–æ–±—ã –≤–∞—à –∫–ª–∏–µ–Ω—Ç –ø—Ä–æ—Ö–æ–¥–∏–ª –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—É—Ç—å –∫ –ø–æ–∫—É–ø–∫–µ üí∏\\n\\n–ß—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω–µ–µ –ø–∏—à–∏ –≤ –ª—Å \"–°–û–¢–†–£–î–ù–ò–ß–ï–°–¢–í–û\"ü§ç'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Element"
      ],
      "metadata": {
        "id": "2ViCtPXXZXzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[50]"
      ],
      "metadata": {
        "id": "6sDQJPRAaC7H",
        "outputId": "130015f4-41dc-40dc-d0fe-54fb55d32995",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text         –ò—â–µ—à—å –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä–∞ –∏ PR —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞? \\n\\n–ü—Ä–∏–≤–µ—Ç...\n",
              "category                                                   ads\n",
              "text_lemm    –∏—â–µ—à –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä –∏ pr —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø—Ä–∏–≤–µ—Ç –º–µ–Ω –∑–æ–≤...\n",
              "Name: 50, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mywords = []\n",
        "text = df['text'][50]#'–ü—Ä–æ–¥–∞–º –≥–∞—Ä–∞–∂. –ú–æ–ø–µ–¥ –Ω–µ –º–æ–π. –Ø –ø—Ä–æ—Å—Ç–æ —Ä–∞–∑–º–µ—Å—Ç–∏–ª –æ–±—ä—è–≤—É.'\n",
        "tk = tokenizer.tokenize(get_prep_text(text).lower())\n",
        "stk = [stemmer.stem(token) for token in tk]\n",
        "lmtk = [lem for lem in mystem.lemmatize(\" \".join(stk)) if not lem.isspace()]\n",
        "mywords.append(' '.join(lmtk))\n",
        "wrd = tfidf_vectorizer.transform(mywords)\n",
        "rf_model.predict(wrd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1vw2EZ1WsaZ",
        "outputId": "444e5e22-4776-435f-bf28-0777a9ba1548"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Add Stacking of models"
      ],
      "metadata": {
        "id": "qQe_zR4VkwO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_models = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)),\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42)),\n",
        "    ('svm', SVC(kernel='linear', random_state=42, gamma=\"auto\", probability=True)),\n",
        "     ('logreg', LogisticRegression(C=0.0045)),\n",
        "    ('xgb', xgb.XGBClassifier())]\n",
        "final_model = RandomForestClassifier(n_estimators=100, max_depth=7, random_state=42)\n",
        "\n",
        "stacking_model = StackingClassifier(estimators=base_models, final_estimator=final_model)\n",
        "test_model(stacking_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANjUw6m3hK1Q",
        "outputId": "fc20a613-825c-4f0a-bbb6-8c9ef9ff55e5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.875\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.83      0.86        30\n",
            "           1       0.85      0.93      0.89        30\n",
            "           2       0.86      0.80      0.83        30\n",
            "           3       0.90      0.93      0.92        30\n",
            "\n",
            "    accuracy                           0.88       120\n",
            "   macro avg       0.88      0.88      0.87       120\n",
            "weighted avg       0.88      0.88      0.87       120\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement as pipeline"
      ],
      "metadata": {
        "id": "kSmrpEmZidDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class iPipe:\n",
        "  def __init__(self, estimator):\n",
        "    self.estimator = estimator\n",
        "    self.model = None\n",
        "\n",
        "  def prepipe(self, text):\n",
        "    tk = tokenizer.tokenize(get_prep_text(text).lower())\n",
        "    stk = [stemmer.stem(token) for token in tk]\n",
        "    return ' '.join(stk)\n",
        "\n",
        "\n",
        "  def train(self, X_train, y_train):\n",
        "    self.model = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(preprocessor=self.prepipe)),\n",
        "        ('clf', self.estimator)])\n",
        "\n",
        "    self.model.fit(X_train, y_train)\n",
        "    return self.model\n",
        "\n",
        "\n",
        "  def predict(self, x):\n",
        "    return self.model.predict(x)\n",
        "\n",
        "\n",
        "  def evaluate(self, X_test, y_test):\n",
        "    y_pred = self.predict(X_test)\n",
        "    print('predicted')\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "  def fit_predict(self, df):\n",
        "    X = df['text']\n",
        "    y = df['category']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42, test_size=0.2)\n",
        "    self.train(X_train, y_train)\n",
        "    print('trained')\n",
        "    self.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "khJv0PCXe7hi"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = iPipe(RandomForestClassifier(n_estimators=100, random_state=42, max_depth=6))\n",
        "pipe.fit_predict(text_data)"
      ],
      "metadata": {
        "id": "112mOgwohPuE",
        "outputId": "300c0f31-b0a6-4ece-d66e-8118052d2eb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trained\n",
            "predicted\n",
            "Accuracy: 0.84375\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ads       0.94      0.71      0.81        24\n",
            "     message       0.75      1.00      0.86        24\n",
            "     project       0.89      0.71      0.79        24\n",
            "     vacancy       0.85      0.96      0.90        24\n",
            "\n",
            "    accuracy                           0.84        96\n",
            "   macro avg       0.86      0.84      0.84        96\n",
            "weighted avg       0.86      0.84      0.84        96\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrd = ['–î–ª—è –º–µ–≥–∞—Å—Ç–∞—Ä—Ç–∞–ø–∞ –Ω–æ–≤—ã–π –≥—É–≥–ª –∏—â—É –¥–∞—Ç–∞—Å–∞—Ç–∞–Ω–∏—Å—Ç–∞. \\\n",
        "        –ø–ª–∞—á—É 300000 –±–∞–∫—Å–æ–≤\\–Ω–∞–Ω–æ—Å–µ–∫. –Ω–∞–¥–æ –≤—Å–µ –∏ —Å—Ä–∞–∑—É - –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞, –æ–±—Ä–∞–±–æ—Ç–∫–∞, –Ω–∞–ø–∏—Å–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π, \\\n",
        "        —Å–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∞—Å–∏–≤–µ–Ω—å–∫–∏—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∏ –ø—Ä–æ–¥–∞–∂–∞ –¥–∞–Ω–Ω—ã—Ö. –ù—É–∂–µ–Ω –º–∏–¥–ª —Å –∑–∞–ø—Ä–æ—Å–∞–º–∏ –¥–∂—É–Ω–∞ –∏ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—è–º–∏ —Å–µ–Ω—å–æ—Ä–∞. \\\n",
        "        —Ç–∏–º–ª–∏–¥ –∏ —Ç–µ—Ö–ª–∏–¥ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ. –≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–∏–¥–µ—Ç—Å—è –∏—Å–∫–∞—Ç—å –∫–ª–∏–µ–Ω—Ç–æ–≤, –ø—Ä–µ–∑–µ–Ω—Ç–æ–≤–∞—Ç—å –∏–º —Ä–∞–±–æ—Ç—É –∏ –≤–µ—Å—Ç–∏ \\\n",
        "        –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è. –ò–Ω–æ–≥–¥–∞ –º—ã—Ç—å –ø–æ–ª—ã. –ù–µ –∑–∞–¥–∞–≤–∞—Ç—å—Å—è –≤–æ–ø—Ä–æ—Å–æ–º –∑–∞—á–µ–º —è –Ω—É–∂–µ–Ω –≤ –ø—Ä–æ–µ–∫—Ç–µ.']\n",
        "pipe.predict(wrd)"
      ],
      "metadata": {
        "id": "AjHf5Hnxiihw",
        "outputId": "d01ad3e9-69eb-4e8a-bc7a-b723478791a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['project'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Word2Vec"
      ],
      "metadata": {
        "id": "hXKBmxgNoKp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gensim"
      ],
      "metadata": {
        "id": "T9jkxooNoMMO"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "from sklearn.base import BaseEstimator, TransformerMixin"
      ],
      "metadata": {
        "id": "aQzkmraBoOZG"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#api.info()\n",
        "word2vec_model = api.load('word2vec-ruscorpora-300')"
      ],
      "metadata": {
        "id": "acgU98cMosMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ea9213-eae3-460f-a48f-77f192f3e59d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 198.8/198.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convlist='''A       ADJ\n",
        "ADV     ADV\n",
        "ADVPRO  ADV\n",
        "ANUM    ADJ\n",
        "APRO    DET\n",
        "COM     ADJ\n",
        "CONJ    SCONJ\n",
        "INTJ    INTJ\n",
        "NONLEX  X\n",
        "NUM     NUM\n",
        "PART    PART\n",
        "PR      ADP\n",
        "S       NOUN\n",
        "SPRO    PRON\n",
        "UNKN    X\n",
        "V       VERB'''.split()\n",
        "conv_dict = {}\n",
        "for i in range(0, len(convlist), 2):\n",
        "    keyword = convlist[i]\n",
        "    value = convlist[i + 1]\n",
        "    conv_dict[keyword] = value\n"
      ],
      "metadata": {
        "id": "-jY_5RDkbYWV"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tag(word='–ø–æ–∂–∞—Ä'):\n",
        "    processed = mystem.analyze(word)[0]\n",
        "    if not ('analysis' in processed):\n",
        "      return 'unknown'\n",
        "    elif not processed['analysis']:\n",
        "      return word\n",
        "    lemma = processed[\"analysis\"][0][\"lex\"].lower().strip()\n",
        "    pos = processed[\"analysis\"][0][\"gr\"].split(',')[0]\n",
        "    pos = pos.split('=')[0].strip()\n",
        "    tagged = lemma+'_'+conv_dict[pos]\n",
        "\n",
        "    return tagged"
      ],
      "metadata": {
        "id": "sWIitHrXZ0l3"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag('–ø—Ä–∏–≤–µ—Ç') in word2vec_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Srzdly2GZPjI",
        "outputId": "f84bc122-aa0c-4c07-fb5a-2098d71dbef8"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'lex': '–ø—Ä–∏–≤–µ—Ç', 'wt': 1, 'gr': 'S,–º—É–∂,–Ω–µ–æ–¥=(–≤–∏–Ω,–µ–¥|–∏–º,–µ–¥)'}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag('cpfsdm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "0ZU6pZWEKXTK",
        "outputId": "62a65eeb-e3c3-45a1-849e-b47865fd90ec"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'unknown'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model.key_to_index['–∏—Å–∫–∞—Ç—å_VERB']"
      ],
      "metadata": {
        "id": "VTjI5RBWzBD9",
        "outputId": "78db3068-6033-4a79-9133-5ef21ac94ff1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "368"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w0 = df['text'][0].split()[0]\n",
        "print(f'\"{w0}\" in corpora: {w0 in word2vec_model}')\n",
        "print(f'tag \"{tag(w0)}\" in corpora: {tag(w0) in word2vec_model}')"
      ],
      "metadata": {
        "id": "5FPXBrhdz_Os",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4181f326-5c61-45dd-b52e-d1130358c3ca"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"–ò—â—É\" in corpora: False\n",
            "[{'lex': '–∏—Å–∫–∞—Ç—å', 'wt': 1, 'gr': 'V,–Ω–µ—Å–æ–≤,–ø–µ=–Ω–µ–ø—Ä–æ—à,–µ–¥,–∏–∑—ä—è–≤,1-–ª'}]\n",
            "[{'lex': '–∏—Å–∫–∞—Ç—å', 'wt': 1, 'gr': 'V,–Ω–µ—Å–æ–≤,–ø–µ=–Ω–µ–ø—Ä–æ—à,–µ–¥,–∏–∑—ä—è–≤,1-–ª'}]\n",
            "tag \"–∏—Å–∫–∞—Ç—å_VERB\" in corpora: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Might need to try and train w2v from zero or solve the _VERB _NOUN shyte of rus corpora"
      ],
      "metadata": {
        "id": "DC3mBdCv2PK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "UPD: No need. converting the word using stemma into base form and adding parts of speech type (with conversion) worked"
      ],
      "metadata": {
        "id": "ThJAaWIYdUlH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Add english corpora for english words"
      ],
      "metadata": {
        "id": "dNXOi6P0iPKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_mbeddings = api.load(\"glove-wiki-gigaword-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf7R-mooiRzk",
        "outputId": "fe9f8ceb-8562-4cfd-dd7b-0e35587e21d6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(en_mbeddings['unknown'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbVQLQzbiZPN",
        "outputId": "f32a1d04-e6c4-40f4-f075-e9392a2ab2c3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7.2751107837684685"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create custom class for using word2vec in pipeline"
      ],
      "metadata": {
        "id": "QwXbaKnDqHml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2VecTrans(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, word2vec_model):\n",
        "        self.word2vec_model = word2vec_model\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        embeddings = []\n",
        "        for text in X:\n",
        "            tokens = text.split()  # Split text into tokens\n",
        "            text_embeddings = []\n",
        "            for token in tokens:\n",
        "                token = tag(token)\n",
        "                if token in self.word2vec_model:\n",
        "                    text_embeddings.append(self.word2vec_model[token])\n",
        "                elif token in en_mbeddings:\n",
        "                    text_embeddings.append(en_mbeddings[token])\n",
        "            embeddings.append(text_embeddings)\n",
        "        return embeddings"
      ],
      "metadata": {
        "id": "MRlLNdlvpXG7"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create custom class for preprocessing stuff before pass it to word2vec"
      ],
      "metadata": {
        "id": "U-hU5TFhtUij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocessor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, preprocessor):\n",
        "        self.preprocessor = preprocessor\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return [self.preprocessor(text) for text in X]\n"
      ],
      "metadata": {
        "id": "oIFcgZnCtaSi"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  tk = tokenizer.tokenize(get_prep_text(text).lower())\n",
        "  return ' '.join(tk)"
      ],
      "metadata": {
        "id": "hVI1Q6h1tjNa"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a separate class for w2v pipeline"
      ],
      "metadata": {
        "id": "XtMYV3M1uYlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class W2VPipe(iPipe):\n",
        "  def __init__(self, preprocessor, w2v, estimator):\n",
        "    super().__init__(estimator)\n",
        "    self.preprocessor = preprocessor\n",
        "    self.w2v = w2v\n",
        "\n",
        "  def train(self, X_train, y_train):\n",
        "    self.model = Pipeline([\n",
        "        #('preprocess', self.preprocessor),\n",
        "        #('w2v', self.w2v),\n",
        "        ('clf', self.estimator)])\n",
        "\n",
        "    self.model.fit(X_train, y_train)\n",
        "    return self.model\n",
        "\n",
        "  def fit_predict(self, X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42, test_size=0.2)\n",
        "    self.train(X_train, y_train)\n",
        "    print('trained')\n",
        "    self.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "iIXtRaJ1qN7R"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gather it all together"
      ],
      "metadata": {
        "id": "r2ayrO_DvYlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model.vector_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be-QnFmXUW_W",
        "outputId": "7681bb42-df08-45ae-f278-36594893bc1c"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_transformer = Word2VecTrans(word2vec_model)\n",
        "preprop = Preprocessor(preprocessor=preprocess)\n",
        "svm_w2v = SVC(kernel='linear', random_state=42, gamma=\"auto\", probability=True, C=5000)"
      ],
      "metadata": {
        "id": "v3hkLLj9rBRR"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v = w2v_transformer.transform(preprop.transform(text_data['text']))"
      ],
      "metadata": {
        "id": "D8-OhE4wwVB2"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wmaxlen = max(len(x) for x in w2v)\n",
        "for entry in w2v:\n",
        "  while len(entry) < wmaxlen:\n",
        "    entry.append(0.0)\n",
        "avg_w2v = [np.mean(emb, axis=0) if emb else np.zeros(word2vec_model.vector_size) for emb in w2v]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gAqXDzURFXH",
        "outputId": "0003d19d-1def-4848-a616-6d8164de4be9"
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:164: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = asanyarray(a)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wX_train, wX_test, wy_train, wy_test = train_test_split(avg_w2v, text_data['category'], random_state=42, stratify=y, test_size=0.2)"
      ],
      "metadata": {
        "id": "X8VFuSVBQ8JB"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wsvm = svm_w2v.fit(wX_train, wy_train)\n",
        "wy_pred = svm_w2v.predict(wX_test)\n",
        "waccuracy = accuracy_score(wy_test, wy_pred)\n",
        "print(\"Accuracy:\", waccuracy)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(wy_test, wy_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek9u8F8ZSFbY",
        "outputId": "e560fc37-c39a-4050-f8bb-18965699d384"
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.84375\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ads       0.82      0.75      0.78        24\n",
            "     message       0.88      0.96      0.92        24\n",
            "     project       0.87      0.83      0.85        24\n",
            "     vacancy       0.80      0.83      0.82        24\n",
            "\n",
            "    accuracy                           0.84        96\n",
            "   macro avg       0.84      0.84      0.84        96\n",
            "weighted avg       0.84      0.84      0.84        96\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Add fastText for multilanguage word2vec"
      ],
      "metadata": {
        "id": "z2EFW633psUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext_model = api.load(\"fasttext-wiki-news-subwords-300\")"
      ],
      "metadata": {
        "id": "Z9lYuY4f1uhy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d338b994-c82a-49e7-fd88-768dc5520470"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================================-] 100.0% 958.1/958.4MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_transformer = Word2VecTrans(fasttext_model)\n",
        "ftpreprop = Preprocessor(preprocessor=preprocess)"
      ],
      "metadata": {
        "id": "pJkSEoVMbhTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft = w2v_transformer.transform(preprop.transform(text_data['text']))\n",
        "ftmaxlen = max(len(x) for x in ft)\n",
        "for entry in ft:\n",
        "  while len(entry) < ftmaxlen:\n",
        "    entry.append(np.zeros(fasttext_model.vector_size))\n",
        "favg_w2v = [np.mean(emb, axis=0) if emb else np.zeros(fasttext_model.vector_size) for emb in ft]\n",
        "ftX_train, ftX_test, fty_train, fty_test = train_test_split(favg_w2v, text_data['category'], random_state=42, stratify=y, test_size=0.2)\n"
      ],
      "metadata": {
        "id": "_qFW-AYtdwE6"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_ft = SVC(kernel='linear', random_state=42, gamma=\"auto\", probability=True, C=6000)\n",
        "ft_forest = RandomForestClassifier(max_depth=5, random_state=42, n_estimators=100)"
      ],
      "metadata": {
        "id": "FtnZxHfoeAB7"
      },
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_ft in (svm_ft, ft_forest):\n",
        "  wsvm = model_ft.fit(ftX_train, fty_train)\n",
        "  fty_pred = model_ft.predict(ftX_test)\n",
        "  ftaccuracy = accuracy_score(fty_test, fty_pred)\n",
        "  print(\"Accuracy:\", ftaccuracy)\n",
        "  print(\"Classification Report:\")\n",
        "  print(classification_report(fty_test, fty_pred))"
      ],
      "metadata": {
        "id": "NxXVFpjweOWD",
        "outputId": "2dbf3051-ea6b-4933-a550-d0dfb7ebfefa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.84375\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ads       0.82      0.75      0.78        24\n",
            "     message       0.88      0.96      0.92        24\n",
            "     project       0.87      0.83      0.85        24\n",
            "     vacancy       0.80      0.83      0.82        24\n",
            "\n",
            "    accuracy                           0.84        96\n",
            "   macro avg       0.84      0.84      0.84        96\n",
            "weighted avg       0.84      0.84      0.84        96\n",
            "\n",
            "Accuracy: 0.75\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ads       0.71      0.62      0.67        24\n",
            "     message       0.87      0.83      0.85        24\n",
            "     project       0.69      0.75      0.72        24\n",
            "     vacancy       0.73      0.79      0.76        24\n",
            "\n",
            "    accuracy                           0.75        96\n",
            "   macro avg       0.75      0.75      0.75        96\n",
            "weighted avg       0.75      0.75      0.75        96\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural networks solution"
      ],
      "metadata": {
        "id": "sTYi4nuJB2A_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### import NN stuff"
      ],
      "metadata": {
        "id": "TMCtBxEsJFvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras.utils import pad_sequences, to_categorical"
      ],
      "metadata": {
        "id": "RAOb_m7gIVf9"
      },
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "LgJOFcxcB5gw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prerocessing"
      ],
      "metadata": {
        "id": "jzuTUm2CCBVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data"
      ],
      "metadata": {
        "id": "1POaf7K8C-Cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "EuLXF6KhM_hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def k_process(df):\n",
        "    X = df['text'].copy()\n",
        "    y = df['category'].copy()\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(y)\n",
        "    return train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "BxG3kH1UCCny"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize"
      ],
      "metadata": {
        "id": "3d_JVJ1NCXF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def k_tokenize(x1, x2):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(x1)\n",
        "\n",
        "  x_train = tokenizer.texts_to_sequences(x1)\n",
        "  x_test = tokenizer.texts_to_sequences(x2)\n",
        "\n",
        "  return tokenizer, x_train, x_test"
      ],
      "metadata": {
        "id": "pzYvag2QCR0A"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add padding"
      ],
      "metadata": {
        "id": "th0cjU-yDWQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def k_padme(x1, x2, maxlen=100):\n",
        "  x_train = pad_sequences(x1, maxlen=maxlen, padding='post')\n",
        "  x_test = pad_sequences(x2, maxlen=maxlen, padding='post')\n",
        "  return x_train, x_test"
      ],
      "metadata": {
        "id": "_Gh0rzlmDXsC"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create model"
      ],
      "metadata": {
        "id": "55tAGeDeDoy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMClassifier:\n",
        "  def __init__(self, vocab_size, embedding_dim, maxlen):\n",
        "    self.vocab = vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.maxlen = maxlen\n",
        "    self.model = self._create_model()\n",
        "\n",
        "  def _create_model(self)->Sequential:\n",
        "    '''creates lstm with embedding, rnn and classificator'''\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=self.vocab, output_dim=self.embedding_dim, input_length=self.maxlen))\n",
        "    model.add(LSTM(units=64))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "  def fit(self, X_train:np.array, y_train:np.array, batch_size:int=64, epochs:int=5)->None:\n",
        "    '''trains model'''\n",
        "\n",
        "    self.model.fit(X_train, y_train.astype(int), epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "\n",
        "  def predict(self, X_test:np.array)->np.array:\n",
        "    '''predics values for validation and test'''\n",
        "    print(\"PREDICTING\")\n",
        "    X_test_padded = pad_sequences(X_test, maxlen=self.maxlen)\n",
        "    return self.model.predict(X_test_padded)\n",
        "\n",
        "\n",
        "  def evaluate(self, pred:np.array, y_test:np.array)->None:\n",
        "    '''reports statistics'''\n",
        "    loss, accuracy = self.model.evaluate(pred, y_test)\n",
        "    pred = (pred > 0.5).astype(int)\n",
        "    print(f\"Loss: {loss}\\nAccuracy: {accuracy}\")\n",
        "    print(classification_report(y_test, pred))\n",
        "\n",
        "\n",
        "  def fit_predict(self, X_train, X_test, y_train, y_test, batch=64, epochs=5):\n",
        "    '''fits data into model, predicts values and reports sttistics'''\n",
        "\n",
        "    self.fit(X_train, y_train, batch, epochs)\n",
        "    y_pred = self.predict(X_test)\n",
        "    print('\\n\\n\\n\\n\\ntest binary\\n\\n\\n\\n')\n",
        "    # Convert predicted values to binary values (0 or 1)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "    self.evaluate(y_pred_binary, y_test)"
      ],
      "metadata": {
        "id": "dnGMRpJ9Edxe"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run it"
      ],
      "metadata": {
        "id": "CaDxAODHJMOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kX_train, kX_test, ky_train, ky_test = k_process(df)\n",
        "k_tokenizer, kX_train, kX_test = k_tokenize(kX_train, kX_test)\n",
        "kX_train, kXtest = k_padme(kX_train, kX_test)\n",
        "\n",
        "kX_train = np.array(kX_train)\n",
        "kX_test = np.array(kX_test)\n",
        "ky_train = np.array(ky_train)\n",
        "ky_test = np.array(ky_test)\n"
      ],
      "metadata": {
        "id": "aFuZLDqCJV8-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bca6e33a-9237-4e51-8a17-28ffbec58f43"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-171-47ef54b04943>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  kX_test = np.array(kX_test)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_vocab_size = len(k_tokenizer.word_index) + 1    # num of unique words in all texts +1  for padding token\n",
        "k_embedding_dim = 100                             #vectors representing a word\n",
        "maxlen = 100                                      # sequence length after tokenization. too long - cut it"
      ],
      "metadata": {
        "id": "-xa12nSYJQ8u"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kLSTM = LSTMClassifier(k_vocab_size, k_embedding_dim, maxlen)\n",
        "kLSTM.fit_predict(kX_train, kX_test, ky_train, ky_test, epochs=10)"
      ],
      "metadata": {
        "id": "wl6Tuq9kKA2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try multiclass"
      ],
      "metadata": {
        "id": "LEf6go_Q1f2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class M_LSTMTextClassifier:\n",
        "    def __init__(self, num_classes=4, vocab_size=10000, embedding_dim=128, lstm_units=128):\n",
        "        self.num_classes = num_classes\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.lstm_units = lstm_units\n",
        "        self.model = self.build_model()\n",
        "\n",
        "\n",
        "    def build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim))\n",
        "        model.add(LSTM(self.lstm_units, dropout=0.2, recurrent_dropout=0.2))\n",
        "        model.add(Dense(self.num_classes, activation='softmax'))\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "\n",
        "    def preprocess_data(self, text_data, target):\n",
        "        tokenizer = Tokenizer(num_words=self.vocab_size)\n",
        "        tokenizer.fit_on_texts(text_data)\n",
        "        sequences = tokenizer.texts_to_sequences(text_data)\n",
        "        word_index = tokenizer.word_index\n",
        "\n",
        "        max_sequence_length = max([len(seq) for seq in sequences])\n",
        "        padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "        one_hot_target = tf.keras.utils.to_categorical(target, self.num_classes)\n",
        "\n",
        "        return padded_sequences, one_hot_target\n",
        "\n",
        "\n",
        "    def train(self, X_train, y_train, epochs=10, batch_size=32, validation_split=0.2):\n",
        "        history = self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split)\n",
        "        return history\n",
        "\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        return self.model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "ndGL-mai_Xpd"
      },
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm_X_y(df):\n",
        "  mtext_data = df['text']# .drop('category', axis=1) causes dimension problem when passed to the Sequential gotta find a way to solve it if added nontext cols\n",
        "  mtarget = df['category']\n",
        "  return mtext_data, mtarget\n",
        "\n",
        "def get_encoded_lstm(mtarget):\n",
        "  mlabel_encoder = LabelEncoder()\n",
        "  y = mlabel_encoder.fit_transform(mtarget)\n",
        "  return mlabel_encoder, y\n",
        "\n",
        "\n",
        "def split_lstm(params, target):\n",
        "  return train_test_split(params, target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "0L7JB9g3Vg0G"
      },
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_lstm(X_train, y_train, classnum, epochs = 10):\n",
        "  classifier = M_LSTMTextClassifier(num_classes=classnum, vocab_size=10000)\n",
        "  # Preprocess and train the model\n",
        "  X_train_processed, y_train_processed = classifier.preprocess_data(X_train, y_train)\n",
        "  classifier.train(X_train_processed, y_train_processed, epochs=epochs)\n",
        "  return classifier\n",
        "\n",
        "\n",
        "def test_lstm(classifier, label_encoder, mX_test, my_test):\n",
        "  X_test_processed, y_test_processed = classifier.preprocess_data(mX_test, my_test)\n",
        "  loss, accuracy = classifier.evaluate(X_test_processed, y_test_processed)\n",
        "  print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "  # Convert predicted labels to original class names\n",
        "  y_pred = classifier.model.predict(X_test_processed)\n",
        "  predicted_labels = np.argmax(y_pred, axis=1)\n",
        "  predicted_class_names = label_encoder.inverse_transform(predicted_labels)\n",
        "\n",
        "  # Generate classification report\n",
        "  classification_rep = classification_report(y_test_processed.argmax(axis=1), predicted_labels, target_names=label_encoder.classes_)\n",
        "  print(\"Classification Report:\")\n",
        "  print(classification_rep)\n",
        "  return\n"
      ],
      "metadata": {
        "id": "p381taOdBG7P"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mX, my = lstm_X_y(text_data)\n",
        "multi_encoder, my_labels = get_encoded_lstm(my)\n",
        "mX_train, mX_test, my_train, my_test = split_lstm(mX, my_labels)\n",
        "\n",
        "mclassifier = train_lstm(mX_train, my_train, len(multi_encoder.classes_), 10)\n",
        "\n",
        "test_lstm(mclassifier, multi_encoder, mX_test, my_test)"
      ],
      "metadata": {
        "id": "ctG78p6njEz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c00142c-a9b0-47b7-c1c1-74518b612f48"
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 26s 2s/step - loss: 1.3580 - accuracy: 0.3779 - val_loss: 1.3336 - val_accuracy: 0.3247\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 12s 1s/step - loss: 1.1648 - accuracy: 0.4788 - val_loss: 1.2021 - val_accuracy: 0.3636\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 11s 1s/step - loss: 0.9591 - accuracy: 0.5472 - val_loss: 1.1423 - val_accuracy: 0.4545\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.8248 - accuracy: 0.5993 - val_loss: 1.0557 - val_accuracy: 0.5065\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.6155 - accuracy: 0.8502 - val_loss: 0.9251 - val_accuracy: 0.7013\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.3584 - accuracy: 0.9381 - val_loss: 1.0392 - val_accuracy: 0.6753\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.5111 - accuracy: 0.7948 - val_loss: 0.9049 - val_accuracy: 0.6104\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.2105 - accuracy: 0.9511 - val_loss: 0.9143 - val_accuracy: 0.6364\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.1272 - accuracy: 0.9870 - val_loss: 0.8399 - val_accuracy: 0.7143\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 15s 1s/step - loss: 0.0747 - accuracy: 0.9935 - val_loss: 0.8108 - val_accuracy: 0.7143\n",
            "3/3 [==============================] - 1s 113ms/step - loss: 1.3704 - accuracy: 0.4688\n",
            "Test Loss: 1.3704, Test Accuracy: 0.4688\n",
            "3/3 [==============================] - 1s 108ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ads       0.40      0.34      0.37        29\n",
            "     message       0.50      0.39      0.44        18\n",
            "     project       0.47      0.61      0.53        23\n",
            "     vacancy       0.52      0.54      0.53        26\n",
            "\n",
            "    accuracy                           0.47        96\n",
            "   macro avg       0.47      0.47      0.47        96\n",
            "weighted avg       0.47      0.47      0.46        96\n",
            "\n"
          ]
        }
      ]
    }
  ]
}