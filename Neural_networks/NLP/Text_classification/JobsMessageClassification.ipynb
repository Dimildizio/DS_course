{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimildizio/DS_course/blob/main/Neural_networks/NLP/Text_classification/JobsMessageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libs"
      ],
      "metadata": {
        "id": "wlZOb4Dl-Dhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install emoji --upgrade\n",
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alxSWiApUsUd",
        "outputId": "1c1cf93c-10d3-4b8b-b0f2-1e7a3e6ba5a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.8.0\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2-cp310-cp310-manylinux2014_x86_64.whl (98.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "iF4iz0A48-vN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "import re\n",
        "import emoji\n",
        "import string\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from pymystem3 import Mystem"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrXVzNn0UzEC",
        "outputId": "f90bc319-cd5f-44bb-dd69-a101e0004522"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Freeze seeds"
      ],
      "metadata": {
        "id": "Adr7nZLtTrH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "SeqZPHCETtge"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the dataset"
      ],
      "metadata": {
        "id": "5Bc_Iah-_hm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = pd.read_excel('msg_type.xlsx')"
      ],
      "metadata": {
        "id": "GcSsofsF-dMV"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "orbCX_lh-Wj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = TweetTokenizer()"
      ],
      "metadata": {
        "id": "PCpZOGIf-Wy0"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming"
      ],
      "metadata": {
        "id": "Qz286hbW-pdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = SnowballStemmer(\"russian\")"
      ],
      "metadata": {
        "id": "Eau245xn_Q4N"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmaization"
      ],
      "metadata": {
        "id": "gQ-tCd_W_r8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mystem = Mystem()"
      ],
      "metadata": {
        "id": "rAdp3V8i_tpg"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorize using TFIDF"
      ],
      "metadata": {
        "id": "dXTCd6Lb_3DU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords.words('russian'))"
      ],
      "metadata": {
        "id": "9bS02FX5_5F0"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split dataset to parameters and encode target labels"
      ],
      "metadata": {
        "id": "nyQPCc1bC7Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = text_data.copy()\n",
        "df['category'] = df['category'].replace({'ads': 'message', 'project': 'vacancy'})\n"
      ],
      "metadata": {
        "id": "9VEDUqDtC-jq"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['category']"
      ],
      "metadata": {
        "id": "Y6hVYWNpv979",
        "outputId": "0a76b7bb-dc09-42e8-cc3f-d053bc02d805",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      message\n",
              "1      message\n",
              "2      message\n",
              "3      message\n",
              "4      message\n",
              "        ...   \n",
              "475    vacancy\n",
              "476    vacancy\n",
              "477    vacancy\n",
              "478    vacancy\n",
              "479    vacancy\n",
              "Name: category, Length: 480, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Label encode categories"
      ],
      "metadata": {
        "id": "PdmxZUdeVnlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "encoded_target = label_encoder.fit_transform(df['category'])"
      ],
      "metadata": {
        "id": "hzhggYegVrIY"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split into params and target values"
      ],
      "metadata": {
        "id": "wRqIDsNJV4Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text']\n",
        "y = encoded_target"
      ],
      "metadata": {
        "id": "e0-QiBASVlxW"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform transformation on df"
      ],
      "metadata": {
        "id": "egQ65yKOCyux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emoji(text: str) -> str:\n",
        "    return emoji.replace_emoji(text, \" \")\n",
        "\n",
        "\n",
        "def remove_links(text: str) -> str:\n",
        "    return re.sub(r\"http\\S+\", \" \", text, flags=re.MULTILINE)\n",
        "\n",
        "\n",
        "def remove_usernames_and_emails(text: str) -> str:\n",
        "    \"\"\"Удалеяет юзернеймы и email\"\"\"\n",
        "    return re.sub(r\"\\S*@\\S*\", \" \", text, flags=re.MULTILINE)\n",
        "\n",
        "\n",
        "def remove_punctuation(text: str) -> str:\n",
        "    \"\"\"Удаляем символы пунктуации\"\"\"\n",
        "    return \"\".join([ch if ch not in string.punctuation else \" \" for ch in text])\n",
        "\n",
        "\n",
        "def remove_numbers(text: str) -> str:\n",
        "    \"\"\"Удаляем числа\"\"\"\n",
        "    return \"\".join([i if not i.isdigit() else \" \" for i in text])\n",
        "\n",
        "\n",
        "def remove_multiple_spaces(text: str) -> str:\n",
        "    \"\"\"Удаляем двойные (и более) пробелы\"\"\"\n",
        "    return re.sub(r\"\\s+\", \" \", text, flags=re.I)"
      ],
      "metadata": {
        "id": "kvAuLGg2DeLL"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prep_text(text: str) -> str:\n",
        "  return remove_multiple_spaces(\n",
        "      remove_numbers(\n",
        "          remove_punctuation(\n",
        "              remove_usernames_and_emails(\n",
        "                  remove_links(\n",
        "                      remove_emoji(text)\n",
        "                      )\n",
        "                  )\n",
        "              )\n",
        "          )\n",
        "      )"
      ],
      "metadata": {
        "id": "Ze1Dd5irEFH8"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#our new dataset with stemmed lemmatized and later vectorized texts\n",
        "stemmed_lemma_txts = []\n",
        "\n",
        "for text in X:\n",
        "  tok = tokenizer.tokenize(get_prep_text(text).lower())\n",
        "  stem_tok = [stemmer.stem(token) for token in tok]\n",
        "  # lem_tok = [lem for lem in mystem.lemmatize(\" \".join(stem_tok)) if not lem.isspace()]\n",
        "  # stemmed_lemma_txts.append(' '.join(lem_tok))\n",
        "  stemmed_lemma_txts.append(' '.join(stem_tok))\n",
        "\n",
        "df['text_lemm'] = stemmed_lemma_txts"
      ],
      "metadata": {
        "id": "_AoklUd1CyQu"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TFIDF Vectorize"
      ],
      "metadata": {
        "id": "ao8AJx7yD188"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidfd = tfidf_vectorizer.fit_transform(stemmed_lemma_txts)"
      ],
      "metadata": {
        "id": "TPetowxrD0BS"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split dataset"
      ],
      "metadata": {
        "id": "EPEBSiRxAGHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pass tfidf'd and transfromed data instead of texts as X"
      ],
      "metadata": {
        "id": "pS8tzS8AVK66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tfidfd, y, stratify=y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "3FHZ9SUyAHx-"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "7HX96oveEee1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and train baseline model"
      ],
      "metadata": {
        "id": "ZshtoMLyAgcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(C=0.004)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "JzH_z-mPADkt",
        "outputId": "9b1f4b7c-20c4-45bc-d6e2-844f0cd90c24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.004)"
            ],
            "text/html": [
              "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.004)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.004)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict"
      ],
      "metadata": {
        "id": "Sy2G_blXEcE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "-gapxEVgAfrY"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate"
      ],
      "metadata": {
        "id": "n1Dd5275EjjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy"
      ],
      "metadata": {
        "id": "bS6NmFkhEvw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy:', acc)"
      ],
      "metadata": {
        "id": "UGsDgjo8El3O",
        "outputId": "1e7953fd-94eb-49f9-c2af-78d053832949",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Report"
      ],
      "metadata": {
        "id": "bC_2nOceExNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "G3_u5H3RE2ne",
        "outputId": "e18f317e-ef6f-4905-e387-f15cacec2561",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93        60\n",
            "           1       0.95      0.92      0.93        60\n",
            "\n",
            "    accuracy                           0.93       120\n",
            "   macro avg       0.93      0.93      0.93       120\n",
            "weighted avg       0.93      0.93      0.93       120\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sum it up"
      ],
      "metadata": {
        "id": "QJXTDgm66jBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Catboost"
      ],
      "metadata": {
        "id": "l75Q3u20xSLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_model = CatBoostClassifier(iterations=300, depth=6, learning_rate=0.1, loss_function='MultiClass', verbose=False)\n",
        "cat_model.fit(X_train, y_train, eval_set=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRD3V3L5puaX",
        "outputId": "a7cba2da-9e74-449b-9a63-e68d391a6e0c"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7c91302dbd30>"
            ]
          },
          "metadata": {},
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_pred, y_test)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "class_names = ['0','1']\n",
        "report = classification_report(y_test, y_pred, target_names=class_names)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB79wrrDsBmo",
        "outputId": "1609bb53-7598-49f4-9fc0-83c1133fe74c"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.93\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93        60\n",
            "           1       0.95      0.92      0.93        60\n",
            "\n",
            "    accuracy                           0.93       120\n",
            "   macro avg       0.93      0.93      0.93       120\n",
            "weighted avg       0.93      0.93      0.93       120\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model):\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  print('Accuracy:', acc)\n",
        "  print(\"Classification Report:\")\n",
        "  print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "Y_7ouuCQ6iXJ"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_model = LogisticRegression(C=0.004)\n",
        "nb_model = MultinomialNB()\n",
        "svm_model = SVC(kernel='linear', random_state=42, gamma=\"auto\", probability=True)\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "ensemble = VotingClassifier(estimators=[\n",
        "                              ('rf', rf_model),\n",
        "                              ('svm', svm_model),\n",
        "                              ('xgb', xgb_model)],\n",
        "                            voting='soft')        # soft for probability-based voting\n",
        "\n",
        "rfensemble = VotingClassifier(estimators=[\n",
        "                              ('rf', rf_model),\n",
        "                              ('svm', svm_model),\n",
        "                              ('rf1', RandomForestClassifier(n_estimators=100, random_state=42))],\n",
        "                            voting='hard')\n",
        "\n",
        "models = [log_model, nb_model, svm_model, rf_model, xgb_model, knn_model, ensemble,rfensemble]\n",
        "model_names = ['logreg', 'bayes', 'SVM', 'RandomForest', 'XGB', 'KNN', 'Ensemble', 'RF_ensemble']"
      ],
      "metadata": {
        "id": "AC9Hns0G68Qs"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(models)):\n",
        "  print(model_names[i])\n",
        "  print()\n",
        "  test_model(models[i])\n",
        "  print('\\n\\n')"
      ],
      "metadata": {
        "id": "TYOo_QZ98p01",
        "outputId": "ecc813ab-e5cf-4497-a83d-b2990be259a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logreg\n",
            "\n",
            "Accuracy: 0.9333333333333333\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93        60\n",
            "           1       0.95      0.92      0.93        60\n",
            "\n",
            "    accuracy                           0.93       120\n",
            "   macro avg       0.93      0.93      0.93       120\n",
            "weighted avg       0.93      0.93      0.93       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bayes\n",
            "\n",
            "Accuracy: 0.8916666666666667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.82      0.88        60\n",
            "           1       0.84      0.97      0.90        60\n",
            "\n",
            "    accuracy                           0.89       120\n",
            "   macro avg       0.90      0.89      0.89       120\n",
            "weighted avg       0.90      0.89      0.89       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "SVM\n",
            "\n",
            "Accuracy: 0.9416666666666667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94        60\n",
            "           1       0.95      0.93      0.94        60\n",
            "\n",
            "    accuracy                           0.94       120\n",
            "   macro avg       0.94      0.94      0.94       120\n",
            "weighted avg       0.94      0.94      0.94       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RandomForest\n",
            "\n",
            "Accuracy: 0.9583333333333334\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96        60\n",
            "           1       0.98      0.93      0.96        60\n",
            "\n",
            "    accuracy                           0.96       120\n",
            "   macro avg       0.96      0.96      0.96       120\n",
            "weighted avg       0.96      0.96      0.96       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "XGB\n",
            "\n",
            "Accuracy: 0.9083333333333333\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.92      0.91        60\n",
            "           1       0.92      0.90      0.91        60\n",
            "\n",
            "    accuracy                           0.91       120\n",
            "   macro avg       0.91      0.91      0.91       120\n",
            "weighted avg       0.91      0.91      0.91       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "KNN\n",
            "\n",
            "Accuracy: 0.8333333333333334\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.82      0.83        60\n",
            "           1       0.82      0.85      0.84        60\n",
            "\n",
            "    accuracy                           0.83       120\n",
            "   macro avg       0.83      0.83      0.83       120\n",
            "weighted avg       0.83      0.83      0.83       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Ensemble\n",
            "\n",
            "Accuracy: 0.9416666666666667\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94        60\n",
            "           1       0.93      0.95      0.94        60\n",
            "\n",
            "    accuracy                           0.94       120\n",
            "   macro avg       0.94      0.94      0.94       120\n",
            "weighted avg       0.94      0.94      0.94       120\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "RF_ensemble\n",
            "\n",
            "Accuracy: 0.9583333333333334\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96        60\n",
            "           1       0.98      0.93      0.96        60\n",
            "\n",
            "    accuracy                           0.96       120\n",
            "   macro avg       0.96      0.96      0.96       120\n",
            "weighted avg       0.96      0.96      0.96       120\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder.inverse_transform([0, 1])"
      ],
      "metadata": {
        "id": "FXRPVw4xjZSm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f85d7b-d9dd-4831-b305-2055e456ec80"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['message', 'vacancy'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Add Stacking of models"
      ],
      "metadata": {
        "id": "qQe_zR4VkwO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_models = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)),\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42)),\n",
        "    ('svm', SVC(kernel='linear', random_state=42, gamma=\"auto\", probability=True)),\n",
        "     ('logreg', LogisticRegression(C=0.0045)),\n",
        "    ('xgb', xgb.XGBClassifier())]\n",
        "final_model = RandomForestClassifier(n_estimators=100, max_depth=7, random_state=42)\n",
        "\n",
        "stacking_model = StackingClassifier(estimators=base_models, final_estimator=final_model)\n",
        "test_model(stacking_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANjUw6m3hK1Q",
        "outputId": "6a730a39-22db-457c-db3b-6ee1ed8e89af"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9583333333333334\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96        60\n",
            "           1       0.97      0.95      0.96        60\n",
            "\n",
            "    accuracy                           0.96       120\n",
            "   macro avg       0.96      0.96      0.96       120\n",
            "weighted avg       0.96      0.96      0.96       120\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural networks solution"
      ],
      "metadata": {
        "id": "sTYi4nuJB2A_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### import NN stuff"
      ],
      "metadata": {
        "id": "TMCtBxEsJFvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras.utils import pad_sequences"
      ],
      "metadata": {
        "id": "RAOb_m7gIVf9"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "LgJOFcxcB5gw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prerocessing"
      ],
      "metadata": {
        "id": "jzuTUm2CCBVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data"
      ],
      "metadata": {
        "id": "1POaf7K8C-Cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_lemm'][0]"
      ],
      "metadata": {
        "id": "EuLXF6KhM_hq",
        "outputId": "463a4349-7082-49c4-8f98-b69462de4382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ищ эксперт кто хочет продава сво услуг быстр и легк привет я ол графическ и веб дизайнер эксперт я созда лаконичн с правильн структур и собствен вайб сайт для эксперт на taplink вся нужн и важн информац собра в одн мест чтоб ваш клиент проход минимальн пут к покупк чтоб узна подробн пиш в лс сотрудничеств'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def k_process(df):\n",
        "  X = df['text_lemm'].copy()\n",
        "  y = df['category'].copy()\n",
        "  return train_test_split(X, y, stratify=y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "BxG3kH1UCCny"
      },
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize"
      ],
      "metadata": {
        "id": "3d_JVJ1NCXF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def k_tokenize(x1, x2):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(x1)\n",
        "\n",
        "  x_train = tokenizer.texts_to_sequences(x1)\n",
        "  x_test = tokenizer.texts_to_sequences(x2)\n",
        "\n",
        "  return tokenizer, x_train, x_test"
      ],
      "metadata": {
        "id": "pzYvag2QCR0A"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add padding"
      ],
      "metadata": {
        "id": "th0cjU-yDWQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def k_padme(x1, x2, maxlen=100):\n",
        "  x_train = pad_sequences(x1, maxlen=maxlen, padding='post')\n",
        "  x_test = pad_sequences(x2, maxlen=maxlen, padding='post')\n",
        "  return x_train, x_test"
      ],
      "metadata": {
        "id": "_Gh0rzlmDXsC"
      },
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create model"
      ],
      "metadata": {
        "id": "55tAGeDeDoy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMClassifier:\n",
        "  def __init__(self, vocab_size, embedding_dim, maxlen):\n",
        "    self.vocab = vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.maxlen = maxlen\n",
        "    self.model = self._create_model()\n",
        "\n",
        "  def _create_model(self)->Sequential:\n",
        "    '''creates lstm with embedding, rnn and classificator'''\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=self.vocab, output_dim=self.embedding_dim, input_length=self.maxlen))\n",
        "    model.add(LSTM(units=64))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "  def fit(self, X_train:np.array, y_train:np.array, batch_size:int=64, epochs:int=5)->None:\n",
        "    '''trains model'''\n",
        "    self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "\n",
        "  def predict(self, X_test:np.array)->np.array:\n",
        "    '''predics values for validation and test'''\n",
        "    return self.model.predict(X_test)\n",
        "\n",
        "\n",
        "  def evaluate(self, pred:np.array, y_test:np.array)->None:\n",
        "    '''reports statistics'''\n",
        "    loss, accuracy = self.model.evaluate(pred, y_test)\n",
        "    pred = (pred > 0.5).astype(int)\n",
        "    print(f\"Loss: {loss}\\nAccuracy: {accuracy}\")\n",
        "    print(classification_report(y_test, pred))\n",
        "\n",
        "\n",
        "  def fit_predict(self, X_train, X_test, y_train, y_test, batch=64, epochs=5):\n",
        "    '''fits data into model, predicts values and reports sttistics'''\n",
        "    self.fit(X_train, y_train, batch, epochs)\n",
        "    y_pred = self.predcit(X_test)\n",
        "    self.evaluate(y_pred, y_test)"
      ],
      "metadata": {
        "id": "dnGMRpJ9Edxe"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run it"
      ],
      "metadata": {
        "id": "CaDxAODHJMOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kX_train, kX_test, ky_train, ky_test = k_process(df)\n",
        "k_tokenizer, kX_train, kX_test = k_tokenize(kX_train, kX_test)\n",
        "kX_train, kXtest = k_padme(kX_train, kX_test)"
      ],
      "metadata": {
        "id": "aFuZLDqCJV8-"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_vocab_size = len(k_tokenizer.word_index) + 1    # num of unique words in all texts +1  for padding token\n",
        "k_embedding_dim = 100                             #vectors representing a word\n",
        "maxlen = 100                                      # sequence length after tokenization. too long - cut it"
      ],
      "metadata": {
        "id": "-xa12nSYJQ8u"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kLSTM = LSTMClassifier(k_vocab_size, k_embedding_dim, maxlen)\n",
        "kLSTM.fit_predict(kX_train, kX_test, ky_train, ky_test)"
      ],
      "metadata": {
        "id": "wl6Tuq9kKA2S",
        "outputId": "65fc8a6b-5557-46e5-f1bf-05ca08b1b392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-260-9b96051a07f4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkLSTM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_embedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkLSTM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mky_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mky_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-257-f6b02d359a37>\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X_train, X_test, y_train, y_test, batch, epochs)\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;34m'''fits data into model, predicts values and reports sttistics'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredcit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-257-f6b02d359a37>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, batch_size, epochs)\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m'''trains model'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'binary_crossentropy/Cast' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-260-9b96051a07f4>\", line 2, in <cell line: 2>\n      kLSTM.fit_predict(kX_train, kX_test, ky_train, ky_test)\n    File \"<ipython-input-257-f6b02d359a37>\", line 38, in fit_predict\n      self.fit(X_train, y_train, batch, epochs)\n    File \"<ipython-input-257-f6b02d359a37>\", line 20, in fit\n      self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 2145, in binary_crossentropy\n      y_true = tf.cast(y_true, y_pred.dtype)\nNode: 'binary_crossentropy/Cast'\nCast string to float is not supported\n\t [[{{node binary_crossentropy/Cast}}]] [Op:__inference_train_function_6913]"
          ]
        }
      ]
    }
  ]
}