{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMT9Mbr/zGzTdoFF0n/q73z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimildizio/DS_course/blob/main/Neural_networks/NLP/Text_classification/Prohibited_language_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prohibited Language classification"
      ],
      "metadata": {
        "id": "0HYYwt0GNw7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification of foul language task using Bag of Words embeddings, TF-IDF, word vectors\n"
      ],
      "metadata": {
        "id": "Gg_X6uTiO44Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "7LL86MGUP7pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as gensim_api\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "KzKjaclUNz5j"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "qau-zciSOJEb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "w38XUUF7P9ZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/Dimildizio/DS_course/main/Neural_networks/NLP/Text_classification/data/comments.tsv"
      ],
      "metadata": {
        "id": "RbLjVYt7QDLr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IJJsAuv-Nvnl"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('comments.tsv', sep='\\t')"
      ]
    }
  ]
}