{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOECPgQ5SlM61Uyd3ri61Q6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimildizio/DS_course/blob/main/Neural_networks/NLP/Text_classification/places_rating_comments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comments rating classification"
      ],
      "metadata": {
        "id": "MgbY4XUfv1Dt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## download libs"
      ],
      "metadata": {
        "id": "yVeWKMin2H4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install nltk gensim wandb"
      ],
      "metadata": {
        "id": "2KQsNDf52A7A"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## imports"
      ],
      "metadata": {
        "id": "aQ_5oUMLzXGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import wandb\n",
        "\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "from nltk.tokenize import word_tokenize\n",
        "from pymystem3 import Mystem\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import List, Dict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "from torch.nn.utils.rnn import pack_sequence, PackedSequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.multiprocessing import Pool\n",
        "\n",
        "#from functools import partial"
      ],
      "metadata": {
        "id": "4MaZrN7ivwhh"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGItDiYQ2Iqt",
        "outputId": "f2b31cd9-64fb-4382-a730-cd36199dfb61"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "gensim_model = api.load(\"word2vec-ruscorpora-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlK3ummHOgHa",
        "outputId": "ccc5f886-5963-4e0e-f234-b36bd64afca9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 198.8/198.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set WandB"
      ],
      "metadata": {
        "id": "yrVD6nZ63HBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb_config = {\n",
        "    'achitecture':'biLSTM',\n",
        "    'dropout':0.18,\n",
        "    'hid_layers':2,\n",
        "    'hid_size':64,\n",
        "    'activation':'relu',\n",
        "    'optimizer':'AdamW',\n",
        "    'lr':4e-3,\n",
        "    'epochs':10,\n",
        "    'train_batch':128\n",
        "}"
      ],
      "metadata": {
        "id": "okpCbLai0oDp"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WANDBAPI = False\n",
        "try:\n",
        "  with open('wandb_api.txt', 'r') as f:\n",
        "    WANDBAPI = f.readline()\n",
        "    project=\"\"\n",
        "    entity=''\n",
        "    wandb.login(key=WANDBAPI)\n",
        "\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "id": "zaGrl8H4xlp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wandb_wrapper(func):\n",
        "    def wrapped_function(*args, **kwargs):\n",
        "        if WANDBAPI:\n",
        "            wandb.init(project=project,entity=entity, config=wandb_config)\n",
        "\n",
        "        result = func(*args, **kwargs)\n",
        "        if WANDBAPI:\n",
        "            wandb.finish()\n",
        "        return result\n",
        "    return wrapped_function"
      ],
      "metadata": {
        "id": "qSykkajO-7yW"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load data"
      ],
      "metadata": {
        "id": "yiWM9OoszY_W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "typckxywn04R"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/Dimildizio/DS_course/main/Neural_networks/NLP/Text_classification/data/train_reviews.csv\n",
        "\n",
        "!wget https://raw.githubusercontent.com/Dimildizio/DS_course/main/Neural_networks/NLP/Text_classification/data/test_reviews.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trdf = pd.read_csv('train_reviews.csv')\n",
        "test_df = pd.read_csv('test_reviews.csv')"
      ],
      "metadata": {
        "id": "-le90E87wAg1"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trdf.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bhaCbpko1vPi",
        "outputId": "43310d04-0dd9-4965-e063-849c327b76f9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       rate                                               text\n",
              "19083     2  –û—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ –æ–±—Å–ª—É–∂–∏–≤–∞—é—Ç. –†–∞–±–æ—Ç–∞–µ—Ç –æ–¥–Ω–∞ –∫–∞—Å—Å...\n",
              "32953     4  –•–æ—Ä–æ—à–æ, —á—Ç–æ –≤ –º–∞–≥–∞–∑–∏–Ω–∞—Ö –ø–æ—è–≤–∏–ª–∏—Å—å –∫–∞—Å—Å—ã —Å–∞–º–æ–æ–±...\n",
              "24674     5  –î–∏—Ä–µ–∫—Ç–æ—Ä –ù–∞—Ç–∞–ª—å—è –í—è—á–µ—Å–ª–∞–≤–æ–≤–Ω–∞ –æ–≥–æ–Ω—å –ø—Ä–æ—Å—Ç–æ)) –¥...\n",
              "4975      5         –í—Å–µ–≥–¥–∞ –≤–µ–∂–ª–∏–≤—ã–µ –ø—Ä–æ–¥–∞–≤—Ü—ã –∏ —Ö–æ—Ä–æ—à–∏–π —Ç–æ–≤–∞—Ä üåπ\n",
              "40249     5              –ë–æ–ª—å—à–æ–π –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç, –≤–µ–∂–ª–∏–≤—ã–µ –∫–∞—Å—Å–∏—Ä—ã"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bcef1b68-2319-4764-be4e-9d529a4faceb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rate</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19083</th>\n",
              "      <td>2</td>\n",
              "      <td>–û—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ –æ–±—Å–ª—É–∂–∏–≤–∞—é—Ç. –†–∞–±–æ—Ç–∞–µ—Ç –æ–¥–Ω–∞ –∫–∞—Å—Å...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32953</th>\n",
              "      <td>4</td>\n",
              "      <td>–•–æ—Ä–æ—à–æ, —á—Ç–æ –≤ –º–∞–≥–∞–∑–∏–Ω–∞—Ö –ø–æ—è–≤–∏–ª–∏—Å—å –∫–∞—Å—Å—ã —Å–∞–º–æ–æ–±...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24674</th>\n",
              "      <td>5</td>\n",
              "      <td>–î–∏—Ä–µ–∫—Ç–æ—Ä –ù–∞—Ç–∞–ª—å—è –í—è—á–µ—Å–ª–∞–≤–æ–≤–Ω–∞ –æ–≥–æ–Ω—å –ø—Ä–æ—Å—Ç–æ)) –¥...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4975</th>\n",
              "      <td>5</td>\n",
              "      <td>–í—Å–µ–≥–¥–∞ –≤–µ–∂–ª–∏–≤—ã–µ –ø—Ä–æ–¥–∞–≤—Ü—ã –∏ —Ö–æ—Ä–æ—à–∏–π —Ç–æ–≤–∞—Ä üåπ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40249</th>\n",
              "      <td>5</td>\n",
              "      <td>–ë–æ–ª—å—à–æ–π –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç, –≤–µ–∂–ª–∏–≤—ã–µ –∫–∞—Å—Å–∏—Ä—ã</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcef1b68-2319-4764-be4e-9d529a4faceb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bcef1b68-2319-4764-be4e-9d529a4faceb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bcef1b68-2319-4764-be4e-9d529a4faceb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cb042950-8d45-41ab-b159-42983773cafb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb042950-8d45-41ab-b159-42983773cafb')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cb042950-8d45-41ab-b159-42983773cafb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## set target in range 0:x"
      ],
      "metadata": {
        "id": "Vjs_iM1OzbHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trdf['rate'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r24pNgsxwi-K",
        "outputId": "16dbed82-6150-43e2-c54f-86080665fd8b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    26069\n",
              "4     9922\n",
              "3     6126\n",
              "1     4138\n",
              "2     2410\n",
              "Name: rate, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def norm_target(df, to_train=True):\n",
        "  num = -1 if to_train else 1\n",
        "  dfr = df.copy()\n",
        "  dfr['rate'] = dfr['rate'] + num\n",
        "  return dfr"
      ],
      "metadata": {
        "id": "88Wn_5m7zjnO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = norm_target(trdf)"
      ],
      "metadata": {
        "id": "SnSgOafCworY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tokenize"
      ],
      "metadata": {
        "id": "asJpzJBK2dmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(text, lang='russian'):\n",
        "    tokens = word_tokenize(text, language=lang)\n",
        "    return [token for token in tokens if token.isalpha()]"
      ],
      "metadata": {
        "id": "iZhb0E212X2C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tok_txt = [tokenize_text(t) for t in train_df.text.values]"
      ],
      "metadata": {
        "id": "4hxxgynM1-Vu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### create vocab"
      ],
      "metadata": {
        "id": "5l6JTiPF3E5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Voc:\n",
        "  def __init__(self, txt, vocab_size):\n",
        "    toks = [tok for word in txt for tok in word]\n",
        "    tok_dict = Counter(toks)\n",
        "    self.tokens = [tok for tok, num in tok_dict.most_common(vocab_size)]"
      ],
      "metadata": {
        "id": "zQeL6uwc3G9d"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = Voc(tok_txt, 350000)\n",
        "vocabulary.tokens[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbEK9Izb4P_l",
        "outputId": "d80a0990-a92c-4ccf-e1c3-765de8514243"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['–∏',\n",
              " '–Ω–µ',\n",
              " '–≤',\n",
              " '–º–∞–≥–∞–∑–∏–Ω',\n",
              " '–Ω–∞',\n",
              " '—Å',\n",
              " '—á—Ç–æ',\n",
              " '–Ω–æ',\n",
              " '–≤—Å–µ–≥–¥–∞',\n",
              " '–µ—Å—Ç—å',\n",
              " '–æ—á–µ–Ω—å',\n",
              " '–ø–æ',\n",
              " '–ø–µ—Ä—Å–æ–Ω–∞–ª',\n",
              " '–∫–∞–∫',\n",
              " '–≤—Å–µ',\n",
              " '–∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç',\n",
              " '–•–æ—Ä–æ—à–∏–π',\n",
              " '–Ω–µ—Ç',\n",
              " '–∞',\n",
              " '—Å–∞–º–æ–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split"
      ],
      "metadata": {
        "id": "6_2gFMl8-flA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_df.drop('rate', axis=1)\n",
        "y = train_df['rate']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "UzHE8PjR8eip"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preset funcs for rnn"
      ],
      "metadata": {
        "id": "HkFfD-wf8far"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "copied"
      ],
      "metadata": {
        "id": "Qv-3eojCABn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self, word_pattern=\"[\\w']+\"):\n",
        "        \"\"\"\n",
        "        Simple tokenizer that splits the sentence by given regex pattern\n",
        "        :param word_pattern: pattern that determines word boundaries\n",
        "        \"\"\"\n",
        "        self.word_pattern = re.compile(word_pattern)\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        return self.word_pattern.findall(text)\n",
        "\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self, tokenized_texts: List[List[str]], max_vocab_size=None):\n",
        "        \"\"\"\n",
        "        Builds a vocabulary by concatenating all tokenized texts and counting words.\n",
        "        Most common words are placed in vocabulary, others are replaced with [UNK] token\n",
        "        :param tokenized_texts: texts to build a vocab\n",
        "        :param max_vocab_size: amount of words in vocabulary\n",
        "        \"\"\"\n",
        "        counts = Counter(chain(*tokenized_texts))\n",
        "        max_vocab_size = max_vocab_size or len(counts)\n",
        "        common_pairs = counts.most_common(max_vocab_size)\n",
        "        self.PAD_IDX = 0\n",
        "        self.UNK_IDX = 1\n",
        "        self.EOS_IDX = 2\n",
        "        self.itos = [\"<PAD>\", \"<UNK>\", \"<EOS>\"] + [pair[0]\n",
        "                                                   for pair in common_pairs]\n",
        "        self.stoi = {token: i for i, token in enumerate(self.itos)}\n",
        "\n",
        "    def vectorize(self, text: List[str]):\n",
        "        \"\"\"\n",
        "        Maps each token to it's index in the vocabulary\n",
        "        :param text: sequence of tokens\n",
        "        :return: vectorized sequence\n",
        "        \"\"\"\n",
        "        return [self.stoi.get(tok, self.UNK_IDX) for tok in text]\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.itos)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, tokenized_texts, labels, vocab: Vocab):\n",
        "        \"\"\"\n",
        "        A Dataset for the task\n",
        "        :param tokenized_texts: texts from a train/val/test split\n",
        "        :param labels: corresponding toxicity ratings\n",
        "        :param vocab: vocabulary with indexed tokens\n",
        "        \"\"\"\n",
        "        self.texts = tokenized_texts\n",
        "        self.labels = labels\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return (\n",
        "            self.vocab.vectorize(self.texts[item]) + [self.vocab.EOS_IDX],\n",
        "            self.labels[item],\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        \"\"\"\n",
        "        Technical method to form a batch to feed into recurrent network\n",
        "        \"\"\"\n",
        "        tmp = pack_sequence(\n",
        "            [torch.tensor(pair[0]) for pair in batch], enforce_sorted=False\n",
        "        ), torch.tensor([pair[1] for pair in batch])\n",
        "        return tmp\n",
        "\n",
        "\n",
        "def custom_train_test_split(data, train_frac=0.85):\n",
        "    \"\"\"\n",
        "    Splits the data into train and test parts, stratifying by labels.\n",
        "    Should it shuffle the data before split?\n",
        "    :param data: dataset to split\n",
        "    :param train_frac: proportion of train examples\n",
        "    :return: texts and labels for each split\n",
        "    \"\"\"\n",
        "    n_toxicity_ratings = 5\n",
        "    train_labels = []\n",
        "    val_labels = []\n",
        "    train_texts = []\n",
        "    val_texts = []\n",
        "    for label in range(n_toxicity_ratings):\n",
        "        texts = data[data.rate == label].text.values\n",
        "        n_train = int(len(texts) * train_frac)\n",
        "        n_val = len(texts) - n_train\n",
        "        train_texts.extend(texts[:n_train])\n",
        "        val_texts.extend(texts[n_train:])\n",
        "        train_labels += [label] * n_train\n",
        "        val_labels += [label] * n_val\n",
        "    return train_texts, train_labels, val_texts, val_labels"
      ],
      "metadata": {
        "id": "yNMu4cOh8fv6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tok = Tokenizer()\n",
        "vocab = Vocab([tok.tokenize(t) for t in train_df.text.values], 30000)\n",
        "train_texts, train_labels, val_texts, val_labels = custom_train_test_split(train_df)\n",
        "\n",
        "\n",
        "train_dataset = TextDataset([tok.tokenize(t) for t in train_texts],\n",
        "                            train_labels,\n",
        "                            vocab)\n",
        "val_dataset = TextDataset([tok.tokenize(t) for t in val_texts],\n",
        "                          val_labels,\n",
        "                          vocab)"
      ],
      "metadata": {
        "id": "OTCcryCp_Wp1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts[42]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "QJnH3zkX4eB2",
        "outputId": "6f086250-f2db-4df2-c6ab-385c169f3614"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'–ù–∞ –¥–Ω—è—Ö –∑–∞—à—ë–ª –∫—É–ø–∏—Ç—å –≤ —ç—Ç–æ—Ç –º–∞–≥–∞–∑–∏–Ω —Å–∏–≥–∞—Ä–µ—Ç , —Ç–∞–∫ –∂–µ —Ö–æ—Ç–µ–ª –∫—É–ø–∏—Ç—å –∏–∫—Ä—ã , —á—Ç–æ —Å—Ç–æ–∏—Ç –≤ —Ö–æ–ª–æ–¥–∏–ª—å–Ω–∏–∫–µ –±–ª–∏–∂–µ –∫ –∫–∞—Å–µ–µ \"–∞–ª–∫–æ–≥–æ–ª—è –∏ —Ç–∞–±–∞–∫–∞\", –Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ–≤ —á—Ç–æ –∫–∞—á–µ—Å—Ç–≤–æ –∏–∫—Ä—ã –Ω–µ –æ—á–µ–Ω—å , –ø–æ—Å—Ç–∞–≤–∏–ª –±–∞–Ω–∫—É –æ–±—Ä–∞—Ç–Ω–æ . –ü–æ—Å–ª–µ –ø–æ–∫—É–ø–∫–∏ —Å–∏–≥–∞—Ä–µ—Ç –Ω–∞ –∫–∞—Å—Å–µ , –º–µ–Ω—è –æ—Å—Ç–∞–Ω–æ–≤–∏–ª –Ω–µ –ø–æ–Ω—è—Ç–Ω–∞—è –ª–∏—á–Ω–æ –Ω–µ —Å–ª–∞–≤—è–Ω—Å–∫–æ–π –≤–Ω–µ—à–Ω–æ—Å—Ç–∏ ... –∏ —Å–æ —Å–ª–æ–≤–∞–º–∏ \"—ç–π —Ç—ã ... –≥–¥–µ –∏–∫—Ä–∞ , –≤—ã–≤–æ—Ä–∞—á–∏–≤–∞–π –∫–∞—Ä–º–∞–Ω—ã\" –≤–æ—Ç –≤–∞–º –∏ –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è –∏ –≤–µ–∂–ª–∏–≤–æ—Å—Ç—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ . )'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TAG_MAPPING = {'A': 'ADJ',\n",
        "               'ADV': 'ADV',\n",
        "               'ADVPRO': 'ADV',\n",
        "               'ANUM': 'ADJ',\n",
        "               'APRO': 'DET',\n",
        "               'COM': 'ADJ',\n",
        "               'CONJ': 'SCONJ',\n",
        "               'INTJ': 'INTJ',\n",
        "               'NONLEX': 'X',\n",
        "               'NUM': 'NUM',\n",
        "               'PART': 'PART',\n",
        "               'PR': 'ADP',\n",
        "               'S': 'NOUN',\n",
        "               'SPRO': 'PRON',\n",
        "               'UNKN': 'X',\n",
        "               'V': 'VERB'}"
      ],
      "metadata": {
        "id": "OnENqO9Z203X"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingProcessor:\n",
        "  def __init__(self, gensim_model):\n",
        "      self.model = gensim_model\n",
        "      self.mean = self.model.vectors.mean(1).mean()\n",
        "      self.std = self.model.vectors.std(1).mean()\n",
        "      self.vec_size = self.model.vector_size\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def get_universal_tag(word):\n",
        "      m = Mystem()\n",
        "      processed = m.analyze(word)[0]\n",
        "      lemma = processed[\"analysis\"][0][\"lex\"].lower().strip()\n",
        "      pos = processed[\"analysis\"][0][\"gr\"].split(',')[0]\n",
        "      pos = pos.split('=')[0].strip()\n",
        "      tagged = lemma + '_' + pos\n",
        "      return tagged\n",
        "\n",
        "\n",
        "  def process_word(self, idx, word):\n",
        "      try:\n",
        "        tagged = self.add_tag(word)\n",
        "        vector = self.model.get_vector(tagged)\n",
        "        return idx, torch.tensor(vector)\n",
        "      except Exception as e:\n",
        "        random_vector = torch.randn(self.vec_size) * self.std + self.mean\n",
        "        return idx, random_vector\n",
        "\n",
        "\n",
        "  def add_tag(self, word):\n",
        "      word = self.get_universal_tag(word)\n",
        "      tag = word.split('_')[1]\n",
        "      tag = TAG_MAPPING.get(tag, tag)\n",
        "\n",
        "      word = word.split('_')[0] + '_' + tag\n",
        "      return word"
      ],
      "metadata": {
        "id": "qTpLm_ja9iHt"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiproc_emb(mymodel, vocab, n_processes=3):\n",
        "  matrix = torch.zeros(len(vocab), mymodel.vec_size)\n",
        "\n",
        "  with Pool(processes=n_processes) as p:\n",
        "    arguments = [(idx, word) for idx, word in enumerate(vocab.itos[:1], 1)]\n",
        "    embs = p.starmap(mymodel.process_word, arguments)\n",
        "  for idx, emb in embs:\n",
        "    matrix[idx] = emb\n",
        "  return matrix"
      ],
      "metadata": {
        "id": "Sfje91kSKsJZ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_model = EmbeddingProcessor(gensim_model)\n",
        "emb_matrix = multiproc_emb(emb_model, vocab)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYjKhUL_OxGi",
        "outputId": "e6997d34-1885-498f-cc37-176237c63982"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch_emb_matrix = torch.tensor(emb_matrix, dtype=torch.float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCHK-FYLWbbq",
        "outputId": "8bb0aa21-4221-4f5c-e7e5-fe360899769a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-64-d0a2a002e07b>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch_emb_matrix = torch.tensor(emb_matrix, dtype=torch.float)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('mean:', emb_model.mean)\n",
        "print('std:', emb_model.std)\n",
        "print('–≤–æ–¥–∞:', sum(emb_model.model.get_vector('–≤–æ–¥–∞_NOUN')))\n",
        "new_word = emb_model.add_tag('–±–µ–∂–∞—Ç—å')\n",
        "print('–±–µ–∂–∞—Ç—å:', new_word)\n",
        "print('–±–µ–∂–∞—Ç—å:', sum(emb_model.model[new_word]))\n",
        "print('vals:', emb_matrix.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ng0-Q0aQdk4",
        "outputId": "e94eb617-05ef-40ca-eb2f-d8885f919620"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean: -0.0012723453\n",
            "std: 0.057641353\n",
            "–≤–æ–¥–∞: -1.2167136888456298\n",
            "–±–µ–∂–∞—Ç—å: –±–µ–∂–∞—Ç—å_VERB\n",
            "–±–µ–∂–∞—Ç—å: -0.14577608798572328\n",
            "vals: <built-in method values of Tensor object at 0x7a654c0aa0c0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create LSTM model"
      ],
      "metadata": {
        "id": "3KSwjmIbVtgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  copied\n",
        "class RecurrentClassifier(nn.Module):\n",
        "    def __init__(self, config: Dict, vocab: Vocab, emb_matrix):\n",
        "        \"\"\"\n",
        "        Baseline classifier, hyperparameters are passed in `config`.\n",
        "        Consists of recurrent part and a classifier (Multilayer Perceptron) part\n",
        "        Keys are:\n",
        "            - freeze: whether word embeddings should be frozen\n",
        "            - cell_type: one of: RNN, GRU, LSTM, which recurrent cell model should use\n",
        "            - hidden_size: size of hidden state for recurrent cell\n",
        "            - num_layers: amount of recurrent cells in the model\n",
        "            - cell_dropout: dropout rate between recurrent cells (not applied if model has only one cell!)\n",
        "            - bidirectional: boolean, whether to use unidirectional of bidirectional model\n",
        "            - out_activation: one of: \"sigmoid\", \"tanh\", \"relu\", \"elu\". Activation in classifier part\n",
        "            - out_dropout: dropout rate in classifier part\n",
        "            - out_sizes: List[int], hidden size of each layer in classifier part. Empty list means that final\n",
        "                layer is attached directly to recurrent part output\n",
        "        :param config: configuration of model\n",
        "        :param vocab: vocabulary\n",
        "        :param emb_matrix: embeddings matrix from `prepare_emb_matrix`\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.vocab = vocab\n",
        "        self.emb_matrix = emb_matrix\n",
        "        self.embeddings = nn.Embedding.from_pretrained(\n",
        "            emb_matrix, freeze=config[\"freeze\"], padding_idx=vocab.PAD_IDX\n",
        "        )\n",
        "        cell_types = {\"RNN\": nn.RNN, \"GRU\": nn.GRU, \"LSTM\": nn.LSTM}\n",
        "        cell_class = cell_types[config[\"cell_type\"]]\n",
        "        self.cell = cell_class(input_size=emb_matrix.size(1),\n",
        "                               batch_first=True,\n",
        "                               hidden_size=config[\"hidden_size\"],\n",
        "                               num_layers=config[\"num_layers\"],\n",
        "                               dropout=config[\"cell_dropout\"],\n",
        "                               bidirectional= config[\"bidirectional\"],)\n",
        "\n",
        "        activation_types = {\"sigmoid\": nn.Sigmoid,\n",
        "                            \"tanh\": nn.Tanh,\n",
        "                            \"relu\": nn.ReLU,\n",
        "                            \"elu\": nn.ELU}\n",
        "\n",
        "        self.out_activation = activation_types[config[\"out_activation\"]]\n",
        "        self.out_dropout = nn.Dropout(config[\"out_dropout\"])\n",
        "        cur_out_size = config[\"hidden_size\"] * config[\"num_layers\"]\n",
        "        if config[\"bidirectional\"]:\n",
        "            cur_out_size *= 2\n",
        "        out_layers = []\n",
        "        for cur_hidden_size in config[\"out_sizes\"]:\n",
        "            out_layers.append(nn.Linear(cur_out_size, cur_hidden_size))\n",
        "            nn.init.kaiming_normal_(out_layers[-1].weight)\n",
        "            cur_out_size = cur_hidden_size\n",
        "        out_layers.append(nn.Linear(cur_out_size, 6))\n",
        "        self.out_proj = nn.Sequential(*out_layers)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.embeddings(input.data)\n",
        "        _, last_state = self.cell(PackedSequence(embedded,\n",
        "                                                 input.batch_sizes,\n",
        "                                                 sorted_indices=input.sorted_indices,\n",
        "                                                 unsorted_indices=input.unsorted_indices))\n",
        "\n",
        "        if isinstance(last_state, tuple):\n",
        "            last_state = last_state[0]\n",
        "        last_state = last_state.transpose(0, 1)\n",
        "        last_state = last_state.reshape(last_state.size(0), -1)\n",
        "        return self.out_proj(last_state)"
      ],
      "metadata": {
        "id": "HE0pzGgeTc5Q"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {'freeze':False,\n",
        "          'cell_type': 'LSTM',\n",
        "          \"cell_dropout\": 0.18,\n",
        "          'num_layers':3,\n",
        "          'hidden_size':128,\n",
        "          'out_activation':\"elu\",\n",
        "          'bidirectional':True,\n",
        "          'out_dropout': 0.18,\n",
        "          'out_sizes':[200]}"
      ],
      "metadata": {
        "id": "131vbgcWVwF1"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RecurrentClassifier(config, vocab, torch_emb_matrix)"
      ],
      "metadata": {
        "id": "4FpfW0wFWyHR"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "vQXIW1-MtxQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copied\n",
        "class Trainer:\n",
        "    def __init__(self, config: Dict):\n",
        "        \"\"\"\n",
        "        Fits end evaluates given model with Adam optimizer.\n",
        "         Hyperparameters are specified in `config`\n",
        "        Possible keys are:\n",
        "            - n_epochs: number of epochs to train\n",
        "            - lr: optimizer learning rate\n",
        "            - weight_decay: l2 regularization weight\n",
        "            - device: on which device to perform training (\"cpu\" or \"cuda\")\n",
        "            - verbose: whether to print anything during training\n",
        "        :param config: configuration for `Trainer`\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.n_epochs = config[\"n_epochs\"]\n",
        "        self.setup_opt_fn = lambda model: torch.optim.AdamW(\n",
        "            model.parameters(), config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
        "\n",
        "        self.model = None\n",
        "        self.opt = None\n",
        "        self.history = None\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "        self.device = config[\"device\"]\n",
        "        self.verbose = config.get(\"verbose\", True)\n",
        "\n",
        "\n",
        "    @wandb_wrapper\n",
        "    def fit(self, model, train_loader, val_loader):\n",
        "        \"\"\"\n",
        "        Fits model on training data, each epoch evaluates on validation data\n",
        "        :param model: PyTorch model for toxic comments classification (for example, `RecurrentClassifier`)\n",
        "        :param train_loader: DataLoader for training data\n",
        "        :param val_loader: DataLoader for validation data\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "        self.model = model.to(self.device)\n",
        "        self.opt = self.setup_opt_fn(self.model)\n",
        "        self.history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
        "        for epoch in range(self.n_epochs):\n",
        "            print(f\"Epoch {epoch + 1}/{self.n_epochs}\")\n",
        "            train_info = self._train_epoch(train_loader)\n",
        "            val_info = self._val_epoch(val_loader)\n",
        "            self.history[\"train_loss\"].extend(train_info[\"train_loss\"])\n",
        "            self.history[\"val_loss\"].append(val_info[\"loss\"])\n",
        "            self.history[\"val_acc\"].append(val_info[\"acc\"])\n",
        "        return self.model.eval()\n",
        "\n",
        "    def _train_epoch(self, train_loader):\n",
        "        self.model.train()\n",
        "        losses = []\n",
        "        if self.verbose:\n",
        "            train_loader = tqdm(train_loader)\n",
        "        for batch in train_loader:\n",
        "            self.model.zero_grad()\n",
        "            texts, labels = batch\n",
        "            logits = self.model.forward(texts.to(self.device))\n",
        "            loss = self.loss_fn(logits, labels.to(self.device))\n",
        "            loss.backward()\n",
        "            self.opt.step()\n",
        "            loss_val = loss.item()\n",
        "            if self.verbose:\n",
        "                train_loader.set_description(f\"Loss={loss_val:.3}\")\n",
        "            losses.append(loss_val)\n",
        "        if WANDBAPI:\n",
        "          wandb.log({\"Train Loss\": sum(losses) / len(losses)})\n",
        "        return {\"train_loss\": losses}\n",
        "\n",
        "    def _val_epoch(self, val_loader):\n",
        "        self.model.eval()\n",
        "        all_logits = []\n",
        "        all_labels = []\n",
        "        if self.verbose:\n",
        "            val_loader = tqdm(val_loader)\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                texts, labels = batch\n",
        "                logits = self.model.forward(texts.to(self.device))\n",
        "                all_logits.append(logits)\n",
        "                all_labels.append(labels)\n",
        "        all_labels = torch.cat(all_labels).to(self.device)\n",
        "        all_logits = torch.cat(all_logits)\n",
        "        loss = nn.CrossEntropyLoss()(all_logits, all_labels).item()\n",
        "        acc = (all_logits.argmax(1) == all_labels).float().mean().item()\n",
        "        if self.verbose:\n",
        "            val_loader.set_description(f\"Loss={loss:.3}; Acc:{acc:.3}\")\n",
        "        if WANDBAPI:\n",
        "          wandb.log({\"Validation Loss\": self.val_info[\"loss\"], \"Validation Accuracy\": self.val_info[\"acc\"]})\n",
        "        return {\"acc\": acc, \"loss\": loss}\n",
        "\n",
        "    def predict(self, test_loader):\n",
        "        if self.model is None:\n",
        "            raise RuntimeError(\"You should train the model first\")\n",
        "        self.model.eval()\n",
        "        predictions = []\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                texts, labels = batch\n",
        "                logits = self.model.forward(texts.to(self.device))\n",
        "                predictions.extend(logits.argmax(1).tolist())\n",
        "        return np.asarray(predictions)\n",
        "\n",
        "    def save(self, path: str):\n",
        "        if self.model is None:\n",
        "            raise RuntimeError(\"You should train the model first\")\n",
        "        checkpoint = {\n",
        "            \"config\": self.model.config,\n",
        "            \"trainer_config\": self.config,\n",
        "            \"vocab\": self.model.vocab,\n",
        "            \"emb_matrix\": self.model.emb_matrix,\n",
        "            \"state_dict\": self.model.state_dict(),\n",
        "        }\n",
        "        torch.save(checkpoint, path)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, path: str):\n",
        "        ckpt = torch.load(path)\n",
        "        keys = [\"config\", \"trainer_config\",\n",
        "                \"vocab\", \"emb_matrix\", \"state_dict\"]\n",
        "        for key in keys:\n",
        "            if key not in ckpt:\n",
        "                raise RuntimeError(f\"Missing key {key} in checkpoint\")\n",
        "        new_model = RecurrentClassifier(\n",
        "            ckpt[\"config\"], ckpt[\"vocab\"], ckpt[\"emb_matrix\"]\n",
        "        )\n",
        "        new_model.load_state_dict(ckpt[\"state_dict\"])\n",
        "        new_trainer = cls(ckpt[\"trainer_config\"])\n",
        "        new_trainer.model = new_model\n",
        "        new_trainer.model.to(new_trainer.device)\n",
        "        return new_trainer"
      ],
      "metadata": {
        "id": "d-MpdvAzuam2"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = lambda: 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "TI0eHVmluADG"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_config = {\n",
        "    \"lr\": 4e-3,\n",
        "    \"n_epochs\": 10,\n",
        "    \"weight_decay\": 1e-6,\n",
        "    \"batch_size\": 128,\n",
        "    \"device\": device()\n",
        "}\n",
        "for key,val in train_config.items():\n",
        "  wandb_config[key] = val"
      ],
      "metadata": {
        "id": "svQOhhm-t5oq"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset,\n",
        "                              batch_size=train_config[\"batch_size\"], shuffle=True,\n",
        "                              collate_fn=train_dataset.collate_fn)\n",
        "\n",
        "val_dataloader = DataLoader(val_dataset,\n",
        "                            batch_size=train_config[\"batch_size\"], shuffle=False,\n",
        "                            collate_fn=val_dataset.collate_fn)\n",
        "\n",
        "test_dataloader = DataLoader(TextDataset([tok.tokenize(sent) for sent in test_df['text'].values],\n",
        "                            [-1] * test_df.shape[0], vocab), shuffle=False,\n",
        "                             batch_size=train_config[\"batch_size\"],\n",
        "                             collate_fn=val_dataset.collate_fn)"
      ],
      "metadata": {
        "id": "bslKzeLJtHu0"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training = Trainer(train_config)\n",
        "training.fit(model, train_dataloader, val_dataloader)"
      ],
      "metadata": {
        "id": "lXy6sSGR_qov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## inference"
      ],
      "metadata": {
        "id": "8B-9TUfB78-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = training.predict(test_dataloader)"
      ],
      "metadata": {
        "id": "KzzuzgDa3p_g"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa5OlRIm7ut4",
        "outputId": "ccc4d32b-d902-4765-c874-510158a4d330"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12167"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.DataFrame({'rate':preds+1})\n",
        "result.to_csv('submissions.csv', index=True, index_label='index')"
      ],
      "metadata": {
        "id": "G0X5xNnD7Gkf"
      },
      "execution_count": 126,
      "outputs": []
    }
  ]
}