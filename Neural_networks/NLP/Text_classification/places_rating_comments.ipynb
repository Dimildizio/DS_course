{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9+iftmXmM778mz8c8h6ce",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimildizio/DS_course/blob/main/Neural_networks/NLP/Text_classification/places_rating_comments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comments rating classification"
      ],
      "metadata": {
        "id": "MgbY4XUfv1Dt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## download libs"
      ],
      "metadata": {
        "id": "yVeWKMin2H4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install nltk gensim"
      ],
      "metadata": {
        "id": "2KQsNDf52A7A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## imports"
      ],
      "metadata": {
        "id": "aQ_5oUMLzXGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "from nltk.tokenize import word_tokenize\n",
        "from pymystem3 import Mystem\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import List, Dict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "from torch.nn.utils.rnn import pack_sequence, PackedSequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.multiprocessing import Pool\n",
        "\n",
        "#from functools import partial"
      ],
      "metadata": {
        "id": "4MaZrN7ivwhh"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGItDiYQ2Iqt",
        "outputId": "f2b31cd9-64fb-4382-a730-cd36199dfb61"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "gensim_model = api.load(\"word2vec-ruscorpora-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlK3ummHOgHa",
        "outputId": "ccc5f886-5963-4e0e-f234-b36bd64afca9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 198.8/198.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load data"
      ],
      "metadata": {
        "id": "yiWM9OoszY_W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "typckxywn04R"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/Dimildizio/DS_course/main/Neural_networks/NLP/Text_classification/data/train_reviews.csv\n",
        "!wget https://github.com/Dimildizio/DS_course/blob/main/Neural_networks/NLP/Text_classification/data/test_reviews.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trdf = pd.read_csv('train_reviews.csv')\n",
        "test_df = pd.read_csv('test_reviews.csv')"
      ],
      "metadata": {
        "id": "-le90E87wAg1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trdf.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bhaCbpko1vPi",
        "outputId": "43310d04-0dd9-4965-e063-849c327b76f9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       rate                                               text\n",
              "19083     2  –û—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ –æ–±—Å–ª—É–∂–∏–≤–∞—é—Ç. –†–∞–±–æ—Ç–∞–µ—Ç –æ–¥–Ω–∞ –∫–∞—Å—Å...\n",
              "32953     4  –•–æ—Ä–æ—à–æ, —á—Ç–æ –≤ –º–∞–≥–∞–∑–∏–Ω–∞—Ö –ø–æ—è–≤–∏–ª–∏—Å—å –∫–∞—Å—Å—ã —Å–∞–º–æ–æ–±...\n",
              "24674     5  –î–∏—Ä–µ–∫—Ç–æ—Ä –ù–∞—Ç–∞–ª—å—è –í—è—á–µ—Å–ª–∞–≤–æ–≤–Ω–∞ –æ–≥–æ–Ω—å –ø—Ä–æ—Å—Ç–æ)) –¥...\n",
              "4975      5         –í—Å–µ–≥–¥–∞ –≤–µ–∂–ª–∏–≤—ã–µ –ø—Ä–æ–¥–∞–≤—Ü—ã –∏ —Ö–æ—Ä–æ—à–∏–π —Ç–æ–≤–∞—Ä üåπ\n",
              "40249     5              –ë–æ–ª—å—à–æ–π –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç, –≤–µ–∂–ª–∏–≤—ã–µ –∫–∞—Å—Å–∏—Ä—ã"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bcef1b68-2319-4764-be4e-9d529a4faceb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rate</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19083</th>\n",
              "      <td>2</td>\n",
              "      <td>–û—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ –æ–±—Å–ª—É–∂–∏–≤–∞—é—Ç. –†–∞–±–æ—Ç–∞–µ—Ç –æ–¥–Ω–∞ –∫–∞—Å—Å...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32953</th>\n",
              "      <td>4</td>\n",
              "      <td>–•–æ—Ä–æ—à–æ, —á—Ç–æ –≤ –º–∞–≥–∞–∑–∏–Ω–∞—Ö –ø–æ—è–≤–∏–ª–∏—Å—å –∫–∞—Å—Å—ã —Å–∞–º–æ–æ–±...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24674</th>\n",
              "      <td>5</td>\n",
              "      <td>–î–∏—Ä–µ–∫—Ç–æ—Ä –ù–∞—Ç–∞–ª—å—è –í—è—á–µ—Å–ª–∞–≤–æ–≤–Ω–∞ –æ–≥–æ–Ω—å –ø—Ä–æ—Å—Ç–æ)) –¥...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4975</th>\n",
              "      <td>5</td>\n",
              "      <td>–í—Å–µ–≥–¥–∞ –≤–µ–∂–ª–∏–≤—ã–µ –ø—Ä–æ–¥–∞–≤—Ü—ã –∏ —Ö–æ—Ä–æ—à–∏–π —Ç–æ–≤–∞—Ä üåπ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40249</th>\n",
              "      <td>5</td>\n",
              "      <td>–ë–æ–ª—å—à–æ–π –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç, –≤–µ–∂–ª–∏–≤—ã–µ –∫–∞—Å—Å–∏—Ä—ã</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcef1b68-2319-4764-be4e-9d529a4faceb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bcef1b68-2319-4764-be4e-9d529a4faceb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bcef1b68-2319-4764-be4e-9d529a4faceb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cb042950-8d45-41ab-b159-42983773cafb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb042950-8d45-41ab-b159-42983773cafb')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cb042950-8d45-41ab-b159-42983773cafb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## set target in range 0:x"
      ],
      "metadata": {
        "id": "Vjs_iM1OzbHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trdf['rate'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r24pNgsxwi-K",
        "outputId": "16dbed82-6150-43e2-c54f-86080665fd8b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    26069\n",
              "4     9922\n",
              "3     6126\n",
              "1     4138\n",
              "2     2410\n",
              "Name: rate, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def norm_target(df, to_train=True):\n",
        "  num = -1 if to_train else 1\n",
        "  dfr = df.copy()\n",
        "  dfr['rate'] = dfr['rate'] + num\n",
        "  return dfr"
      ],
      "metadata": {
        "id": "88Wn_5m7zjnO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = norm_target(trdf)"
      ],
      "metadata": {
        "id": "SnSgOafCworY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tokenize"
      ],
      "metadata": {
        "id": "asJpzJBK2dmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(text, lang='russian'):\n",
        "    tokens = word_tokenize(text, language=lang)\n",
        "    return [token for token in tokens if token.isalpha()]"
      ],
      "metadata": {
        "id": "iZhb0E212X2C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tok_txt = [tokenize_text(t) for t in train_df.text.values]"
      ],
      "metadata": {
        "id": "4hxxgynM1-Vu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### create vocab"
      ],
      "metadata": {
        "id": "5l6JTiPF3E5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Voc:\n",
        "  def __init__(self, txt, vocab_size):\n",
        "    toks = [tok for word in txt for tok in word]\n",
        "    tok_dict = Counter(toks)\n",
        "    self.tokens = [tok for tok, num in tok_dict.most_common(vocab_size)]"
      ],
      "metadata": {
        "id": "zQeL6uwc3G9d"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = Voc(tok_txt, 350000)\n",
        "vocabulary.tokens[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbEK9Izb4P_l",
        "outputId": "d80a0990-a92c-4ccf-e1c3-765de8514243"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['–∏',\n",
              " '–Ω–µ',\n",
              " '–≤',\n",
              " '–º–∞–≥–∞–∑–∏–Ω',\n",
              " '–Ω–∞',\n",
              " '—Å',\n",
              " '—á—Ç–æ',\n",
              " '–Ω–æ',\n",
              " '–≤—Å–µ–≥–¥–∞',\n",
              " '–µ—Å—Ç—å',\n",
              " '–æ—á–µ–Ω—å',\n",
              " '–ø–æ',\n",
              " '–ø–µ—Ä—Å–æ–Ω–∞–ª',\n",
              " '–∫–∞–∫',\n",
              " '–≤—Å–µ',\n",
              " '–∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç',\n",
              " '–•–æ—Ä–æ—à–∏–π',\n",
              " '–Ω–µ—Ç',\n",
              " '–∞',\n",
              " '—Å–∞–º–æ–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split"
      ],
      "metadata": {
        "id": "6_2gFMl8-flA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_df.drop('rate', axis=1)\n",
        "y = train_df['rate']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "UzHE8PjR8eip"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preset funcs for rnn"
      ],
      "metadata": {
        "id": "HkFfD-wf8far"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "copied"
      ],
      "metadata": {
        "id": "Qv-3eojCABn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self, word_pattern=\"[\\w']+\"):\n",
        "        \"\"\"\n",
        "        Simple tokenizer that splits the sentence by given regex pattern\n",
        "        :param word_pattern: pattern that determines word boundaries\n",
        "        \"\"\"\n",
        "        self.word_pattern = re.compile(word_pattern)\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        return self.word_pattern.findall(text)\n",
        "\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self, tokenized_texts: List[List[str]], max_vocab_size=None):\n",
        "        \"\"\"\n",
        "        Builds a vocabulary by concatenating all tokenized texts and counting words.\n",
        "        Most common words are placed in vocabulary, others are replaced with [UNK] token\n",
        "        :param tokenized_texts: texts to build a vocab\n",
        "        :param max_vocab_size: amount of words in vocabulary\n",
        "        \"\"\"\n",
        "        counts = Counter(chain(*tokenized_texts))\n",
        "        max_vocab_size = max_vocab_size or len(counts)\n",
        "        common_pairs = counts.most_common(max_vocab_size)\n",
        "        self.PAD_IDX = 0\n",
        "        self.UNK_IDX = 1\n",
        "        self.EOS_IDX = 2\n",
        "        self.itos = [\"<PAD>\", \"<UNK>\", \"<EOS>\"] + [pair[0]\n",
        "                                                   for pair in common_pairs]\n",
        "        self.stoi = {token: i for i, token in enumerate(self.itos)}\n",
        "\n",
        "    def vectorize(self, text: List[str]):\n",
        "        \"\"\"\n",
        "        Maps each token to it's index in the vocabulary\n",
        "        :param text: sequence of tokens\n",
        "        :return: vectorized sequence\n",
        "        \"\"\"\n",
        "        return [self.stoi.get(tok, self.UNK_IDX) for tok in text]\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.itos)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, tokenized_texts, labels, vocab: Vocab):\n",
        "        \"\"\"\n",
        "        A Dataset for the task\n",
        "        :param tokenized_texts: texts from a train/val/test split\n",
        "        :param labels: corresponding toxicity ratings\n",
        "        :param vocab: vocabulary with indexed tokens\n",
        "        \"\"\"\n",
        "        self.texts = tokenized_texts\n",
        "        self.labels = labels\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return (\n",
        "            self.vocab.vectorize(self.texts[item]) + [self.vocab.EOS_IDX],\n",
        "            self.labels[item],\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        \"\"\"\n",
        "        Technical method to form a batch to feed into recurrent network\n",
        "        \"\"\"\n",
        "        tmp = pack_sequence(\n",
        "            [torch.tensor(pair[0]) for pair in batch], enforce_sorted=False\n",
        "        ), torch.tensor([pair[1] for pair in batch])\n",
        "        return tmp\n",
        "\n",
        "\n",
        "def custom_train_test_split(data, train_frac=0.85):\n",
        "    \"\"\"\n",
        "    Splits the data into train and test parts, stratifying by labels.\n",
        "    Should it shuffle the data before split?\n",
        "    :param data: dataset to split\n",
        "    :param train_frac: proportion of train examples\n",
        "    :return: texts and labels for each split\n",
        "    \"\"\"\n",
        "    n_toxicity_ratings = 5\n",
        "    train_labels = []\n",
        "    val_labels = []\n",
        "    train_texts = []\n",
        "    val_texts = []\n",
        "    for label in range(n_toxicity_ratings):\n",
        "        texts = data[data.rate == label].text.values\n",
        "        n_train = int(len(texts) * train_frac)\n",
        "        n_val = len(texts) - n_train\n",
        "        train_texts.extend(texts[:n_train])\n",
        "        val_texts.extend(texts[n_train:])\n",
        "        train_labels += [label] * n_train\n",
        "        val_labels += [label] * n_val\n",
        "    return train_texts, train_labels, val_texts, val_labels"
      ],
      "metadata": {
        "id": "yNMu4cOh8fv6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tok = Tokenizer()\n",
        "vocab = Vocab([tok.tokenize(t) for t in train_df.text.values], 30000)\n",
        "train_texts, train_labels, val_texts, val_labels = custom_train_test_split(train_df)\n",
        "\n",
        "\n",
        "train_dataset = TextDataset([tok.tokenize(t) for t in train_texts],\n",
        "                            train_labels,\n",
        "                            vocab)\n",
        "val_dataset = TextDataset([tok.tokenize(t) for t in val_texts],\n",
        "                          val_labels,\n",
        "                          vocab)"
      ],
      "metadata": {
        "id": "OTCcryCp_Wp1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts[42]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "QJnH3zkX4eB2",
        "outputId": "6f086250-f2db-4df2-c6ab-385c169f3614"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'–ù–∞ –¥–Ω—è—Ö –∑–∞—à—ë–ª –∫—É–ø–∏—Ç—å –≤ —ç—Ç–æ—Ç –º–∞–≥–∞–∑–∏–Ω —Å–∏–≥–∞—Ä–µ—Ç , —Ç–∞–∫ –∂–µ —Ö–æ—Ç–µ–ª –∫—É–ø–∏—Ç—å –∏–∫—Ä—ã , —á—Ç–æ —Å—Ç–æ–∏—Ç –≤ —Ö–æ–ª–æ–¥–∏–ª—å–Ω–∏–∫–µ –±–ª–∏–∂–µ –∫ –∫–∞—Å–µ–µ \"–∞–ª–∫–æ–≥–æ–ª—è –∏ —Ç–∞–±–∞–∫–∞\", –Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ–≤ —á—Ç–æ –∫–∞—á–µ—Å—Ç–≤–æ –∏–∫—Ä—ã –Ω–µ –æ—á–µ–Ω—å , –ø–æ—Å—Ç–∞–≤–∏–ª –±–∞–Ω–∫—É –æ–±—Ä–∞—Ç–Ω–æ . –ü–æ—Å–ª–µ –ø–æ–∫—É–ø–∫–∏ —Å–∏–≥–∞—Ä–µ—Ç –Ω–∞ –∫–∞—Å—Å–µ , –º–µ–Ω—è –æ—Å—Ç–∞–Ω–æ–≤–∏–ª –Ω–µ –ø–æ–Ω—è—Ç–Ω–∞—è –ª–∏—á–Ω–æ –Ω–µ —Å–ª–∞–≤—è–Ω—Å–∫–æ–π –≤–Ω–µ—à–Ω–æ—Å—Ç–∏ ... –∏ —Å–æ —Å–ª–æ–≤–∞–º–∏ \"—ç–π —Ç—ã ... –≥–¥–µ –∏–∫—Ä–∞ , –≤—ã–≤–æ—Ä–∞—á–∏–≤–∞–π –∫–∞—Ä–º–∞–Ω—ã\" –≤–æ—Ç –≤–∞–º –∏ –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è –∏ –≤–µ–∂–ª–∏–≤–æ—Å—Ç—å —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ . )'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TAG_MAPPING = {'A': 'ADJ',\n",
        "               'ADV': 'ADV',\n",
        "               'ADVPRO': 'ADV',\n",
        "               'ANUM': 'ADJ',\n",
        "               'APRO': 'DET',\n",
        "               'COM': 'ADJ',\n",
        "               'CONJ': 'SCONJ',\n",
        "               'INTJ': 'INTJ',\n",
        "               'NONLEX': 'X',\n",
        "               'NUM': 'NUM',\n",
        "               'PART': 'PART',\n",
        "               'PR': 'ADP',\n",
        "               'S': 'NOUN',\n",
        "               'SPRO': 'PRON',\n",
        "               'UNKN': 'X',\n",
        "               'V': 'VERB'}"
      ],
      "metadata": {
        "id": "OnENqO9Z203X"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingProcessor:\n",
        "  def __init__(self, gensim_model):\n",
        "      self.model = gensim_model\n",
        "      self.mean = self.model.vectors.mean(1).mean()\n",
        "      self.std = self.model.vectors.std(1).mean()\n",
        "      self.vec_size = self.model.vector_size\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def get_universal_tag(word):\n",
        "      m = Mystem()\n",
        "      processed = m.analyze(word)[0]\n",
        "      lemma = processed[\"analysis\"][0][\"lex\"].lower().strip()\n",
        "      pos = processed[\"analysis\"][0][\"gr\"].split(',')[0]\n",
        "      pos = pos.split('=')[0].strip()\n",
        "      tagged = lemma + '_' + pos\n",
        "      return tagged\n",
        "\n",
        "\n",
        "  def process_word(self, idx, word):\n",
        "      try:\n",
        "        tagged = self.add_tag(word)\n",
        "        vector = self.model.get_vector(tagged)\n",
        "        return idx, torch.tensor(vector)\n",
        "      except Exception as e:\n",
        "        random_vector = torch.randn(self.vec_size) * self.std + self.mean\n",
        "        return idx, random_vector\n",
        "\n",
        "\n",
        "  def add_tag(self, word):\n",
        "      word = self.get_universal_tag(word)\n",
        "      tag = word.split('_')[1]\n",
        "      tag = TAG_MAPPING.get(tag, tag)\n",
        "\n",
        "      word = word.split('_')[0] + '_' + tag\n",
        "      return word"
      ],
      "metadata": {
        "id": "qTpLm_ja9iHt"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiproc_emb(mymodel, vocab, n_processes=3):\n",
        "  matrix = torch.zeros(len(vocab), mymodel.vec_size)\n",
        "\n",
        "  with Pool(processes=n_processes) as p:\n",
        "    arguments = [(idx, word) for idx, word in enumerate(vocab.itos[:1], 1)]\n",
        "    embs = p.starmap(mymodel.process_word, arguments)\n",
        "  for idx, emb in embs:\n",
        "    matrix[idx] = emb\n",
        "  return matrix"
      ],
      "metadata": {
        "id": "Sfje91kSKsJZ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_model = EmbeddingProcessor(gensim_model)\n",
        "emb_matrix = multiproc_emb(emb_model, vocab)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYjKhUL_OxGi",
        "outputId": "e6997d34-1885-498f-cc37-176237c63982"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch_emb_matrix = torch.tensor(emb_matrix, dtype=torch.float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCHK-FYLWbbq",
        "outputId": "8bb0aa21-4221-4f5c-e7e5-fe360899769a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-64-d0a2a002e07b>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  torch_emb_matrix = torch.tensor(emb_matrix, dtype=torch.float)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('mean:', emb_model.mean)\n",
        "print('std:', emb_model.std)\n",
        "print('–≤–æ–¥–∞:', sum(emb_model.model.get_vector('–≤–æ–¥–∞_NOUN')))\n",
        "new_word = emb_model.add_tag('–±–µ–∂–∞—Ç—å')\n",
        "print('–±–µ–∂–∞—Ç—å:', new_word)\n",
        "print('–±–µ–∂–∞—Ç—å:', sum(emb_model.model[new_word]))\n",
        "print('vals:', emb_matrix.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ng0-Q0aQdk4",
        "outputId": "e94eb617-05ef-40ca-eb2f-d8885f919620"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean: -0.0012723453\n",
            "std: 0.057641353\n",
            "–≤–æ–¥–∞: -1.2167136888456298\n",
            "–±–µ–∂–∞—Ç—å: –±–µ–∂–∞—Ç—å_VERB\n",
            "–±–µ–∂–∞—Ç—å: -0.14577608798572328\n",
            "vals: <built-in method values of Tensor object at 0x7a654c0aa0c0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create LSTM model"
      ],
      "metadata": {
        "id": "3KSwjmIbVtgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## this part is copied form the task\n",
        "class RecurrentClassifier(nn.Module):\n",
        "    def __init__(self, config: Dict, vocab: Vocab, emb_matrix):\n",
        "        \"\"\"\n",
        "        Baseline classifier, hyperparameters are passed in `config`.\n",
        "        Consists of recurrent part and a classifier (Multilayer Perceptron) part\n",
        "        Keys are:\n",
        "            - freeze: whether word embeddings should be frozen\n",
        "            - cell_type: one of: RNN, GRU, LSTM, which recurrent cell model should use\n",
        "            - hidden_size: size of hidden state for recurrent cell\n",
        "            - num_layers: amount of recurrent cells in the model\n",
        "            - cell_dropout: dropout rate between recurrent cells (not applied if model has only one cell!)\n",
        "            - bidirectional: boolean, whether to use unidirectional of bidirectional model\n",
        "            - out_activation: one of: \"sigmoid\", \"tanh\", \"relu\", \"elu\". Activation in classifier part\n",
        "            - out_dropout: dropout rate in classifier part\n",
        "            - out_sizes: List[int], hidden size of each layer in classifier part. Empty list means that final\n",
        "                layer is attached directly to recurrent part output\n",
        "        :param config: configuration of model\n",
        "        :param vocab: vocabulary\n",
        "        :param emb_matrix: embeddings matrix from `prepare_emb_matrix`\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.vocab = vocab\n",
        "        self.emb_matrix = emb_matrix\n",
        "        self.embeddings = nn.Embedding.from_pretrained(\n",
        "            emb_matrix, freeze=config[\"freeze\"], padding_idx=vocab.PAD_IDX\n",
        "        )\n",
        "        cell_types = {\"RNN\": nn.RNN, \"GRU\": nn.GRU, \"LSTM\": nn.LSTM}\n",
        "        cell_class = cell_types[config[\"cell_type\"]]\n",
        "        self.cell = cell_class(input_size=emb_matrix.size(1),\n",
        "                               batch_first=True,\n",
        "                               hidden_size=config[\"hidden_size\"],\n",
        "                               num_layers=config[\"num_layers\"],\n",
        "                               dropout=config[\"cell_dropout\"],\n",
        "                               bidirectional= config[\"bidirectional\"],)\n",
        "\n",
        "        activation_types = {\"sigmoid\": nn.Sigmoid,\n",
        "                            \"tanh\": nn.Tanh,\n",
        "                            \"relu\": nn.ReLU,\n",
        "                            \"elu\": nn.ELU}\n",
        "\n",
        "        self.out_activation = activation_types[config[\"out_activation\"]]\n",
        "        self.out_dropout = nn.Dropout(config[\"out_dropout\"])\n",
        "        cur_out_size = config[\"hidden_size\"] * config[\"num_layers\"]\n",
        "        if config[\"bidirectional\"]:\n",
        "            cur_out_size *= 2\n",
        "        out_layers = []\n",
        "        for cur_hidden_size in config[\"out_sizes\"]:\n",
        "            out_layers.append(nn.Linear(cur_out_size, cur_hidden_size))\n",
        "            cur_out_size = cur_hidden_size\n",
        "        out_layers.append(nn.Linear(cur_out_size, 6))\n",
        "        self.out_proj = nn.Sequential(*out_layers)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.embeddings(input.data)\n",
        "        _, last_state = self.cell(PackedSequence(embedded,\n",
        "                                                 input.batch_sizes,\n",
        "                                                 sorted_indices=input.sorted_indices,\n",
        "                                                 unsorted_indices=input.unsorted_indices))\n",
        "\n",
        "        if isinstance(last_state, tuple):\n",
        "            last_state = last_state[0]\n",
        "        last_state = last_state.transpose(0, 1)\n",
        "        last_state = last_state.reshape(last_state.size(0), -1)\n",
        "        return self.out_proj(last_state)"
      ],
      "metadata": {
        "id": "HE0pzGgeTc5Q"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {'freeze':False,\n",
        "          'cell_type': 'LSTM',\n",
        "          \"cell_dropout\": 0.18,\n",
        "          'num_layers':2,\n",
        "          'hidden_size':64,\n",
        "          'out_activation':\"elu\",\n",
        "          'bidirectional':True,\n",
        "          'out_dropout': 0.18,\n",
        "          'out_sizes':[200]}"
      ],
      "metadata": {
        "id": "131vbgcWVwF1"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RecurrentClassifier(config, vocab, torch_emb_matrix)"
      ],
      "metadata": {
        "id": "4FpfW0wFWyHR"
      },
      "execution_count": 82,
      "outputs": []
    }
  ]
}