{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFwyPmX7oDYZXXggSpxfnh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimildizio/DS_course/blob/main/Neural_networks/NLP/Langchain/Langchain_hf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain with huggingface"
      ],
      "metadata": {
        "id": "CdrkcbRXy6ey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get libs"
      ],
      "metadata": {
        "id": "LWRWhHAEy9ny"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75H_LeJRo4y3",
        "outputId": "cca7c228-f5c0-4297-8e4b-a0f3fa9773da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install transformers huggingface-hub langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "p-sQliWczAxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain import PromptTemplate, HuggingFaceHub, LLMChain"
      ],
      "metadata": {
        "id": "8Kl0Pn1Vpjmc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get huggingface API KEY"
      ],
      "metadata": {
        "id": "ENjBiUZ3zDTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./hf_api.txt') as f:\n",
        "  key = f.readline()"
      ],
      "metadata": {
        "id": "bMPfCowtpCvq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = key"
      ],
      "metadata": {
        "id": "vmffsfrQyRKV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a prompt for messages"
      ],
      "metadata": {
        "id": "uY6WPgJ9zLcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Question: {question}\n",
        "Answer: Lets' think step by step.\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
      ],
      "metadata": {
        "id": "FYWbh-CJxLgL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run online"
      ],
      "metadata": {
        "id": "sLXqzPHu5RI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload a model"
      ],
      "metadata": {
        "id": "6IQuYRZpzP7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = \"google/flan-t5-base\"\n",
        "model = HuggingFaceHub(repo_id=repo_id, model_kwargs={'temperature':0.5, 'max_length':256})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJd9rB__xu6z",
        "outputId": "12034dc6-2d0a-4c0f-91b7-dc74ae567601"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '0.19.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=model)"
      ],
      "metadata": {
        "id": "M92Ef-gsyLNI"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execute"
      ],
      "metadata": {
        "id": "v7muIDRF5XNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How to make a sandwich?\""
      ],
      "metadata": {
        "id": "sY8OLU0s5ae9"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = llm_chain.run(question)\n",
        "print(len(result), result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE669AS5zXxl",
        "outputId": "15f692bd-42ce-4a73-c39c-ebc3e67cd821"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "108 A sandwich is a sandwich that is made with bread, cheese, lettuce, tomato, and cheese. The answer: sandwich.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run locally"
      ],
      "metadata": {
        "id": "2m2gL5N45Kzp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Smbc91b5pp_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}