{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimildizio/DS_course/blob/main/Neural_networks/NLP/Langchain/Mistral/mistral_prompting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d7f6058-d0d1-44af-b43a-cb4b06df03d8",
      "metadata": {
        "id": "5d7f6058-d0d1-44af-b43a-cb4b06df03d8"
      },
      "source": [
        "# Prompting Capabilities\n",
        "\n",
        "chat interface [Le Chat](https://chat.mistral.ai/chat)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper funcs"
      ],
      "metadata": {
        "id": "8GADhW8tjRTC"
      },
      "id": "8GADhW8tjRTC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daa37d97-10e4-425d-b852-15bd043662b9",
      "metadata": {
        "height": 30,
        "id": "daa37d97-10e4-425d-b852-15bd043662b9"
      },
      "outputs": [],
      "source": [
        "!pip install mistralai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3b3ac64-1295-4a0e-90ab-51c338c945f7",
      "metadata": {
        "id": "d3b3ac64-1295-4a0e-90ab-51c338c945f7"
      },
      "source": [
        "- Notice that it's \"mistralai\", and not \"mistral\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "from mistralai.client import MistralClient\n",
        "from mistralai.models.chat_completion import ChatMessage\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n"
      ],
      "metadata": {
        "id": "8vT7CIhyjTNs"
      },
      "id": "8vT7CIhyjTNs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = None\n",
        "dlai_endpoint = None\n",
        "client = None"
      ],
      "metadata": {
        "id": "U9wZmJ9hjjcO"
      },
      "id": "U9wZmJ9hjjcO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_env():\n",
        "    _ = load_dotenv(find_dotenv())\n",
        "\n",
        "\n",
        "def load_mistral_api_key(ret_key=False):\n",
        "    load_env()\n",
        "    global api_key\n",
        "    global dlai_endpoint\n",
        "    api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
        "    dlai_endpoint = os.getenv(\"DLAI_MISTRAL_API_ENDPOINT\")\n",
        "\n",
        "    global client\n",
        "    client = MistralClient(api_key=api_key, endpoint=dlai_endpoint)\n",
        "\n",
        "    if ret_key:\n",
        "        return api_key, dlai_endpoint"
      ],
      "metadata": {
        "id": "VYVirfe6jX4D"
      },
      "id": "VYVirfe6jX4D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mistral(user_message,\n",
        "            model=\"mistral-small-latest\",\n",
        "            is_json=False):\n",
        "    client = MistralClient(api_key=api_key, endpoint=dlai_endpoint)\n",
        "    messages = [ChatMessage(role=\"user\", content=user_message)]\n",
        "\n",
        "    if is_json:\n",
        "        chat_response = client.chat(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            response_format={\"type\": \"json_object\"})\n",
        "    else:\n",
        "        chat_response = client.chat(\n",
        "            model=model,\n",
        "            messages=messages)\n",
        "\n",
        "    return chat_response.choices[0].message.content\n",
        "\n",
        "\n",
        "def get_text_embedding(txt):\n",
        "    global client\n",
        "    embeddings_batch_response = client.embeddings(\n",
        "        model=\"mistral-embed\",\n",
        "        input=txt\n",
        "    )\n",
        "    return embeddings_batch_response.data[0].embedding"
      ],
      "metadata": {
        "id": "LmvwcM22jbTq"
      },
      "id": "LmvwcM22jbTq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_web_article_text(url, file_save_name=None):\n",
        "\n",
        "    response = requests.get(url)\n",
        "    html_doc = response.text\n",
        "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "\n",
        "\n",
        "    tag = soup.find(\"div\", re.compile(\"^prose--styled\"))\n",
        "    text = tag.text\n",
        "\n",
        "    if file_save_name:\n",
        "        f = open(file_save_name, \"w\")\n",
        "        f.write(text)\n",
        "        f.close()\n",
        "    return text"
      ],
      "metadata": {
        "id": "MrzL2oAOjeGk"
      },
      "id": "MrzL2oAOjeGk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ff393a84-303a-48ae-97fe-3551f524f733",
      "metadata": {
        "id": "ff393a84-303a-48ae-97fe-3551f524f733"
      },
      "source": [
        "### Load API key and helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f6a5640-203a-4e7a-bc4c-4bfe78da4099",
      "metadata": {
        "height": 47,
        "id": "3f6a5640-203a-4e7a-bc4c-4bfe78da4099"
      },
      "outputs": [],
      "source": [
        "load_mistral_api_key()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e030d9c2-1ecb-4bf0-864d-9f96b41bd016",
      "metadata": {
        "height": 47,
        "id": "e030d9c2-1ecb-4bf0-864d-9f96b41bd016",
        "outputId": "378123f4-1b8e-4050-e35d-b62c6f39e400"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hello! I can assist you with a variety of tasks, such as answering questions, providing information, setting reminders, managing your schedule, and much more. I can also help you with research, writing, and learning. How can I assist you today?'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mistral(\"hello, what can you do?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b98a29ef-4764-40b7-aed8-0e5d0502f985",
      "metadata": {
        "id": "b98a29ef-4764-40b7-aed8-0e5d0502f985"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d71e9d1c-ca45-4d19-882c-07e077ea19ad",
      "metadata": {
        "height": 642,
        "id": "d71e9d1c-ca45-4d19-882c-07e077ea19ad"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "    You are a bank customer service bot.\n",
        "    Your task is to assess customer intent and categorize customer\n",
        "    inquiry after <<<>>> into one of the following predefined categories:\n",
        "\n",
        "    card arrival\n",
        "    change pin\n",
        "    exchange rate\n",
        "    country support\n",
        "    cancel transfer\n",
        "    charge dispute\n",
        "\n",
        "    If the text doesn't fit into any of the above categories,\n",
        "    classify it as:\n",
        "    customer service\n",
        "\n",
        "    You will only respond with the predefined category.\n",
        "    Do not provide explanations or notes.\n",
        "\n",
        "    ###\n",
        "    Here are some examples:\n",
        "\n",
        "    Inquiry: How do I know if I will get my card, or if it is lost? I am concerned about the delivery process and would like to ensure that I will receive my card as expected. Could you please provide information about the tracking process for my card, or confirm if there are any indicators to identify if the card has been lost during delivery?\n",
        "    Category: card arrival\n",
        "    Inquiry: I am planning an international trip to Paris and would like to inquire about the current exchange rates for Euros as well as any associated fees for foreign transactions.\n",
        "    Category: exchange rate\n",
        "    Inquiry: What countries are getting support? I will be traveling and living abroad for an extended period of time, specifically in France and Germany, and would appreciate any information regarding compatibility and functionality in these regions.\n",
        "    Category: country support\n",
        "    Inquiry: Can I get help starting my computer? I am having difficulty starting my computer, and would appreciate your expertise in helping me troubleshoot the issue.\n",
        "    Category: customer service\n",
        "    ###\n",
        "\n",
        "    <<<\n",
        "    Inquiry: {inquiry}\n",
        "    >>>\n",
        "    Category:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a21d367f-cc2c-4857-abd5-d1f6a545ebc0",
      "metadata": {
        "id": "a21d367f-cc2c-4857-abd5-d1f6a545ebc0"
      },
      "source": [
        "#### Ask Mistral to check the spelling and grammar of your prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "465a2ecd-e542-4863-96dc-29786c003799",
      "metadata": {
        "height": 64,
        "id": "465a2ecd-e542-4863-96dc-29786c003799"
      },
      "outputs": [],
      "source": [
        "response = mistral(f\"Please correct the spelling and grammar of \\\n",
        "this prompt and return a text that is the same prompt,\\\n",
        "with the spelling and grammar fixed: {prompt}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "476f0db5-ba51-43ca-a4c4-dc2b072291ba",
      "metadata": {
        "height": 30,
        "id": "476f0db5-ba51-43ca-a4c4-dc2b072291ba",
        "outputId": "587c348f-03bf-442a-838c-35899fb9cdee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are a bank customer service bot.\n",
            "Your task is to assess the customer's intent and categorize the customer inquiry after \"<<<>>>\" into one of the following predefined categories:\n",
            "\n",
            "* card arrival\n",
            "* change PIN\n",
            "* exchange rate\n",
            "* country support\n",
            "* cancel transfer\n",
            "* charge dispute\n",
            "\n",
            "If the text doesn't fit into any of the above categories, classify it as:\n",
            "\n",
            "* customer service\n",
            "\n",
            "You will only respond with the predefined category. Do not provide explanations or notes.\n",
            "\n",
            "###\n",
            "Here are some examples:\n",
            "\n",
            "Inquiry: How do I know if I will get my card, or if it is lost? I am concerned about the delivery process and would like to ensure that I will receive my card as expected. Could you please provide information about the tracking process for my card, or confirm if there are any indicators to identify if the card has been lost during delivery?\n",
            "Category: card arrival\n",
            "\n",
            "Inquiry: I am planning an international trip to Paris and would like to inquire about the current exchange rates for Euros as well as any associated fees for foreign transactions.\n",
            "Category: exchange rate\n",
            "\n",
            "Inquiry: What countries are supported? I will be traveling and living abroad for an extended period of time, specifically in France and Germany, and would appreciate any information regarding compatibility and functionality in these regions.\n",
            "Category: country support\n",
            "\n",
            "Inquiry: Can I get help starting my computer? I am having difficulty starting my computer, and would appreciate your expertise in helping me troubleshoot the issue.\n",
            "Category: customer service\n",
            "\n",
            "###\n",
            "\n",
            "<<<\n",
            "Inquiry: {inquiry}\n",
            ">>>\n",
            "Category:\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d27bbf68-a0bc-4e8a-bb6b-8ae20f3f2e2d",
      "metadata": {
        "id": "d27bbf68-a0bc-4e8a-bb6b-8ae20f3f2e2d"
      },
      "source": [
        "#### Try out the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4625fdc0-c6ef-4dcf-bbc0-d250a0ed277c",
      "metadata": {
        "height": 98,
        "id": "4625fdc0-c6ef-4dcf-bbc0-d250a0ed277c",
        "outputId": "aa84e0f8-871c-486e-8f38-6be25cd14a4a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'country support'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mistral(\n",
        "    response.format(\n",
        "        inquiry=\"I am inquiring about the availability of your cards in the EU\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4252e995-f3fc-4e62-abdb-3e367df55cbe",
      "metadata": {
        "id": "4252e995-f3fc-4e62-abdb-3e367df55cbe"
      },
      "source": [
        "## Information Extraction with JSON Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6741a613-5b1b-4fb1-9843-1c5737f36cd5",
      "metadata": {
        "height": 166,
        "id": "6741a613-5b1b-4fb1-9843-1c5737f36cd5"
      },
      "outputs": [],
      "source": [
        "medical_notes = \"\"\"\n",
        "A 60-year-old male patient, Mr. Johnson, presented with symptoms\n",
        "of increased thirst, frequent urination, fatigue, and unexplained\n",
        "weight loss. Upon evaluation, he was diagnosed with diabetes,\n",
        "confirmed by elevated blood sugar levels. Mr. Johnson's weight\n",
        "is 210 lbs. He has been prescribed Metformin to be taken twice daily\n",
        "with meals. It was noted during the consultation that the patient is\n",
        "a current smoker.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14c2bd7a-48c9-4c0b-8a4a-049a43045805",
      "metadata": {
        "height": 472,
        "id": "14c2bd7a-48c9-4c0b-8a4a-049a43045805"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Extract information from the following medical notes:\n",
        "{medical_notes}\n",
        "\n",
        "Return json format with the following JSON schema:\n",
        "\n",
        "{{\n",
        "        \"age\": {{\n",
        "            \"type\": \"integer\"\n",
        "        }},\n",
        "        \"gender\": {{\n",
        "            \"type\": \"string\",\n",
        "            \"enum\": [\"male\", \"female\", \"other\"]\n",
        "        }},\n",
        "        \"diagnosis\": {{\n",
        "            \"type\": \"string\",\n",
        "            \"enum\": [\"migraine\", \"diabetes\", \"arthritis\", \"acne\"]\n",
        "        }},\n",
        "        \"weight\": {{\n",
        "            \"type\": \"integer\"\n",
        "        }},\n",
        "        \"smoking\": {{\n",
        "            \"type\": \"string\",\n",
        "            \"enum\": [\"yes\", \"no\"]\n",
        "        }}\n",
        "}}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "951a0b58-aae5-45e2-8496-714b884f16b6",
      "metadata": {
        "height": 47,
        "id": "951a0b58-aae5-45e2-8496-714b884f16b6",
        "outputId": "35f0f5e8-03ab-42fe-a18e-e84c9d2c6cf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"age\": 60, \"gender\": \"male\", \"diagnosis\": \"diabetes\", \"weight\": 210, \"smoking\": \"yes\"}\n"
          ]
        }
      ],
      "source": [
        "response = mistral(prompt, is_json=True)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1a9cb95-bb08-4929-b16c-eb19877f3c01",
      "metadata": {
        "id": "d1a9cb95-bb08-4929-b16c-eb19877f3c01"
      },
      "source": [
        "## Personalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cf048b4-3e33-4753-af97-25b73c51ee6a",
      "metadata": {
        "height": 166,
        "id": "9cf048b4-3e33-4753-af97-25b73c51ee6a"
      },
      "outputs": [],
      "source": [
        "email = \"\"\"\n",
        "Dear mortgage lender,\n",
        "\n",
        "What's your 30-year fixed-rate APR, how is it compared to the 15-year\n",
        "fixed rate?\n",
        "\n",
        "Regards,\n",
        "Anna\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36de7c1e-60c2-4f35-a51a-115b12d65bb6",
      "metadata": {
        "height": 404,
        "id": "36de7c1e-60c2-4f35-a51a-115b12d65bb6"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "\n",
        "You are a mortgage lender customer service bot, and your task is to\n",
        "create personalized email responses to address customer questions.\n",
        "Answer the customer's inquiry using the provided facts below. Ensure\n",
        "that your response is clear, concise, and directly addresses the\n",
        "customer's question. Address the customer in a friendly and\n",
        "professional manner. Sign the email with \"Lender Customer Support.\"\n",
        "\n",
        "# Facts\n",
        "30-year fixed-rate: interest rate 6.403%, APR 6.484%\n",
        "20-year fixed-rate: interest rate 6.329%, APR 6.429%\n",
        "15-year fixed-rate: interest rate 5.705%, APR 5.848%\n",
        "10-year fixed-rate: interest rate 5.500%, APR 5.720%\n",
        "7-year ARM: interest rate 7.011%, APR 7.660%\n",
        "5-year ARM: interest rate 6.880%, APR 7.754%\n",
        "3-year ARM: interest rate 6.125%, APR 7.204%\n",
        "30-year fixed-rate FHA: interest rate 5.527%, APR 6.316%\n",
        "30-year fixed-rate VA: interest rate 5.684%, APR 6.062%\n",
        "\n",
        "# Email\n",
        "{email}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaf50774-0f91-4e0e-86c9-1525f6045ebb",
      "metadata": {
        "height": 47,
        "scrolled": true,
        "id": "aaf50774-0f91-4e0e-86c9-1525f6045ebb",
        "outputId": "2e4c7a6b-478d-4a5a-9b3d-27af9f42fc5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dear Anna,\n",
            "\n",
            "Thank you for reaching out. Our current 30-year fixed-rate APR is 6.484%. In comparison, our 15-year fixed-rate APR is 5.848%. As you can see, the 15-year fixed-rate has a lower APR than the 30-year fixed-rate. This is because you'll pay off the loan in half the time, resulting in less interest paid over the life of the loan.\n",
            "\n",
            "However, keep in mind that the monthly payment for a 15-year loan will be higher than for a 30-year loan, as you're paying off the loan in a shorter period of time.\n",
            "\n",
            "If you have any other questions or need further clarification, please don't hesitate to ask.\n",
            "\n",
            "Best regards,\n",
            "Lender Customer Support\n"
          ]
        }
      ],
      "source": [
        "response = mistral(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cfaad2c-411e-4221-80f0-7acd21ba398c",
      "metadata": {
        "id": "4cfaad2c-411e-4221-80f0-7acd21ba398c"
      },
      "source": [
        "## Summarization\n",
        "\n",
        "- We'll use this [article](https://www.deeplearning.ai/the-batch/mistral-enhances-ai-landscape-in-europe-with-microsoft-partnership-and-new-language-models) from The Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bbab492-1d18-4832-86a9-2fba645e0e52",
      "metadata": {
        "height": 336,
        "id": "0bbab492-1d18-4832-86a9-2fba645e0e52"
      },
      "outputs": [],
      "source": [
        "newsletter = \"\"\"\n",
        "European AI champion Mistral AI unveiled new large language models and formed an alliance with Microsoft.\n",
        "\n",
        "What’s new: Mistral AI introduced two closed models, Mistral Large and Mistral Small (joining Mistral Medium, which debuted quietly late last year). Microsoft invested $16.3 million in the French startup, and it agreed to distribute Mistral Large on its Azure platform and let Mistral AI use Azure computing infrastructure. Mistral AI makes the new models available to try for free here and to use on its La Plateforme and via custom deployments.\n",
        "\n",
        "Model specs: The new models’ parameter counts, architectures, and training methods are undisclosed. Like the earlier, open source Mistral 7B and Mixtral 8x7B, they can process 32,000 tokens of input context.\n",
        "\n",
        "Mistral Large achieved 81.2 percent on the MMLU benchmark, outperforming Anthropic’s Claude 2, Google’s Gemini Pro, and Meta’s Llama 2 70B, though falling short of GPT-4. Mistral Small, which is optimized for latency and cost, achieved 72.2 percent on MMLU.\n",
        "Both models are fluent in French, German, Spanish, and Italian. They’re trained for function calling and JSON-format output.\n",
        "Microsoft’s investment in Mistral AI is significant but tiny compared to its $13 billion stake in OpenAI and Google and Amazon’s investments in Anthropic, which amount to $2 billion and $4 billion respectively.\n",
        "Mistral AI and Microsoft will collaborate to train bespoke models for customers including European governments.\n",
        "Behind the news: Mistral AI was founded in early 2023 by engineers from Google and Meta. The French government has touted the company as a home-grown competitor to U.S.-based leaders like OpenAI. France’s representatives in the European Commission argued on Mistral’s behalf to loosen the European Union’s AI Act oversight on powerful AI models.\n",
        "\n",
        "Yes, but: Mistral AI’s partnership with Microsoft has divided European lawmakers and regulators. The European Commission, which already was investigating Microsoft’s agreement with OpenAI for potential breaches of antitrust law, plans to investigate the new partnership as well. Members of President Emmanuel Macron’s Renaissance party criticized the deal’s potential to give a U.S. company access to European users’ data. However, other French lawmakers support the relationship.\n",
        "\n",
        "Why it matters: The partnership between Mistral AI and Microsoft gives the startup crucial processing power for training large models and greater access to potential customers around the world. It gives the tech giant greater access to the European market. And it gives Azure customers access to a high-performance model that’s tailored to Europe’s unique regulatory environment.\n",
        "\n",
        "We’re thinking: Mistral AI has made impressive progress in a short time, especially relative to the resources at its disposal as a startup. Its partnership with a leading hyperscaler is a sign of the tremendous processing and distribution power that remains concentrated in the large, U.S.-headquartered cloud companies.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* And AlphaSignal newsletter from 26.07.2024\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9tCR8NxJj3Ox"
      },
      "id": "9tCR8NxJj3Ox"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cc70041",
      "metadata": {
        "height": 3787,
        "id": "5cc70041"
      },
      "outputs": [],
      "source": [
        "newsletter = \"\"\" AlphaSignal\n",
        "\n",
        "Hey Tess,\n",
        "\n",
        "Welcome to today's edition of AlphaSignal, a newsletter for developers by developers.\n",
        "\n",
        "We identify and summarize the top 1% news, papers, models, and repos in the AI industry.\n",
        "\n",
        "IN TODAY'S SIGNAL\n",
        "Read time: 4 min 48 sec\n",
        "\n",
        "🎖️ Top News\n",
        "\n",
        "Mistral Releases Large 2 : an Open Source Multilingual LLM w. 80+ Coding Languages\n",
        "\n",
        "\n",
        "📌 CodeRabbit\n",
        "\n",
        "Merge Code 10x faster with AI-driven code reviews\n",
        "\n",
        "\n",
        "⚡️ Trending Signals\n",
        "\n",
        "Gemini 1.5 flash is now free for all users.\n",
        "\n",
        "\n",
        "Mark Zuckerberg explains why he open sourced a $500M model.\n",
        "\n",
        "\n",
        "Cohere introduces rerank 3 nimble for faster search.\n",
        "\n",
        "\n",
        "Deepmind’s AlphaProof scores silver in math olympiad.\n",
        "\n",
        "\n",
        "OpenAI announces SearchGPT, a new AI search feature.\n",
        "\n",
        "📌 NVIDIA\n",
        "\n",
        "NVIDIA releases a new way to instantly use and deploy the best models including Llama 3.1 405B, 70B, and 8B\n",
        "\n",
        "\n",
        "🧠 Top Papers\n",
        "\n",
        "4D Reconstruction from a Single Video: New method enhances 3D/2D motion tracking and view synthesis from single videos.\n",
        "\n",
        "\n",
        "The Llama 3 Herd of Models: The new Llama 3.1 research paper.\n",
        "\n",
        "\n",
        "KAN or MLP: A Fairer Comparison: Controlled study finds MLP generally outperforms KAN across various tasks.\n",
        "\n",
        "If you're enjoying AlphaSignal please forward this email to a colleague.\n",
        "\n",
        "It helps us keep this content free.\n",
        "\n",
        "TOP NEWS\n",
        "Open Source\n",
        "\n",
        "Mistral Releases Large 2: An Open Source Multilingual LLM w. 80+ Coding Languages\n",
        "⇧ 2519 Likes\n",
        "\n",
        "\n",
        "What's New\n",
        "Mistral AI released Mistral Large 2, their largest dense model with 123 billion parameters. This model fits on a single H100 node and supports non-commercial open-weights usage. The release follows Meta's Llama 405B.\n",
        "\n",
        "\n",
        "\n",
        "Key Specifications and Performance Metrics\n",
        "\n",
        "123 billion parameters on a single H100 node\n",
        "128k context window, supporting dozens of languages\n",
        "Achieves 84% on MMLU, 8.63 on MT Bench, and 92% on HumanEval\n",
        "Available on Hugging Face for research and non-commercial use\n",
        "Commercial license available for deployment\n",
        "Enhanced Coding and Reasoning Capabilities\n",
        "Mistral Large 2 excels in coding, trained on 80+ programming languages. It matches or surpasses models like GPT-4o, Opus-3, and Llama-3 405B in coding benchmarks.\n",
        "\n",
        "\n",
        "\n",
        "Compared to its predecessor, Mistral Large 1, it has reduced hallucinations and improved reliability, making it more dependable for complex tasks.\n",
        "\n",
        "\n",
        "\n",
        "Improved Instruction Following and Conversation Handling\n",
        "Mistral Large 2 follows instructions better and handles long multi-turn conversations. On benchmarks like Wild Bench, Arena Hard, and MT Bench, it outperforms Llama 3.1 405B and Opus-3, and matches Sonnet-3.5 and GPT-4o. This improvement makes it suitable for applications requiring precise and sustained interactions.\n",
        "\n",
        "\n",
        "\n",
        "Multilingual Training and Performance\n",
        "Trained on a significant amount of multilingual data, Mistral Large 2 excels in languages like English, French, German, Spanish, Italian, Portuguese, Chinese, Japanese, Korean, Arabic, and Hindi.\n",
        "\n",
        "\n",
        "\n",
        "It outperforms Llama-3.1 70B and is comparable to Llama-3.1 405B in multilingual tasks, making it versatile for global applications.\n",
        "\n",
        "\n",
        "\n",
        "Advanced Function Calling\n",
        "Mistral Large 2 features enhanced function calling and retrieval skills, performing parallel and sequential function calls effectively.\n",
        "\n",
        "\n",
        "\n",
        "Access\n",
        "\n",
        "You can use Mistral Large 2 today via la Plateforme under the name mistral-large-2407, and test it on le Chat. Weights for the instruct model are available and are also hosted on HuggingFace.\n",
        "\n",
        "\n",
        "READ MORE\n",
        "\n",
        "CodeRabbit: Merge Code 10x faster with AI-driven code reviews\n",
        "With CodeRabbit, you get:\n",
        "\n",
        "Codebase-aware, line-by-line reviews with 1-click fixes.\n",
        "\n",
        "Smart real-time chat for advice, code generation, and issue creation directly from review comments.\n",
        "\n",
        "Comprehensive pull request summaries and sequence diagrams of changes.\n",
        "\n",
        "Most installed AI app on GitHub and GitLab marketplace, loved by 1000’s of developers.\n",
        "\n",
        "\n",
        "\n",
        "Enjoy a 7-day trial and access for OSS projects.\n",
        "TRY NOW\n",
        "partner with us\n",
        "\n",
        "TRENDING SIGNALS\n",
        "Language Models\n",
        "\n",
        "Google makes Gemini 1.5 Flash free for all users\n",
        "⇧ 205 Likes\n",
        "\n",
        "Open Source\n",
        "\n",
        "Mark Zuckerberg explains his reasoning behind open sourcing a $500 million model\n",
        "⇧ 1225 Likes\n",
        "\n",
        "Notebooks\n",
        "\n",
        "Cohere introduces Rerank 3 Nimble: faster reranking search & retrieval-augmented generation (RAG) Systems\n",
        "⇧ 242 Likes\n",
        "\n",
        "Fine-tuning\n",
        "\n",
        "DeepMind's new AlphaProof achieves silver medal-level score in the International Mathematical Olympiad (IMO)\n",
        "⇧ 1429 Likes\n",
        "\n",
        "Search\n",
        "\n",
        "OpenAI announces SearchGPT: An AI search features that give you fast and timely answers with clear and relevant sources.\n",
        "⇧ 3949 Likes\n",
        "\n",
        "NVIDIA releases a new way to instantly use and deploy the best models including Llama 3.1 405B, 70B, and 8B\n",
        "Their AI Foundry lets you create custom \"supermodels\" tailored to your needs and train them with proprietary data as well as synthetic data generated from Llama 3.1 405B.\n",
        "\n",
        "It can handle, data curation, synthetic data generation, fine-tuning with proprietary data, accurate response retrieval, comprehensive evaluation and deployment.\n",
        "\n",
        "Try it now ↗️\n",
        "\n",
        "TOP PAPERS\n",
        "Video Generation\n",
        "\n",
        "4D Reconstruction from a Single Video\n",
        "⇧ 1528  Likes\n",
        "\n",
        "Problem\n",
        "\n",
        "Reconstructing dynamic scenes from single videos is complex due to the ill-posed nature of the task. Traditional methods are limited as they require templates, function only in nearly static scenes, or cannot track full-sequence 3D motion, which makes them unsuitable for complex, moving scenes.\n",
        "\n",
        "\n",
        "\n",
        "Solution\n",
        "\n",
        "This approach uses SE(3) motion bases to model motion as a combination of base movements. It integrates data-driven priors like depth maps and 2D motion tracks into a unified scene representation, enhancing consistency and accuracy.\n",
        "\n",
        "\n",
        "\n",
        "Results\n",
        "\n",
        "The technique sets a new standard in 3D/2D motion tracking and novel view synthesis. It lowers 3D tracking error to 0.082 EPE and raises 3D tracking accuracy (within 5cm) to 43.0% on the iPhone dataset.\n",
        "\n",
        "Language Models\n",
        "\n",
        "The Llama 3 Herd of Models\n",
        "⇧ 1411 Likes\n",
        "\n",
        "Problem\n",
        "Modern AI requires foundation models that integrate multilinguality, coding, reasoning, and tool usage. Existing models, while advanced, do not fully integrate these capabilities with high performance across various tasks.\n",
        "\n",
        "\n",
        "\n",
        "Solution\n",
        "Llama 3, a dense Transformer model with 405B parameters and a 128K token context window, addresses this need. It was pre-trained on a 15T token multilingual corpus using 3.8 × 10^25 FLOPs, significantly outscaling previous models. Llama 3 supports extensive multilingual capabilities and integrates coding, reasoning, and tool usage more seamlessly.\n",
        "\n",
        "\n",
        "\n",
        "Results\n",
        "Llama 3 matches GPT-4's performance across numerous benchmarks. On tasks like MMLU and IFEval, Llama 3.1 405B scores 87.3% and 88.6%, respectively, showing competitiveness with or superiority to other models. Smaller versions also outperform comparable models, making Llama 3.1 a leading option across size scales.\n",
        "\n",
        "KAN\n",
        "\n",
        "KAN or MLP: A Fairer Comparison\n",
        "⇧ 685 Likes\n",
        "\n",
        "Problem\n",
        "\n",
        "Comparisons between Kolmogorov-Arnold Networks (KAN) and Multi-Layer Perceptrons (MLP) are unfair due to differing parameters and FLOPs.\n",
        "\n",
        "\n",
        "\n",
        "Solution\n",
        "\n",
        "This study controls parameters and FLOPs to fairly compare KAN and MLP across tasks like machine learning, computer vision, NLP, audio processing, and symbolic formula representation. B-spline activation's impact is explored.\n",
        "\n",
        "\n",
        "\n",
        "Results\n",
        "\n",
        "MLP outperformed KAN in machine learning (86.16% vs. 85.96%), computer vision (85.88% vs. 77.88%), NLP (80.45% vs. 79.95%), and audio processing (17.74% vs. 15.49%). KAN excelled only in symbolic formula representation (1.2e-3 RMSE vs. 7.4e-3). Access the code here.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaede63d-7392-4f1c-8a87-507ee31fe246",
      "metadata": {
        "height": 472,
        "id": "eaede63d-7392-4f1c-8a87-507ee31fe246"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "You are a commentator. Your task is to write a report on a newsletter.\n",
        "When presented with the newsletter, come up with interesting questions to ask,\n",
        "and answer each question.\n",
        "Afterward, combine all the information and write a report in the markdown\n",
        "format.\n",
        "\n",
        "# Newsletter:\n",
        "{newsletter}\n",
        "\n",
        "# Instructions:\n",
        "## Summarize:\n",
        "In clear and concise language, summarize the key points and themes\n",
        "presented in the newsletter.\n",
        "\n",
        "## Interesting Questions:\n",
        "Generate three distinct and thought-provoking questions that can be\n",
        "asked about the content of the newsletter. For each question:\n",
        "- After \"Q: \", describe the problem\n",
        "- After \"A: \", provide a detailed explanation of the problem addressed\n",
        "in the question.\n",
        "- Enclose the ultimate answer in <>.\n",
        "\n",
        "## Write a analysis report\n",
        "Using the summary and the answers to the interesting questions,\n",
        "create a comprehensive report in Markdown format.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5505b0a5-411b-4804-aaef-ccecfa3d07be",
      "metadata": {
        "height": 47,
        "scrolled": true,
        "id": "5505b0a5-411b-4804-aaef-ccecfa3d07be",
        "outputId": "d346183e-7858-4157-fdaa-62eb691563b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary:\n",
            "The AlphaSignal newsletter highlights the top developments in the AI industry. Mistral AI has released Large 2, an open-source multilingual LLM with 80+ coding languages and improved instruction following. CodeRabbit is an AI-driven tool for faster code merging. Gemini 1.5 flash is now free for all users, and Mark Zuckerberg has open-sourced a $500M model. Cohere has introduced Rerank 3 Nimble for faster search. DeepMind's AlphaProof scored silver in the math olympiad. NVIDIA has released a new method for deploying models, including Llama 3.1. Top papers include a new method for 4D reconstruction from a single video and the Llama 3 Herd of Models. A study found MLP generally outperforms KAN across various tasks.\n",
            "\n",
            "Interesting Questions:\n",
            "1. Q: How does Mistral Large 2 compare to its predecessor and other models in terms of performance and capabilities?\n",
            "   A: Mistral Large 2 has reduced hallucinations and improved reliability compared to Mistral Large 1. It also matches or surpasses models like GPT-4o, Opus-3, and Llama-3 405B in coding benchmarks. It outperforms Llama-3.1 70B and is comparable to Llama-3.1 405B in multilingual tasks.\n",
            "   <Mistral Large 2 shows overall improvement and competitiveness with other leading models.>\n",
            "\n",
            "2. Q: What are the implications of OpenAI's SearchGPT and NVIDIA's AI Foundry for AI search and model deployment?\n",
            "   A: SearchGPT could revolutionize online search by providing fast, relevant answers with clear sources. NVIDIA's AI Foundry allows users to create custom \"supermodels\" tailored to their needs and train them with proprietary data, making model deployment more accessible and efficient.\n",
            "   <Both developments could significantly enhance the functionality and accessibility of AI applications.>\n",
            "\n",
            "3. Q: How does the new method for 4D reconstruction from a single video improve upon traditional methods?\n",
            "   A: The new method uses SE(3) motion bases to model motion, integrating data-driven priors into a unified scene representation. This enhances consistency and accuracy, reducing 3D tracking error and increasing accuracy in complex, moving scenes.\n",
            "   <The new method sets a new standard for 3D/2D motion tracking and view synthesis in complex scenes.>\n",
            "\n",
            "Report:\n",
            "---\n",
            "\n",
            "# AlphaSignal Newsletter Analysis\n",
            "\n",
            "The latest edition of AlphaSignal brings exciting updates from the AI industry. Mistral AI's Large 2, an open-source multilingual LLM, stands out with its improved performance and capabilities in coding and multilingual tasks (Q1). Meanwhile, tools like CodeRabbit and Gemini 1.5 flash aim to streamline coding and search processes. Open sourcing initiatives by Mark Zuckerberg and DeepMind's AlphaProof's success in the math olympiad further demonstrate the growing openness and competitiveness in the field.\n",
            "\n",
            "In the realm of model deployment, NVIDIA's AI Foundry promises to make creating and training custom models more accessible (Q2). This is particularly significant for models like Llama 3.1, which, according to the top papers section, show impressive performance across various tasks (Q3). The new method for 4D reconstruction from a single video also showcases the potential of AI in handling complex dynamic scenes.\n",
            "\n",
            "The newsletter also highlights a study comparing KAN and MLP, indicating that MLP generally outperforms KAN across various tasks. This could influence future research and model development in the AI community. Overall, the newsletter paints a picture of a dynamic and rapidly evolving AI landscape, with a focus on improving performance, accessibility, and multilingual capabilities.\n",
            "\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "response = mistral(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ed88147-8d43-4207-b45b-06543371f913",
      "metadata": {
        "id": "8ed88147-8d43-4207-b45b-06543371f913"
      },
      "source": [
        "## The Mistral Python client\n",
        "- Below is the helper function that you imported from helper.py and used earlier in this notebook.\n",
        "- For more details, check out the [Mistral AI API documentation](https://docs.mistral.ai/api/)\n",
        "- To get your own Mistral AI API key to use on your own, outside of this classroom, you can create an account and go to the [console](https://console.mistral.ai/) to subscribe and create an API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27ef7a7f-ebd6-49c3-8f91-5f5d284edf17",
      "metadata": {
        "height": 353,
        "id": "27ef7a7f-ebd6-49c3-8f91-5f5d284edf17"
      },
      "outputs": [],
      "source": [
        "from mistralai.client import MistralClient\n",
        "from mistralai.models.chat_completion import ChatMessage\n",
        "\n",
        "def mistral(user_message,\n",
        "            model=\"mistral-small-latest\",\n",
        "            is_json=False):\n",
        "    client = MistralClient(api_key=os.getenv(\"MISTRAL_API_KEY\"))\n",
        "    messages = [ChatMessage(role=\"user\", content=user_message)]\n",
        "\n",
        "    if is_json:\n",
        "        chat_response = client.chat(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            response_format={\"type\": \"json_object\"})\n",
        "    else:\n",
        "        chat_response = client.chat(\n",
        "            model=model,\n",
        "            messages=messages)\n",
        "\n",
        "    return chat_response.choices[0].message.content"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "formats": "ipynb,py:light"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}