{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVfcsR+jTHArzSukCEClSa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimildizio/DS_course/blob/main/Neural_networks/NLP/Embeddings/Simple_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Embeddings"
      ],
      "metadata": {
        "id": "fSDYOEFIa9MQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The task is to rank StackOverflow questions based on their semantic representations."
      ],
      "metadata": {
        "id": "uh3jmwRJbE_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* $X$ - the n number of objects\n",
        "* $X^l = \\{x_1, x_2, ..., x_l\\}$ - train dataset\n",
        "\n",
        "* $i \\prec j$ - the order of index pairs of $X^l$ and $i$, $j$ indices.\n"
      ],
      "metadata": {
        "id": "AE5QaUP8bY-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Task:\n",
        "Construct and ranking function $a$ : $X \\rightarrow R$ so that\n",
        "$$i \\prec j \\Rightarrow a(x_i) < a(x_j)$$"
      ],
      "metadata": {
        "id": "Fpf3J5y_bv6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings"
      ],
      "metadata": {
        "id": "EvkWJ9QAfb_3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the corpora"
      ],
      "metadata": {
        "id": "Agz-_QkwfrPo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAcSxBbra7_N"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget https://zenodo.org/record/1199620/files/SO_vectors_200.bin?download=1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "sYNU7HoRfmFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from typing import List"
      ],
      "metadata": {
        "id": "IIXYOQfqfkMO"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create embeddings"
      ],
      "metadata": {
        "id": "jkj46d7Rf0j7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wv_embeddings = KeyedVectors.load_word2vec_format(\"SO_vectors_200.bin?download=1\", binary=True)"
      ],
      "metadata": {
        "id": "fSfNkxO2fq8G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Examples"
      ],
      "metadata": {
        "id": "ZYFxkpEsgJDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'dog'\n",
        "if word in wv_embeddings:\n",
        "    print(wv_embeddings[word].dtype, wv_embeddings[word].shape)\n",
        "print(f\"Num of words: {len(wv_embeddings.index_to_key)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oesej4FWgDkw",
        "outputId": "864ef967-e9b1-4c91-f534-1651315e3db3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float32 (200,)\n",
            "Num of words: 1787145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1"
      ],
      "metadata": {
        "id": "KGtf23LNgoqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is 'cat' in top5 most similar words to 'dog'? If yes, which position?"
      ],
      "metadata": {
        "id": "1j0gocWOgwS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"'dog' and 'cat' similarity:\")\n",
        "print('\\t', wv_embeddings.similarity('dog', 'cat'))\n",
        "print('\\t', wv_embeddings.n_similarity(['dog'], ['cat']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy0vl5uHnfbs",
        "outputId": "452023ba-d221-4fb1-d395-687800e75b4e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'dog' and 'cat' similarity:\n",
            "\t 0.6852341\n",
            "\t 0.6852341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_occur(req: str, base: str, n: int = 5, flag = True) -> np.ndarray:\n",
        "  \"\"\"Checks if one word is similar to another\n",
        "\n",
        "  :param req: word to check with\n",
        "  :param base: word check if is similar to\n",
        "  :param n: top N words to check\n",
        "  :param flag: a flag to check which slimilarity function to use\n",
        "  :return: None\n",
        "  \"\"\"\n",
        "\n",
        "  # also funcs most_similar_cosmul or similar_by_word could be used\n",
        "  result = wv_embeddings.most_similar(base, topn=n)\n",
        "  for i, (word, perc) in enumerate(result):\n",
        "    if req == word:\n",
        "      print(f'{req} is {int(perc*100)}% similar to {base} at position {i}')\n",
        "      return result\n",
        "  print(f'{req} is not similar to {base}')\n",
        "  return result"
      ],
      "metadata": {
        "id": "-jDEJd1qiwqy"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ('cat', 'cats', 'dog', 'dogs')\n",
        "for requested in words:\n",
        "  requested = requested.lower()\n",
        "  for based in words:\n",
        "    based = based.lower()\n",
        "    if requested != based:\n",
        "      result = check_occur(requested, based)\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbGZuSORgUL7",
        "outputId": "b469557e-f37f-4d8e-9038-a5adf4106157"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat is not similar to cats\n",
            "cat is not similar to dog\n",
            "cat is not similar to dogs\n",
            "\n",
            "cats is not similar to cat\n",
            "cats is 76% similar to dog at position 3\n",
            "cats is 90% similar to dogs at position 0\n",
            "\n",
            "dog is 68% similar to cat at position 1\n",
            "dog is 76% similar to cats at position 2\n",
            "dog is 78% similar to dogs at position 3\n",
            "\n",
            "dogs is not similar to cat\n",
            "dogs is 90% similar to cats at position 0\n",
            "dogs is 78% similar to dog at position 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q1Answer:\n",
        "\n",
        "We've checked several simialrity function: `similar_by_word`, `most_similar_cosmul` and `most_similar` and got identical (different percentage) results. *(Here the words are ranked starting from 1 unlike positions in the similarity list which start from 0)*:\n",
        "\n",
        "**\"cat\" is not in top5 words similar to \"dog\"**, however \"cats\" is similar to \"dog\" coming fourth and and \"cats\" is similar to \"dogs\" coming first. Also 'dog' is similar to 'cat' ranked second, to 'cats' ranked third. And 'dogs' similar to 'cats' ranked first.\n"
      ],
      "metadata": {
        "id": "PLojs2X5kynq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector representations"
      ],
      "metadata": {
        "id": "RE8U0BKHp9Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyTokenizer:\n",
        "    def __init__(self):\n",
        "        self.tokenizer = WordPunctTokenizer()\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        return self.tokenizer.tokenize(text)"
      ],
      "metadata": {
        "id": "ZHntr91FqDh5"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = MyTokenizer()"
      ],
      "metadata": {
        "id": "fhbsEFbukHOU"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def question_to_vec(question, embeddings=wv_embeddings, tokenizer=tokenizer, dim=200):\n",
        "    \"\"\"\n",
        "    Embeds a sentence into vector representations\n",
        "\n",
        "        :param question: str\n",
        "        :param embeddings: embedidngs\n",
        "        :param dim: size of any vector in repr\n",
        "\n",
        "        return: embeddings of a questing\n",
        "    \"\"\"\n",
        "    tokens = tokenizer.tokenize(question)\n",
        "    vecs = []\n",
        "    known_words = 0\n",
        "\n",
        "    for token in tokens:\n",
        "      if token in embeddings:\n",
        "        vecs.append(embeddings[token])\n",
        "        known_words+=1\n",
        "    if not known_words:\n",
        "      return np.zeros(dim)\n",
        "    avg_vector = np.mean(vecs, axis=0)\n",
        "    return avg_vector"
      ],
      "metadata": {
        "id": "v-yf8U76qrHH"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2:\n",
        "\n",
        "What is the third component (2nd index) of vector representation of `\"I love neural networks\"` (rounded to 2 digit)?"
      ],
      "metadata": {
        "id": "zYTj4u7uuSlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q2 = 'I love neural networks'\n",
        "q2_embeds = question_to_vec(q2)\n",
        "third_component = str(round(q2_embeds[2], 2))\n",
        "print(f\"Third component of '{q2}' is {third_component}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5aOFm8QslSF",
        "outputId": "fe263f81-1e66-4eb4-8ab9-2a6a32c5455f"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Third component of 'I love neural networks' is -1.29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q2 Answer:\n",
        "\n",
        "Third component of `'I love neural networks'` is `-1.29`"
      ],
      "metadata": {
        "id": "E6_C7m04t3UC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text similarity"
      ],
      "metadata": {
        "id": "sJyDh_Z-wGXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation\n",
        "\n",
        "*We assume* that cos distance for duplicates is smaleer than between randomly chosen sentences.\n",
        "\n",
        "\n",
        "\n",
        "For each of $N$ questions, we'll **generate** $R$ **random negative examples** and **include the actual duplicates** as well. We'll rank $R + 1$ examples for each question using our model and **look at the position of the duplicate**. Ideally, we want the duplicate to be ranked first.\n",
        "\n",
        "#### Hits@K\n",
        "The first metric will be the number of correct hits for a given $K$:\n",
        "\n",
        "$$ \\text{Hits@K} = \\frac{1}{N}\\sum_{i=1}^N \\, [rank\\_q_i^{'} \\le K],$$\n",
        "* $\\begin{equation*}\n",
        "[x < 0 ] \\equiv\n",
        " \\begin{cases}\n",
        "   1, &x < 0\\\\\n",
        "   0, &x \\geq 0\n",
        " \\end{cases}\n",
        "\\end{equation*}$ - func\n",
        "* $q_i$ - $i$-th question\n",
        "\n",
        "\n",
        "#### DCG@K\n",
        "\n",
        "Another metric will be a simplified DCG metric, which considers the order of elements in the list by multiplying the **relevance of an element** by a **weight equal to the inverse logarithm of its position**:\n",
        "\n",
        "$$ \\text{DCG@K} = \\frac{1}{N} \\sum_{i=1}^N\\frac{1}{\\log_2(1+rank\\_q_i^{'})}\\cdot[rank\\_q_i^{'} \\le K],$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "With this metric, the model is penalized for higher ranks of correct answers."
      ],
      "metadata": {
        "id": "PkYTPYpd1Yo8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3:\n",
        "\n",
        "Max `Hits@47 - DCG@1` ?"
      ],
      "metadata": {
        "id": "yPVzFHYPCu51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The duplicate is always ranked within the top 47 positions (Hits@47 = 1), which means that the model correctly identifies the duplicate as similar to the input question.\n",
        "\n",
        "The duplicate is always ranked first (DCG@1 = 1), showing that the model ranks the duplicate at the top position, with no incorrect rankings above it.\n",
        "\n",
        "So, to generalize:\n",
        "\n",
        "**Hits@47** = 1: means all duplicates are in top47\n",
        "\n",
        "**DCG@1** = 1: means all duplicates are ranked first\n",
        "\n",
        "*If we just want maximum value for the result then we want the situation to be Hits@47=1 (all duplicates within first47), DCG@1=0 (none of the duplicates ranked first) thus having 1 as maximum*\n",
        "$$1-0=1$$\n",
        "\n",
        "So **the answer is 1** however i consider such situation theretical"
      ],
      "metadata": {
        "id": "lOxLThVZ3JfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q3 answer:\n",
        "\n",
        "Max Hits@47 - DCG@1 = 1"
      ],
      "metadata": {
        "id": "h2hsLkYXDFLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def HitsatK(rankings: List, K: int) -> float:\n",
        "    \"\"\"\n",
        "    Compute Hits@K metric.\n",
        "\n",
        "    :param rankings: (list) List of ranks of duplicates in the ranked list for each question.\n",
        "    :param K: (int) Number of top-ranked items to consider.\n",
        "    :returns: float Hits@K score.\n",
        "    \"\"\"\n",
        "    hits = sum(1 for rank in rankings if rank <= K) / len(rankings)\n",
        "    return hits"
      ],
      "metadata": {
        "id": "C3S0N7jVwe5k"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DCGatK(rankings: List, K: int) -> float:\n",
        "    \"\"\"\n",
        "    Compute DCG@K metric.\n",
        "\n",
        "\n",
        "    :param rankings: (list) List of ranks of duplicates in the ranked list for each question.\n",
        "    :param K: (int) Number of top-ranked items to consider.\n",
        "    :returns: float DCG@K score.\n",
        "    \"\"\"\n",
        "    dcg = sum(1 / np.log2(1 + rank) for rank in rankings if rank <= K) / len(rankings)\n",
        "    return dcg"
      ],
      "metadata": {
        "id": "OsTKxPsc8hze"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 4:\n",
        "Find `DCG@10`, if $rank\\_q_i^{'} = 9$(round to 1 digit)"
      ],
      "metadata": {
        "id": "UzJ3lyBdAy6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we dont need a list here we can as well do it in one line of code"
      ],
      "metadata": {
        "id": "6ZWPKgh-B0fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dcg = lambda rank, k: 1 / np.log2(1 + rank) if rank <= k else 0\n",
        "dcg_result = round(dcg(9, 10), 1)\n",
        "print(f\"DCG@10 if rank q'_i is 9: {dcg_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BzRPFKFBPyN",
        "outputId": "168dd981-15b2-4ab3-eed4-74f4885ea1cb"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DCG@10 if rank q'_i is 9: 0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q4 answer:\n",
        "\n",
        "DCG@10 if rank_$q'_i=9$: 0.3"
      ],
      "metadata": {
        "id": "1yUgJnKHCk1M"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qaxQ9rfpC0p1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}