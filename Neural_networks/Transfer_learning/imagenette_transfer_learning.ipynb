{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPf59euhXPLCB4PMqaXfc8h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimildizio/DS_course/blob/main/Neural_networks/Transfer_learning/imagenette_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transfer learning"
      ],
      "metadata": {
        "id": "kHA-xQIBHEbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading and importing libs"
      ],
      "metadata": {
        "id": "ZYarUpOvHK7E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f49W_fRngzVv"
      },
      "outputs": [],
      "source": [
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U albumentations\n",
        "!pip install -q --upgrade wandb\n",
        "!pip install timm\n",
        "\n",
        "display.clear_output()"
      ],
      "metadata": {
        "id": "MTR1N_4qhYbe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import wandb\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo. Installing...\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "import timm\n",
        "\n",
        "import albumentations as A\n",
        "import albumentations.pytorch as AP\n",
        "\n",
        "from albumentations import (\n",
        "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90, Resize, RandomCrop,\n",
        "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
        "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n",
        "    IAASharpen, IAAEmboss, Flip, OneOf, Compose, Rotate, RandomScale, RandomGridShuffle,\n",
        "    RandomContrast, RandomGamma, RandomBrightness, CenterCrop, VerticalFlip, ColorJitter,\n",
        "    ChannelShuffle, InvertImg, RGBShift, ElasticTransform, Equalize, RandomResizedCrop, ChannelDropout\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "HwYuf6SehoGN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting things up"
      ],
      "metadata": {
        "id": "tGGPUAQLHAr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating config class to utilize global variables"
      ],
      "metadata": {
        "id": "8nPM-bumDtfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "\n",
        "    num_workers=2\n",
        "    model_name = 'inception_v3'\n",
        "    size = 224\n",
        "    scheduler = 'StepLR'\n",
        "    epochs = 15\n",
        "    step_size = 20 # StepLR\n",
        "    gamma = 0.1 # StepLR\n",
        "    lr = 3e-4\n",
        "    min_lr = 1e-6  #\n",
        "    batch_size = 8\n",
        "    seed = 42\n",
        "\n",
        "    api = \"\"\n",
        "    project = \"imagenette\"\n",
        "    entity = \"dimildizio\"\n",
        "    wandb = True\n",
        "\n",
        "    @classmethod\n",
        "    def _set_model_name(cls, name):\n",
        "      cls.model_name = name\n",
        "\n",
        "    @classmethod\n",
        "    def _set_lr(cls, lr):\n",
        "      cls.lr = lr\n",
        "\n",
        "    @classmethod\n",
        "    def _set_epochs(cls, epoch):\n",
        "      cls.epochs = epoch\n",
        "\n",
        "    @classmethod\n",
        "    def _switchflag(cls):\n",
        "      cls.wandb = False if cls.wandb else True\n",
        "      print(f'Wandb logging: {cls.wandb}')\n",
        "\n",
        "    @classmethod\n",
        "    @ property\n",
        "    def _get_config(cls):\n",
        "      return {key:value for key, value in CFG.__dict__.items() if (\n",
        "                key[:1]!= '_' and key not in ('api', 'project', 'entity', 'wandb'))}\n"
      ],
      "metadata": {
        "id": "QLjG7a7tpiom"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " CFG._get_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPGHp_a0QxNg",
        "outputId": "b92d23b8-d564-4ea0-cbd3-7016dff64c97"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_workers': 2,\n",
              " 'model_name': 'inception_v3',\n",
              " 'size': 224,\n",
              " 'scheduler': 'StepLR',\n",
              " 'epochs': 15,\n",
              " 'step_size': 20,\n",
              " 'gamma': 0.1,\n",
              " 'lr': 0.0003,\n",
              " 'min_lr': 1e-06,\n",
              " 'batch_size': 8,\n",
              " 'seed': 42}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data transformations - augmentation, normalization"
      ],
      "metadata": {
        "id": "AtzoU2vzEny6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modify torch.utils.data.Dataset class for augmented data"
      ],
      "metadata": {
        "id": "gd0W7H-mFSEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MakeDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, files, transform=None):\n",
        "        super().__init__()\n",
        "        self.files = files\n",
        "        self.labels = [path.parent.name for path in self.files]\n",
        "        self.len_ = len(self.files)\n",
        "        self.transform = transform\n",
        "        self.classes = ['n01440764', 'n02102040', 'n02979186', 'n03000684', 'n03028079', 'n03394916',\n",
        "                        'n03417042', 'n03425413', 'n03445777', 'n03888257']\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len_\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = cv2.imread(f'{self.files[index]}')\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "        label = self.labels[index]\n",
        "        for i in range(len(self.classes)):\n",
        "          if label == self.classes[i]:\n",
        "            y = i\n",
        "\n",
        "        return image, y"
      ],
      "metadata": {
        "id": "WQDoRC4lsF7S"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Augmentations, transformations, normalization"
      ],
      "metadata": {
        "id": "oNGBFDgdHdZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transforms(*, data):\n",
        "\n",
        "    if data == 'train':\n",
        "        transforma = A.Compose([Resize(256,256), RandomCrop(CFG.size,CFG.size), Rotate(limit = 90, p=0.5),\n",
        "                                    GaussNoise(p=0.5), A.Sharpen(p=0.5), ChannelShuffle(p=0.5),\n",
        "                                    HorizontalFlip(p=0.5), A.Normalize(), AP.ToTensorV2()])\n",
        "    elif data == 'valid':\n",
        "        transforma = A.Compose([Resize(256,256), CenterCrop(CFG.size,CFG.size), A.Normalize(), AP.ToTensorV2()])\n",
        "    return transforma"
      ],
      "metadata": {
        "id": "wbk2TKEI1vX1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loaders(train_df, val_df):\n",
        "  train_loader = torch.utils.data.DataLoader(train_df, batch_size=CFG.batch_size,shuffle=True)\n",
        "  valid_loader = torch.utils.data.DataLoader(val_df, batch_size = CFG.batch_size)\n",
        "\n",
        "  print('Train and Valid datasets are loaded:\\n')\n",
        "  print('{:<7s}{:>10s}{:>10s}'.format('Dataset', 'Batches', 'Pictures')), print('-' * 28)\n",
        "  print('{:<7s}{:>10d}{:>10d}'.format('Train', len(train_loader), len(train_df)))\n",
        "  print('{:<7s}{:>10d}{:>10d}'.format('Valid', len(valid_loader), len(val_df)))\n",
        "  return train_loader, valid_loader"
      ],
      "metadata": {
        "id": "W1RI0wjtsF1S"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading dataset and preparing data"
      ],
      "metadata": {
        "id": "qUfHWMiMG0Z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = 'imagenette2-160/'\n",
        "if not os.path.exists(dataset_path):\n",
        "    !wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz\n",
        "    !tar zxvf imagenette2-160.tgz\n",
        "\n",
        "TRAIN_DIR = Path('/content/imagenette2-160/train')\n",
        "VAL_DIR = Path('/content/imagenette2-160/val')\n",
        "\n",
        "train_files = sorted(list(TRAIN_DIR.rglob('*.JPEG')))\n",
        "val_files = sorted(list(VAL_DIR.rglob('*.JPEG')))\n",
        "display.clear_output()"
      ],
      "metadata": {
        "id": "ezBklgYVpj0C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MakeDataset(train_files, transform = get_transforms(data='train'))\n",
        "val_dataset  = MakeDataset(val_files, transform = get_transforms(data='valid'))"
      ],
      "metadata": {
        "id": "a0Lowfc656Fk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, valid_loader = get_loaders(train_dataset, val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBidvzDyLd__",
        "outputId": "9775acd5-9fa2-467b-da75-84d05ff8664c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train and Valid datasets are loaded:\n",
            "\n",
            "Dataset   Batches  Pictures\n",
            "----------------------------\n",
            "Train        1184      9469\n",
            "Valid         491      3925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Performer:\n",
        "  trainloader = train_loader\n",
        "  validloader = valid_loader\n",
        "\n",
        "\n",
        "\n",
        "  @classmethod\n",
        "  def get_device(cls):\n",
        "    cuda = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    device = torch.device(cuda)\n",
        "    print(device)\n",
        "    return device\n",
        "\n",
        "  @classmethod\n",
        "  def trainval_hist(cls):\n",
        "    return {'train':[], 'val':[]}, {'train':[], 'val':[]}\n",
        "\n",
        "  @classmethod\n",
        "  def run_wandb(cls):\n",
        "    if CFG.wandb:\n",
        "      os.environ['WANDB_API_KEY'] = CFG.api\n",
        "      wandb.init(project = CFG.project, entity = CFG.entity,\n",
        "                 name = CFG.model_name, reinit = True, config = CFG._get_config)\n",
        "\n",
        "  @classmethod\n",
        "  def log_wandb(cls, name, loss, acc):\n",
        "    if CFG.wandb:\n",
        "      wandb.log({name+'_loss': loss, name+'_accuracy': acc})\n",
        "\n",
        "  @classmethod\n",
        "  def seed_everything(cls):\n",
        "    seed = CFG.seed\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] =str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "  @classmethod\n",
        "  def switch_trainval(cls, model, phase):\n",
        "    if phase == 'train':\n",
        "      model.train()\n",
        "      return cls.trainloader\n",
        "    else:\n",
        "      model.eval()\n",
        "      return cls.validloader\n",
        "\n",
        "  @classmethod\n",
        "  def train_val(cls, model, optimizer, loss = nn.CrossEntropyLoss(), scheduler = False):\n",
        "    #pre-setup\n",
        "    cls.seed_everything()\n",
        "    cls.run_wandb()\n",
        "    device = cls.get_device()\n",
        "    #set local variables for all epochs\n",
        "    loss_hist, acc_hist = cls.trainval_hist()\n",
        "    best_acc = 0.\n",
        "    best_weights = model.state_dict()\n",
        "\n",
        "    for epoch in range(CFG.epochs):\n",
        "      print(f'Epoch: {epoch+1}/{CFG.epochs}')\n",
        "      #each epoch a phase of train and a phase of val\n",
        "      for phase in ['train', 'val']:\n",
        "        dataloader = cls.switch_trainval(model, phase)\n",
        "\n",
        "        model.to(device)\n",
        "        running_loss, running_acc = 0., 0.\n",
        "\n",
        "        #set X, y\n",
        "        for inputs, labels in tqdm(dataloader):\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "          #predict and adjust if train\n",
        "          optimizer.zero_grad()\n",
        "          with torch.set_grad_enabled(phase == 'train'):\n",
        "            y_pred = model(inputs)\n",
        "            loss_v = loss(y_pred, labels)\n",
        "            if phase == 'train':\n",
        "              loss_v.backward()\n",
        "              optimizer.step()\n",
        "          #calc train val stats\n",
        "          running_loss += loss_v.item()\n",
        "          running_acc += (y_pred.argmax(dim=1) == labels).float().mean().data.cpu().numpy()\n",
        "        if phase == 'train' and scheduler:\n",
        "          scheduler.step()\n",
        "        #calc epoch stats\n",
        "        epoch_loss = running_loss / len(dataloader)\n",
        "        epoch_acc = running_acc / len(dataloader)\n",
        "        cls.log_wandb(phase, epoch_loss, epoch_acc)\n",
        "        display.clear_output()\n",
        "        print(f'Epoch:{epoch+1}, loss:{round(epoch_loss,3)}, accuracy: {round(epoch_acc,3)}')\n",
        "        #select best weights\n",
        "        if phase == 'val' and epoch_acc > best_acc:\n",
        "          best_acc = epoch_acc\n",
        "          best_weights = model.state_dict()\n",
        "        #write for history\n",
        "        loss_hist[phase].append(epoch_loss)\n",
        "        acc_hist[phase].append(epoch_acc)\n",
        "    torch.save(best_weights, '/content/'+f'{CFG.model_name}_best.pth')\n",
        "    return model, loss_hist, acc_hist\n"
      ],
      "metadata": {
        "id": "Oj0eOcSoOEjb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleModel, self).__init__()\n",
        "\n",
        "        # Define your layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(16 * 224 * 224, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "ueSinyxtjlbr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CFG._set_model_name('SimpleModel')\n",
        "CFG._set_lr(3e-3)\n",
        "\n",
        "CFG._set_epochs(10)\n",
        "print(CFG.epochs, CFG.lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD6hv5alrHQD",
        "outputId": "d9cd0b31-216f-4242-984f-d10bc3c0645d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 0.003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CFG._switchflag()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6euK8zElUCQ2",
        "outputId": "1c4c7bf3-de82-4bac-b33c-e287c53bc4bd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wandb logging: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qq = SimpleModel(10)\n",
        "optimizer = torch.optim.AdamW(qq.parameters(), CFG.lr)\n",
        "Performer.train_val(qq, optimizer, scheduler = StepLR(optimizer, step_size=CFG.step_size, gamma=CFG.gamma))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "KWteTq7gjmVh",
        "outputId": "2e1149f0-efaf-4a7a-a09c-74fa92e8eb1f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:15, loss:1.922, accuracy: 0.354\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(SimpleModel(\n",
              "   (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "   (relu): ReLU()\n",
              "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "   (fc): Linear(in_features=802816, out_features=10, bias=True)\n",
              " ),\n",
              " {'train': [5.790056021582033,\n",
              "   2.4837271909455994,\n",
              "   2.2203714607937917,\n",
              "   2.169712279948431,\n",
              "   2.085303667227964,\n",
              "   2.0654405330282612,\n",
              "   2.022474389825318,\n",
              "   2.0322642294136255,\n",
              "   2.003359331271133,\n",
              "   2.003437509105818,\n",
              "   2.0088080401356154,\n",
              "   1.9963812148953612,\n",
              "   1.9838164703467407,\n",
              "   1.9827070006144207,\n",
              "   1.9843518790361043],\n",
              "  'val': [1.9522622985776719,\n",
              "   1.9033764765850152,\n",
              "   1.8692474036255582,\n",
              "   1.9008410462536782,\n",
              "   1.9540871470377548,\n",
              "   1.9426148291032328,\n",
              "   1.939178070929774,\n",
              "   1.9284272401493097,\n",
              "   1.9078649209618812,\n",
              "   1.9282657932603917,\n",
              "   1.8962306041581567,\n",
              "   1.9212714686170371,\n",
              "   1.9480690486319439,\n",
              "   1.8994587652552153,\n",
              "   1.9223298510563107]},\n",
              " {'train': [0.23788006757260174,\n",
              "   0.297043918921436,\n",
              "   0.3139991554104396,\n",
              "   0.3157939189239531,\n",
              "   0.3153293919120286,\n",
              "   0.32075591216719634,\n",
              "   0.326520270290407,\n",
              "   0.32238175675927383,\n",
              "   0.32987753378630086,\n",
              "   0.33044763513513514,\n",
              "   0.3282516891942234,\n",
              "   0.3297297297347639,\n",
              "   0.33127111488500155,\n",
              "   0.3338471283834126,\n",
              "   0.32683699326337995],\n",
              "  'val': [0.38207739312391414,\n",
              "   0.3679735234458675,\n",
              "   0.36359470469645716,\n",
              "   0.37046843178403355,\n",
              "   0.3261710794418747,\n",
              "   0.3558044806578009,\n",
              "   0.3438391038757235,\n",
              "   0.3516293279143798,\n",
              "   0.3710794297413039,\n",
              "   0.35605906314252594,\n",
              "   0.36013238289812677,\n",
              "   0.34994908350912474,\n",
              "   0.3517311609022001,\n",
              "   0.35224032587165016,\n",
              "   0.3542769857494506]})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing a model and freezing layers"
      ],
      "metadata": {
        "id": "6DZ0RnSArZE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "namelist = ['resnet50', 'resnext101_32x8d', 'inception_v3', 'densenet169', 'efficientnet_b0']"
      ],
      "metadata": {
        "id": "vPF5flwRZ4zU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransferModel(torch.nn.Module):\n",
        "  def __init__(self, name='resnet50', value=10):\n",
        "    super().__init__()\n",
        "    self.model = timm.create_model(name, pretrained=True)\n",
        "    self.freeze_me()\n",
        "    self.give_head(name, value)\n",
        "\n",
        "  def give_head(self, name, value):\n",
        "    #sic!\n",
        "    if 'effi' in name:\n",
        "      self.classifier_head_eff(value)\n",
        "    else:\n",
        "      self.classifier_head(value)\n",
        "\n",
        "  def classifier_head_eff(self, value):\n",
        "    inputs = self.model.classifier.in_features\n",
        "    #self.model.classifier = nn.Identity()\n",
        "    self.model.classifier = nn.Linear(inputs, value)\n",
        "\n",
        "  def classifier_head(self, value):\n",
        "    inputs = self.model.fc.in_features\n",
        "    self.model.fc = nn.Linear(inputs, value)\n",
        "\n",
        "  def freeze_me(self):\n",
        "    model_len = len(list(self.model.parameters()))\n",
        "    for idx, param in enumerate(self.model.parameters()):\n",
        "      param.requires_grad = False if idx < model_len-2 else True\n",
        "\n",
        "  @property\n",
        "  def params(self):\n",
        "    layers = list(self.model.parameters())[:-2] + list(self.parameters())[-2:]\n",
        "    return layers\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)"
      ],
      "metadata": {
        "id": "ewPhfftHZeTW"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Freezing all layers except the last one"
      ],
      "metadata": {
        "id": "2GXLdj9-rq6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransferModel()\n",
        "summary(model=model,\n",
        "        input_size= (CFG.batch_size, 3, CFG.size, CFG.size),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20)"
      ],
      "metadata": {
        "id": "xyFeO6SqsV23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804e0066-0a6c-4aed-c0e9-bf7ad0c85eb2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=============================================================================================================================\n",
              "Layer (type:depth-idx)                        Input Shape          Output Shape         Param #              Trainable\n",
              "=============================================================================================================================\n",
              "TransferModel                                 [8, 3, 224, 224]     [8, 10]              --                   Partial\n",
              "├─ResNet: 1-1                                 [8, 3, 224, 224]     [8, 10]              --                   Partial\n",
              "│    └─Conv2d: 2-1                            [8, 3, 224, 224]     [8, 64, 112, 112]    (9,408)              False\n",
              "│    └─BatchNorm2d: 2-2                       [8, 64, 112, 112]    [8, 64, 112, 112]    (128)                False\n",
              "│    └─ReLU: 2-3                              [8, 64, 112, 112]    [8, 64, 112, 112]    --                   --\n",
              "│    └─MaxPool2d: 2-4                         [8, 64, 112, 112]    [8, 64, 56, 56]      --                   --\n",
              "│    └─Sequential: 2-5                        [8, 64, 56, 56]      [8, 256, 56, 56]     --                   False\n",
              "│    │    └─Bottleneck: 3-1                   [8, 64, 56, 56]      [8, 256, 56, 56]     (75,008)             False\n",
              "│    │    └─Bottleneck: 3-2                   [8, 256, 56, 56]     [8, 256, 56, 56]     (70,400)             False\n",
              "│    │    └─Bottleneck: 3-3                   [8, 256, 56, 56]     [8, 256, 56, 56]     (70,400)             False\n",
              "│    └─Sequential: 2-6                        [8, 256, 56, 56]     [8, 512, 28, 28]     --                   False\n",
              "│    │    └─Bottleneck: 3-4                   [8, 256, 56, 56]     [8, 512, 28, 28]     (379,392)            False\n",
              "│    │    └─Bottleneck: 3-5                   [8, 512, 28, 28]     [8, 512, 28, 28]     (280,064)            False\n",
              "│    │    └─Bottleneck: 3-6                   [8, 512, 28, 28]     [8, 512, 28, 28]     (280,064)            False\n",
              "│    │    └─Bottleneck: 3-7                   [8, 512, 28, 28]     [8, 512, 28, 28]     (280,064)            False\n",
              "│    └─Sequential: 2-7                        [8, 512, 28, 28]     [8, 1024, 14, 14]    --                   False\n",
              "│    │    └─Bottleneck: 3-8                   [8, 512, 28, 28]     [8, 1024, 14, 14]    (1,512,448)          False\n",
              "│    │    └─Bottleneck: 3-9                   [8, 1024, 14, 14]    [8, 1024, 14, 14]    (1,117,184)          False\n",
              "│    │    └─Bottleneck: 3-10                  [8, 1024, 14, 14]    [8, 1024, 14, 14]    (1,117,184)          False\n",
              "│    │    └─Bottleneck: 3-11                  [8, 1024, 14, 14]    [8, 1024, 14, 14]    (1,117,184)          False\n",
              "│    │    └─Bottleneck: 3-12                  [8, 1024, 14, 14]    [8, 1024, 14, 14]    (1,117,184)          False\n",
              "│    │    └─Bottleneck: 3-13                  [8, 1024, 14, 14]    [8, 1024, 14, 14]    (1,117,184)          False\n",
              "│    └─Sequential: 2-8                        [8, 1024, 14, 14]    [8, 2048, 7, 7]      --                   False\n",
              "│    │    └─Bottleneck: 3-14                  [8, 1024, 14, 14]    [8, 2048, 7, 7]      (6,039,552)          False\n",
              "│    │    └─Bottleneck: 3-15                  [8, 2048, 7, 7]      [8, 2048, 7, 7]      (4,462,592)          False\n",
              "│    │    └─Bottleneck: 3-16                  [8, 2048, 7, 7]      [8, 2048, 7, 7]      (4,462,592)          False\n",
              "│    └─SelectAdaptivePool2d: 2-9              [8, 2048, 7, 7]      [8, 2048]            --                   --\n",
              "│    │    └─AdaptiveAvgPool2d: 3-17           [8, 2048, 7, 7]      [8, 2048, 1, 1]      --                   --\n",
              "│    │    └─Flatten: 3-18                     [8, 2048, 1, 1]      [8, 2048]            --                   --\n",
              "│    └─Linear: 2-10                           [8, 2048]            [8, 10]              20,490               True\n",
              "=============================================================================================================================\n",
              "Total params: 23,528,522\n",
              "Trainable params: 20,490\n",
              "Non-trainable params: 23,508,032\n",
              "Total mult-adds (G): 32.70\n",
              "=============================================================================================================================\n",
              "Input size (MB): 4.82\n",
              "Forward/backward pass size (MB): 1422.59\n",
              "Params size (MB): 94.11\n",
              "Estimated Total Size (MB): 1521.52\n",
              "============================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CFG._set_epochs(10)\n",
        "CFG._set_lr(4e-4)\n",
        "CFG._set_model_name(namelist[0])\n",
        "CFG._get_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ploDlsAteJ5V",
        "outputId": "3dd3e51e-3168-4b9b-82b6-6a22f6dbd09e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_workers': 2,\n",
              " 'model_name': 'resnet50',\n",
              " 'size': 224,\n",
              " 'scheduler': 'StepLR',\n",
              " 'epochs': 10,\n",
              " 'step_size': 20,\n",
              " 'gamma': 0.1,\n",
              " 'lr': 0.0004,\n",
              " 'min_lr': 1e-06,\n",
              " 'batch_size': 8,\n",
              " 'seed': 42}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CFG._switchflag()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjHX266ohmGz",
        "outputId": "76b399ff-7257-4b24-bced-23402be66d8d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wandb logging: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.params, lr = CFG.lr)\n",
        "scheduler = StepLR(optimizer, step_size=CFG.step_size, gamma=CFG.gamma)\n",
        "Performer.train_val(model, optimizer, scheduler = scheduler)"
      ],
      "metadata": {
        "id": "DK5kEPtWrwSK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "316a92c8-20d5-4080-e096-c7b3018d826a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:10, loss:0.101, accuracy: 0.976\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TransferModel(\n",
              "   (model): ResNet(\n",
              "     (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (act1): ReLU(inplace=True)\n",
              "     (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "     (layer1): Sequential(\n",
              "       (0): Bottleneck(\n",
              "         (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act1): ReLU(inplace=True)\n",
              "         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (drop_block): Identity()\n",
              "         (act2): ReLU(inplace=True)\n",
              "         (aa): Identity()\n",
              "         (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act3): ReLU(inplace=True)\n",
              "         (downsample): Sequential(\n",
              "           (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "           (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         )\n",
              "       )\n",
              "       (1): Bottleneck(\n",
              "         (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act1): ReLU(inplace=True)\n",
              "         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (drop_block): Identity()\n",
              "         (act2): ReLU(inplace=True)\n",
              "         (aa): Identity()\n",
              "         (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act3): ReLU(inplace=True)\n",
              "       )\n",
              "       (2): Bottleneck(\n",
              "         (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act1): ReLU(inplace=True)\n",
              "         (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "         (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (drop_block): Identity()\n",
              "         (act2): ReLU(inplace=True)\n",
              "         (aa): Identity()\n",
              "         (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act3): ReLU(inplace=True)\n",
              "       )\n",
              "     )\n",
              "     (layer2): Sequential(\n",
              "       (0): Bottleneck(\n",
              "         (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act1): ReLU(inplace=True)\n",
              "         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (drop_block): Identity()\n",
              "         (act2): ReLU(inplace=True)\n",
              "         (aa): Identity()\n",
              "         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act3): ReLU(inplace=True)\n",
              "         (downsample): Sequential(\n",
              "           (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "           (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         )\n",
              "       )\n",
              "       (1): Bottleneck(\n",
              "         (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act1): ReLU(inplace=True)\n",
              "         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (drop_block): Identity()\n",
              "         (act2): ReLU(inplace=True)\n",
              "         (aa): Identity()\n",
              "         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act3): ReLU(inplace=True)\n",
              "       )\n",
              "       (2): Bottleneck(\n",
              "         (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act1): ReLU(inplace=True)\n",
              "         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (drop_block): Identity()\n",
              "         (act2): ReLU(inplace=True)\n",
              "         (aa): Identity()\n",
              "         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act3): ReLU(inplace=True)\n",
              "       )\n",
              "       (3): Bottleneck(\n",
              "         (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act1): ReLU(inplace=True)\n",
              "         (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "         (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (drop_block): Identity()\n",
              "         (act2): ReLU(inplace=True)\n",
              "         (aa): Identity()\n",
              "         (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act3): ReLU(inplace=True)\n",
              "       )\n",
              "     )\n",
              "     (layer3): Sequential(\n",
              "       (0): Bottleneck(\n",
              "         (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act1): ReLU(inplace=True)\n",
              "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (drop_block): Identity()\n",
              "         (act2): ReLU(inplace=True)\n",
              "         (aa): Identity()\n",
              "         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act3): ReLU(inplace=True)\n",
              "         (downsample): Sequential(\n",
              "           (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "           (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         )\n",
              "       )\n",
              "       (1): Bottleneck(\n",
              "         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act1): ReLU(inplace=True)\n",
              "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (drop_block): Identity()\n",
              "         (act2): ReLU(inplace=True)\n",
              "         (aa): Identity()\n",
              "         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act3): ReLU(inplace=True)\n",
              "       )\n",
              "       (2): Bottleneck(\n",
              "         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act1): ReLU(inplace=True)\n",
              "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (drop_block): Identity()\n",
              "         (act2): ReLU(inplace=True)\n",
              "         (aa): Identity()\n",
              "         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act3): ReLU(inplace=True)\n",
              "       )\n",
              "       (3): Bottleneck(\n",
              "         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act1): ReLU(inplace=True)\n",
              "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (drop_block): Identity()\n",
              "         (act2): ReLU(inplace=True)\n",
              "         (aa): Identity()\n",
              "         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act3): ReLU(inplace=True)\n",
              "       )\n",
              "       (4): Bottleneck(\n",
              "         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act1): ReLU(inplace=True)\n",
              "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (drop_block): Identity()\n",
              "         (act2): ReLU(inplace=True)\n",
              "         (aa): Identity()\n",
              "         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act3): ReLU(inplace=True)\n",
              "       )\n",
              "       (5): Bottleneck(\n",
              "         (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act1): ReLU(inplace=True)\n",
              "         (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "         (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (drop_block): Identity()\n",
              "         (act2): ReLU(inplace=True)\n",
              "         (aa): Identity()\n",
              "         (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act3): ReLU(inplace=True)\n",
              "       )\n",
              "     )\n",
              "     (layer4): Sequential(\n",
              "       (0): Bottleneck(\n",
              "         (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act1): ReLU(inplace=True)\n",
              "         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (drop_block): Identity()\n",
              "         (act2): ReLU(inplace=True)\n",
              "         (aa): Identity()\n",
              "         (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act3): ReLU(inplace=True)\n",
              "         (downsample): Sequential(\n",
              "           (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "           (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         )\n",
              "       )\n",
              "       (1): Bottleneck(\n",
              "         (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act1): ReLU(inplace=True)\n",
              "         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (drop_block): Identity()\n",
              "         (act2): ReLU(inplace=True)\n",
              "         (aa): Identity()\n",
              "         (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act3): ReLU(inplace=True)\n",
              "       )\n",
              "       (2): Bottleneck(\n",
              "         (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act1): ReLU(inplace=True)\n",
              "         (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "         (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (drop_block): Identity()\n",
              "         (act2): ReLU(inplace=True)\n",
              "         (aa): Identity()\n",
              "         (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "         (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "         (act3): ReLU(inplace=True)\n",
              "       )\n",
              "     )\n",
              "     (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "     (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
              "   )\n",
              " ),\n",
              " {'train': [1.1256690794803403,\n",
              "   0.6278223868119657,\n",
              "   0.527897057129775,\n",
              "   0.4737303789352646,\n",
              "   0.444141887420178,\n",
              "   0.421685752446285,\n",
              "   0.4096567108662802,\n",
              "   0.3905124663730463,\n",
              "   0.3779535958314522,\n",
              "   0.3784837403127804],\n",
              "  'val': [0.5288184753442733,\n",
              "   0.2933661837563252,\n",
              "   0.19183307240457254,\n",
              "   0.15592834534115954,\n",
              "   0.1256785519708464,\n",
              "   0.11632046095890329,\n",
              "   0.13550039193386215,\n",
              "   0.14467959141912595,\n",
              "   0.09360802529748176,\n",
              "   0.10069061279161255]},\n",
              " {'train': [0.7867398648648649,\n",
              "   0.8400337838039205,\n",
              "   0.8460937500050342,\n",
              "   0.8620143581081081,\n",
              "   0.8664273648850016,\n",
              "   0.8731418919019602,\n",
              "   0.8756334459459459,\n",
              "   0.8783783783783784,\n",
              "   0.8841849662162162,\n",
              "   0.8821157094695278],\n",
              "  'val': [0.9598778004316109,\n",
              "   0.9631873727330366,\n",
              "   0.9741344195762137,\n",
              "   0.9720977596984133,\n",
              "   0.9746435845456638,\n",
              "   0.9764256619387391,\n",
              "   0.9726069246678634,\n",
              "   0.970570264790063,\n",
              "   0.9812627291485151,\n",
              "   0.9759164969692891]})"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CFG._switchflag()"
      ],
      "metadata": {
        "id": "yUds8nAvkRZp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}