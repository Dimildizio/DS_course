This folder contains reports and visualizations summarizing our findings and results.

The group projects has been successfully finished. We Got a best score of 0.12334 which is about 500 of current 4500 competitors. 

What hasn't been done: Could have used SVM in Stacking, it has showm remarkable results (and pretty bad if solo).

Didn't have neither time nor desire to work with CatBoost due to the architecture of the code we already had and difficulties implementing it and it's hyperparameters (and choosing them) into a fully-written structure. Anyways, would be a good idea to study it at our own pace, if got time and willingness to write a function for training and selecting model from scratch. Judging by the results of others - CatBoost is a slow but magic pill that does most of the work for you, so thats a must for learning ml models and should be on our todo. Id does increase results a bit, but not that much. Even though it work basically out of the box. One thing left is use KFolds which might help as well since batches do inrease performance.
