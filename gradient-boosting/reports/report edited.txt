Добрый день, меня зовут ____
Наша команда состоит из _______
Нашим проектом было выбрано соревнование по предсказанию цен в Айове на каггле.

Соревнование: ключ к позициям заключается в правильно проведенном еда и преобразовании\отбрасывании  параметров. метрикой соревнования является рмсе разницы логарифмов предсказанной и реальной стоимости. У нас 79 параметров + таргет и 1460 значений на трейне и 1459 на тесте, временной промежуток до 2010года.
После беглого просмотра чужих работ и чтения туториала самым очевидным казалось скопировать чужую работу, скажем по тензорфлоу или хотя бы ЕДА что с легкостью позволило бы впрыгнуть в значения 0.1 - 0.11 но поскольку нашей целью являлась не позиция а овладения навыками, то было решено писать еда и бейзлайн с нуля и посмотреть куда нас это приведет. Стоит отметить, что на каггле изначально датасет был больше, но затем он был разделен на два и в недрах лежит менее популярное соревнование которое содержит все целевые значения тестовой выборки и выводит участника в топ1 с результатом 0.0044 но и этот вариант бы с отвращением отброшен. В целом было решено работать с тем набором знаний, который мы имели, не прибегая к тензорфлоу, керасу и торчу.

Для работы в команде было решено ввести регулярные совещания каждые два дня, ведение реестра обязанностей с помощью таск менеджера (из джиры, трелло и тудуиста выбор пал на последний). был создан правильно структурированный гитхаб репозиторий с документацией и разбиением на папки, куда пулреквестом подгружались новые изменения. Для логгинга был написан код что паковал json\словарь репортов в новый датасет тренировочную выборку, предсказанные значения теста, параметры модели и параметры преобразования столбцов - все это составляло один ряд, все это подгружалось на отдельно выделенный фтп (был выбран фтп а не облако, поскольку уже был готов) в процессе работы с моделью код автоматически должен был распаковывать датасет, вносить изменения\новый ряд если создавалась новая модель и перезаписывать на фтп. Знали бы про WandB или MLFlow воспользовались бы им.

После стандартной работы с датасетом дейскрайб и инфо мы преобразовали категориальные типы данных из объекта в категорию а количественные из флоат и нам64 в 32 для ускорения работы. 

Затем в работе с пустыми значениями пустые категориальные колонки были заполнены новой категорией Missing, а количественные - модой, средним и нулями в зависимости от нашего понимая значения колонки.
Анализ параметров также привел к мысли, что столбец OverallQual имеет высокую степень корреляции с ценой и по сути является искусственным параметром объединяющим в себя большинство категориальных и количественных признаков. Последующая работа с выбором наилучших признаков велась с автоматическим отбрасывание этого параметра

Прежде чем проводить выбросов, решено было логарифмизировать параметры и привести их к единому спектру значений. Были исследованы несколько вариантов преобразования выложенные на сайте ibm, но ни один метод преобразования количественных признаков (ни корень, ни возведение в квадрат) не дал такого существенного прироста как логарифмизация. Чтоб избежать отрицательных значений, каждый параметр проверили на наличие значений ниже нуля, и ко всем значениям прибавили 1 затем проведя тест улучшается ли результата.

Отброс выбросов в пределах iqr*3 показал лучший результат чем 1.5, а так же работа на уже логарифмированных данных оказалась лучше чем без, что позволило сохранить значительное количество рядов.

Количественные признаки отбрасывались согласно матрице корреляции и пеирплота с таргетом. Некоторые признаки как GarageCars и GarageArea показали высокую коллинеарность, выше 80% и один был отброшен.
Качественные признаки, увы, на разных типах энкодинга не показали значительного прироста, несмотря на высокую корреляцию с ценой. Важным фактором здесь оказалось что OverallQual OverallCond уже описывают качественные признаки, поэтому в итоговую выборку попали только Нейборхуд и форма участка и качество камина как те, которые показывали наибольшую корреляцию с ценой, но и они были не обязательны. Из всех типов проверенных энкодигов мы остановили на таргет энкодинге, а OHE было отброшено как создающее слишком много новых параметров. В итоговой выборке оказалось около 15-20 параметров, включая искусственные, что увеличило скорость работы, но возможно сказалось на результате. 
Были введены фиктивные переменные такие как наличие деревянной веранды, наличие второго этажа. Некоторые булевые переменные такие как наличие бассейна ноборот ухудшали результат. Фича инжиниринг позволил нам создать дополнительные количественные переменные, в частности - общий размер веранды, общая площадь, количеству ванных комнат и нежилая площадь территории.

Приступая к созданию бейзлайны мы определили r2 как показатель нашего результата с рмсе как ориентировка на то, как проверяются данные на каггле. В последствии благодаря полезным советам мы пришли к adjusted r2 как более точном показателе работы с большим количеством параметров.
Были выдвинуты гипотезы, в частности что порядок поданных переменных имеет значение, удаление выбросов на результате и перетренировка повышает качество, отсутствие валидационной выборки и тренировка на полном датасете и предсказание на тестовом дадут лучший резлуьтат. Ни одна из них не оправдалась. Последняя - поскольку у нас осталось достаточно рядов после iqr.

Бейзлайн. Был написан стандарьный бейзлайн с линейной регрессией. Но так же были в ручную для понимания принципа работы пермутаций написан код для отбора самый лучших признаков что влияют на модель, а так же функция для шаффла что меняла очередность - ошибочное направление что мы выбрали и которое занимало много времени - модель запускалась каждый шафл для каждого параметра создавая список наилучших параметров. К тому же изза ошибки индентации модель отбирала некоторые повторяющиеся признаки несколько раз, повышая их значение в случае использования линейной модели. В последствии эти функции были замененные встроенными кросс валидейшн скор и пермутейшн импортансез, что давали тот же результат но быстрее. Гипотеза что порядок имеет значения была ложно принята поскольку модель каждый раз тренируется по разному, а мы восприняли другой результат как влияние другой очередности переменных.
Пробовали понижать размерность используя ПСА, что могло бы увеличить скорость, но резултата это не дало. Пробовали нормализацию, стандард скейлер и затем робаст скейлер. Нормализация показала худший результат, а робаст скейлер (на медианах и iqr)- лучший. 
Автоматизировали систему с помощью пайплайна, куда вкладывали разные модели - от кнн, бэггинга линейных регрессиях до стекинга, на котором в итоге и остановились - линейная регресия, решающее дерево, лайт гбм регрессор, лассо регрессия с кроссвалидацией и методом меньших углов, эластик нет (лог регрессия), поскольку все еще есть коррелирующие переменные, финальным эстиматором был выбран решающий лес. Гиперпараметры подбирались сперва с помощью грид серча на заданных константах, а затем рандом серча, в пределах близких к значениям выдаваемых грид серчем. Найденный в чужих работах результат усреднения предсказанных данных с реальными и запуском обучения заново значительных результатов не дал. ШАП хоть и показал значения переменных, но не оказался лучше permuation importance в контексте резлультата отобранных на его основе параметров. Гипотеза с увеличением выборки за счет объединения предсказанных данных с тестовым датасетом, а затем объединния 0.6 семпла этого с трейновым и новым обучением на этом датасете значительного прироста не показал также. Последней попыткой улучшить модель стал блендин на Voteregressor'e что отдельно тренировал несколько моделей - стеккинг, xgboost и лассо регрессии, но и это не дало необходимого прироста. Модель пришла к стабильности, когда ни какое отдельно взятое изменение - будь то модель в стекинге или логарифмизация параметра или добавление нового параметра никак не меняло бы существенно результат.
Хотелось бы отметить что нам повезло с самого начала сделать провести качественную работу по ЕДА, что стала выдавать 85% р2 вместо 64% что сразу забросило нас в рейтинге в первые 0.13% от соревнующихся - 1200 из 4500 текущих (стоит отметить тех кто читерил с вторым датасетом и копировал чужие ноутбуки) далее плотность оказалось значительной как раз в этом сегменте и небольшой прирост подбрасывал сразу на 100-200 позиций вверх, мы и закончили с результатом на 400-500 месте с результатом .12334

Выводы:
1. На цены влияет множество факторов таких как место, возраст, качество и размер дома.
2. Линрегрессия вполне неплохо справляется с задачей, более совершенные модели и ансамбли хоть и бают прирост, но он не такой значительный
3. Фича инжиниринг и подбор гиперпараметров улучшают результат.
4. Правильно проведенная ЕДА заключает в себе самую большую часть успеха.

Рекомендации покупателям:
1. Место имеет значение. Некоторые районы значительно влияют на цену.
2. Размер и возраст дома имеют важное значение. 
3. Дата последнего ремонта имеет значение - если хочется недвижимость подешевле, можно въехать и лишь затем ремонт проводить, если же есть финансы въехать на все готовое, то стоит рассматривать либо новые дома либо со свежей датой последнего ремонта.

Cпасибо за внимание
