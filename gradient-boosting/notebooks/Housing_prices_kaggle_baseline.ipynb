{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimildizio/DS_course/blob/main/gradient-boosting/notebooks/Housing_prices_kaggle_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install catboost\n",
        "!pip install category_encoders"
      ],
      "metadata": {
        "id": "chjZYHAKmr0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba79f003-be63-4d34-8679-da5e5c4446c4"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.9/dist-packages (2.6.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.5.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (0.13.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (0.5.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.5->category_encoders) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from statsmodels>=0.9.0->category_encoders) (23.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "id": "GzRAxg9WsqCF"
      },
      "outputs": [],
      "source": [
        "import ftplib\n",
        "import io\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "#from catboost import CatBoostRegressor\n",
        "from category_encoders import TargetEncoder\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "from lightgbm import LGBMRegressor\n",
        "from matplotlib import pyplot as plt\n",
        "from random import shuffle\n",
        "from scipy import stats\n",
        "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, StackingRegressor\n",
        "from sklearn.linear_model import LassoLarsCV, LinearRegression, SGDRegressor, \\\n",
        "LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder,\\\n",
        "Normalizer\n",
        "from sklearn.tree import DecisionTreeRegressor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "id": "9xqpawjctOhV"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('max_colwidth', 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "id": "7AK-K2sOtO7g"
      },
      "outputs": [],
      "source": [
        "raw_df_train = pd.read_csv('https://raw.githubusercontent.com/Dimildizio/DS_course/main/gradient-boosting/data/train.csv', index_col=0)\n",
        "raw_df_test = pd.read_csv('https://raw.githubusercontent.com/Dimildizio/DS_course/main/gradient-boosting/data/test.csv', index_col=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_cat(df, col):\n",
        "  '''checks if a column is of object or category type'''\n",
        "  return df[col].dtype in ['object', 'category']"
      ],
      "metadata": {
        "id": "mlvPC7TzTl4q"
      },
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "id": "Aoz93DTHtRQq"
      },
      "outputs": [],
      "source": [
        "def improve_cats(dataframe) -> pd.DataFrame:\n",
        "  '''turns dtypes 64->32 and object->category'''\n",
        "  df = dataframe.copy()\n",
        "  for col in df.columns:\n",
        "    if df[col].dtype == 'int64':\n",
        "      df[col] = df[col].astype('int32')\n",
        "    elif df[col].dtype == 'float64':\n",
        "      df[col] = df[col].astype('float32')\n",
        "    elif df[col].dtype == 'object':\n",
        "      df[col] = df[col].astype('category')\n",
        "    else:\n",
        "      print('Unknown data type')\n",
        "      return\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "id": "RpsoL7rwuMRx"
      },
      "outputs": [],
      "source": [
        "#Change after we get encoding\n",
        "def get_valid_cols(df, ok_cols, to_drop=[]):\n",
        "  '''selects all coumns that are not in handpicked list, shouldn't be dropped and not categorical''' \n",
        "  return [x for x in df.columns if x not in ok_cols+to_drop and not is_cat(df, x)] #Change when cats are encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "id": "-zMivoOvuhVe"
      },
      "outputs": [],
      "source": [
        "def split_data(df, target):\n",
        "  '''splits data'''\n",
        "  X = df.drop(target, axis=1)\n",
        "  y = df[target]\n",
        "  return train_test_split(X, y, test_size=0.2, random_state=13)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "id": "hp4ISXf0ukFr"
      },
      "outputs": [],
      "source": [
        "#Could run separate times for y_pred_train, y_pred_test but training two could take longer \n",
        "def run_model(X_train, y_train, X_test, model = LinearRegression):\n",
        "  '''creates a pipeline for a model and predicts the results'''\n",
        "  \n",
        "  estimators = [('LinReg',LinearRegression()), ('Tree',DecisionTreeRegressor(max_depth=5)),\n",
        "                ('LGBR', LGBMRegressor(max_depth = 5, learning_rate = 0.04))]#, ('KNN', KNeighborsRegressor))]\n",
        "                #'Bag',BaggingRegressor(estimator=LinearRegression(), n_estimators=5, random_state=42)),\n",
        "\n",
        "  pipe = make_pipeline(StandardScaler(), LinearRegression())#StackingRegressor(estimators=estimators, final_estimator=  RandomForestRegressor(max_depth = 6))) #RandomForestRegressor(max_depth=7)))\n",
        "                       #KNeighborsRegressor(n_neighbors = 10))#BaggingRegressor(estimator=LinearRegression(), n_estimators=5, random_state=42))#LogisticRegressionCV())#( max_depth=10))\n",
        "  pipe.fit(X_train, y_train)\n",
        "\n",
        "  y_pred_train = pipe.predict(X_train)\n",
        "  y_pred_test = pipe.predict(X_test)\n",
        "  return y_pred_train, y_pred_test, pipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "id": "OEJsDrC8x6Eh"
      },
      "outputs": [],
      "source": [
        "def split_run_test(df, target = 'SalePrice'):\n",
        "  '''splits data and runs model'''\n",
        "  X_train, X_test, y_train, y_test = split_data(df, target)\n",
        "  y_pred_train, y_pred_test, model = run_model(X_train, y_train, X_test)\n",
        "\n",
        "  text = print_scores(y_train, y_test, y_pred_train, y_pred_test, len(X_train.columns), print_train=True)\n",
        "  return model, text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adjusted_r2(yt,yp, colnum):\n",
        "  #computes adjusted r2 score\n",
        "   return 1 - (1 - r2_score(yt, yp)) * ((yt.shape[0]-1) / (yt.shape[0] - colnum))"
      ],
      "metadata": {
        "id": "5F1WYoyzywyw"
      },
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "id": "vm0BiE4wumyu"
      },
      "outputs": [],
      "source": [
        "def print_scores(y_train, y_test, y_pred_train, y_pred_test, colnum, print_train=False):\n",
        "  '''outprints adjusted r2 and rmse results on train and validation'''\n",
        "  train_r2 =  adjusted_r2(y_train, y_pred_train, colnum)\n",
        "  test_r2 = adjusted_r2(y_test,y_pred_test, colnum)\n",
        "  train_rmse = np.sqrt(mean_squared_error(np.log(y_pred_train), np.log(y_train)))\n",
        "  test_rmse = np.sqrt(mean_squared_error(np.log(y_pred_test), np.log(y_test)))\n",
        "\n",
        "  text = f'train r2: {train_r2}\\ntrain rmse: {train_rmse}\\n\\ntest r2: {test_r2}\\ntest rmse: {test_rmse}\\n'\n",
        "\n",
        "  '''#if print_train:\n",
        "  #print('train: r2', r2_score(y_train, y_pred_train))\n",
        "  print('train adjusted r2:', train_r2)\n",
        "  print(\"train: root mean squared error:\", train_rmse)\n",
        "  print('Test:')\n",
        "  #print('test: r2', r2_score(y_test, y_pred_test))\n",
        "  print('test adjusted r2:', test_r2)\n",
        "  print(\"test: root mean squared error:\", test_rmse)'''\n",
        "  print(text)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "id": "5S9NxpvfuqBR"
      },
      "outputs": [],
      "source": [
        "def find_best_param(dataset: pd.DataFrame, valid_cols: list, ok_cols: list, to_drop = [], r2_threshold = 0.67, target = \"SalePrice\"):\n",
        "  '''loops through all valid columns tries to find columns that give the best r2 result if added to handpicked ones'''\n",
        "\n",
        "  dataset = dataset.copy()\n",
        "  best_col = ['', r2_threshold]\n",
        "  \n",
        "  for col in valid_cols:\n",
        "    test_cols = ok_cols + [col]\n",
        "    df = dataset[test_cols]\n",
        "  \n",
        "    try:\n",
        "      X_train, X_test, y_train, y_test = split_data(df, target)\n",
        "      y_pred_train, y_pred_test, _ = run_model(X_train, y_train, X_test)\n",
        "\n",
        "      r2 = adjusted_r2(y_test, y_pred_test, X_train.shape[1])\n",
        "      if r2 > r2_threshold:\n",
        "        r2_threshold = r2\n",
        "        best_col = [col, r2]\n",
        "        #print_scores(y_train, y_test, y_pred_train, y_pred_test)\n",
        "    except ValueError:\n",
        "      continue\n",
        "      #print(col, 'has NaN')\n",
        "  \n",
        "  result = ok_cols + [best_col[0]]\n",
        "  #print('Best result:', result, best_col[1])\n",
        "  return best_col\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "id": "xiLbLFEEuqEq"
      },
      "outputs": [],
      "source": [
        "def get_best_cols(df, ok_cols: list, to_drop =[],  r2_threshold=0.67):\n",
        "  '''shuffles the columns once and finds the set of columns that has the best r2'''\n",
        "  valid_cols = get_valid_cols(df_cats, ok_cols, to_drop)#\n",
        "  valid_nodups = valid_cols.copy()\n",
        "  shuffle(valid_cols)\n",
        "  #best_result = r2_threshold\n",
        "  for col in valid_cols:\n",
        "    #print(new_valid)\n",
        "    best_col, r2 = find_best_param(df_cats, valid_nodups, ok_cols, r2_threshold)\n",
        "    if r2 > r2_threshold:# > 0.001:\n",
        "      r2_threshold = r2\n",
        "      ok_cols.append(best_col)\n",
        "      valid_nodups.remove(col)\n",
        "  return ok_cols, r2_threshold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {
        "id": "qmin6wynvQEC"
      },
      "outputs": [],
      "source": [
        "def many_shuffles(df, my_cols = ['SalePrice', 'OverallQual'], to_drop = [], num=10, threshold = 0.67):\n",
        "  '''runs shuffle several times to find the best order of columns sets'''\n",
        "  bestestbest = [my_cols, threshold]\n",
        "  for x in range(num):\n",
        "    print('shuffle:', x+1)\n",
        "    result = get_best_cols(df, my_cols.copy(), to_drop)\n",
        "    if result[1] > bestestbest[1]:\n",
        "      bestestbest = result\n",
        "      print(bestestbest)\n",
        "  print('\\n\\nThe result is:')\n",
        "  print(bestestbest)\n",
        "  return bestestbest"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_new_cols(df):\n",
        "  #create Total SF\n",
        "  df[\"TotalSF\"] = df[\"1stFlrSF\"] + df[\"2ndFlrSF\"] + df[\"TotalBsmtSF\"] \n",
        "  #create Porch\n",
        "  df['PorchSF'] = df['OpenPorchSF'] + df['EnclosedPorch'] + df['3SsnPorch'] + df['ScreenPorch']\n",
        "  #Create green area\n",
        "  df[\"OutsideArea\"] = df[\"LotArea\"] - df[\"GrLivArea\"] - df[\"GarageArea\"] \n",
        "  #Create month sold * year\n",
        "  df['MonthSold'] = df['YrSold']*12 + df['MoSold'] #-df['YrSold'].min()\n",
        "  #dates_frames  = ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold','MoSold']\n",
        "\n",
        "  cols = ['KitchenAbvGr', 'BedroomAbvGr']\n",
        "\n",
        "  #Create booleans\n",
        "  bsmt = df['TotalBsmtSF']+df['BsmtFinSF1'] + df['BsmtFinSF2'] + df['BsmtUnfSF']\n",
        "  df['HasBsmt'] = bsmt.apply(lambda x: 1 if x > 0 else 0)  \n",
        "  df['Modern'] = df[['YearRemodAdd', 'YearBuilt']].max(axis=1).apply(lambda x: 1 if x > 2000 else 0)\n",
        "  df['Has2Floors'] = df['2ndFlrSF'].apply(lambda x: 1 if x>0 else 0)\n",
        "  df['HasGarage'] = df['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
        "  df['HasPool'] = df['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
        "  df['HasVnr'] = df['MasVnrArea'].apply(lambda x: 1 if x > 0 else 0)\n",
        "  #create bath\n",
        "  fullbsmtb = df['BsmtFullBath'].apply(lambda x: x if x > 0 else 0)\n",
        "  halfbsmtb = df['BsmtHalfBath'].apply(lambda x: x*0.5 if x > 0 else 0)\n",
        "  fullb = df['FullBath'].apply(lambda x: x if x > 0 else 0)\n",
        "  halfb = df['HalfBath'].apply(lambda x: x*0.5 if x > 0 else 0)\n",
        "  df['Bath'] = fullbsmtb + halfbsmtb + fullb + halfb\n",
        "\n",
        "  return df\n",
        "  \n",
        "# What to do with rooms?\n",
        "#df[['TotRmsAbvGrd', 'KitchenAbvGr','BedroomAbvGr','FullBath', 'HalfBath','BsmtFullBath','BsmtHalfBath']].head(10)"
      ],
      "metadata": {
        "id": "CiyYSAwaKUFA"
      },
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bp6LLGy3450J"
      },
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_cols(df):\n",
        "  #drop baths\n",
        "  df = df.drop(columns = ['BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath'])\n",
        "  #drop bsmt qual\n",
        "  #df = df.drop(columns = ['1stFlrSF', '2ndFlrSF', 'TotalBsmtSF'])\n",
        "  df = df.drop(columns=['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF'])\n",
        "  #drop porch\n",
        "  df = df.drop(columns = ['OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch'])\n",
        "  #drop garage\n",
        "  df = df.drop(columns=['GarageCars'])                                              \n",
        "  #drop misc\n",
        "  df = df.drop(columns=['LowQualFinSF', 'PoolArea', 'MiscVal', 'TotRmsAbvGrd', '1stFlrSF'])   \n",
        "  #drop separate year and month\n",
        "  #df_num = df_num.drop(columns = ['YrSold', 'MoSold'])\n",
        "\n",
        "  return df  "
      ],
      "metadata": {
        "id": "gEfOy-Sih-Fb"
      },
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fill_rows(df):\n",
        "  '''fills with values rows that have NaNs'''\n",
        "  df['GarageYrBlt'] = df['GarageYrBlt'].fillna(df['GarageYrBlt'].mean()) #REPLACE\n",
        "  return df\n",
        "  "
      ],
      "metadata": {
        "id": "U8yIL-59mKdL"
      },
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_cols(df, log_cols):\n",
        "  '''adds 1 to all numeric columns and np.logs handpicked columns'''\n",
        "  for column in [col for col in df.columns if not is_cat(df, col)]:\n",
        "    df[column] = df[column]+1\n",
        "\n",
        "  for col in log_cols:\n",
        "    df[col] = np.log(df[col])\n",
        "  return df"
      ],
      "metadata": {
        "id": "FG8zAZUgxJOc"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {
        "id": "pdUghZadtXju"
      },
      "outputs": [],
      "source": [
        "def drop_n_log(df, testdf=False):\n",
        "  '''runs drop, create new, log, fill functions'''\n",
        "  df_num = df.copy()\n",
        "\n",
        "  #Create new columns\n",
        "  df_num = create_new_cols(df_num)\n",
        "  #drop columns \n",
        "  df_num = drop_cols(df_num)\n",
        "  df_num = fill_rows(df_num)\n",
        "\n",
        "\n",
        "\n",
        "  #logs selected cols \n",
        "  target = [] if testdf else ['SalePrice']\n",
        "  to_log = target + ['LotFrontage', 'LotArea', 'GrLivArea']#, 'OutsideArea']#, 'TotalSF']#, 'GarageArea','WoodDeckSF', 'MasVnrArea','TotalBsmtSF','2ndFlrSF', 'PorchSF']#]#,]#, ]#, ]#]]\n",
        "  df_num = log_cols(df_num, to_log)\n",
        "\n",
        "  print(df_num.shape)\n",
        "  return df_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {
        "id": "gF4-TsSttsiN"
      },
      "outputs": [],
      "source": [
        "#Cut iqr\n",
        "def cut_iqr(df, col, mult):\n",
        "  '''cuts iqr*3 ouliers'''\n",
        "  d=df[col].describe()\n",
        "  val =(d['50%'] + (d['75%']-d['25%'])) * mult\n",
        "  return df[df[col] <= val]\n",
        "\n",
        "def plotme(df, col):\n",
        "    if col != 'SalePrice':\n",
        "      sns.scatterplot(y = df['SalePrice'], x = df[col])\n",
        "\n",
        "def make_iqr(df_num, testdf = False):\n",
        "  '''cuts iqr for selected columns and plots the graph'''\n",
        "  df_iqr = df_num.copy()\n",
        "  testdf = [] if testdf else ['SalePrice']\n",
        "  #for col in [x for x in df_num.columns if not is_cat(df_num, x)]:\n",
        "  for col in testdf+['LotFrontage', 'LotArea', 'MasVnrArea', \\\n",
        "              'TotalBsmtSF', 'GrLivArea', \\\n",
        "              'BedroomAbvGr', 'KitchenAbvGr', 'Fireplaces', 'GarageArea', 'PorchSF']:\n",
        "    df_iqr = cut_iqr(df_iqr, col, 3)\n",
        "    #plotme(df_iqr, col)\n",
        "\n",
        "  print(df_iqr.shape)\n",
        "  return df_iqr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "id": "QbG6xN0VtzoK"
      },
      "outputs": [],
      "source": [
        "#we need to remove empty values in categories if there are ones \n",
        "def cut_cats(df):\n",
        "  '''removes unused cats'''\n",
        "  for catcol in df.columns:\n",
        "    if is_cat(df, catcol):\n",
        "      df[catcol].cat.remove_unused_categories() \n",
        "  return df\n",
        "\n",
        "def create_mt_catcol(df_new):\n",
        "  '''if cat col has NaNs creates a MISSING category and assigns taht values to NaN cell'''\n",
        "  df = df_new.copy()\n",
        "  for col in df.columns:\n",
        "      if is_cat(df, col):\n",
        "        if df[col].isna().any():\n",
        "          df[col] = df[col].cat.add_categories(['MISSING'])\n",
        "          df[col] = df[col].fillna('MISSING')\n",
        "  df=cut_cats(df)\n",
        "  return df\n",
        "\n",
        "def factorize_cats(df):\n",
        "  '''factorizes a cat column'''\n",
        "  df = df.copy()\n",
        "  new_df=df.select_dtypes(include=['category']).apply(lambda x: x.factorize()[0])  \n",
        "  print(type(new_df))\n",
        "  for col in new_df.columns:\n",
        "    #print(col)\n",
        "    df[col] = new_df[col]\n",
        "  print(df.shape)\n",
        "  return df\n",
        "\n",
        "def encode_label(df):\n",
        "  for col in ['HouseStyle', 'FireplaceQu','LotShape', 'Foundation']:\n",
        "    encoder = LabelEncoder()\n",
        "    df[col+'_e'] = encoder.fit_transform(df[col])#, df['SalePrice'])\n",
        "  #df = pd.get_dummies(df, columns = ['LotShape', 'Foundation'])\n",
        "  return df\n",
        "\n",
        "\n",
        "def make_cats(df_iqr):\n",
        "  '''drops cat columns and runs other cat processing funcitons'''\n",
        "  df_iqr = df_iqr.copy()\n",
        "  df_iqr = encode_label(df_iqr)\n",
        "\n",
        "  df_cats = df_iqr.drop(columns = [col for col in df_iqr.columns if is_cat(df_iqr,col)])\n",
        "  '''d = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'Utilities', 'Condition1', \n",
        "                        'Condition2', 'Street', 'LandContour', 'LandSlope', \n",
        "                  'RoofMatl', 'ExterCond', 'BsmtCond', 'BsmtFinType2', 'Heating', 'CentralAir', \n",
        "                  'Electrical', 'Functional', 'GarageQual', 'GarageCond', 'PavedDrive', 'SaleType']#, axis = 1)\n",
        "  df_cats = df_iqr.drop(columns = [col for col in d])  #drop cols'''\n",
        "  df_cats = create_mt_catcol(df_cats)                  #fill NaNs with MISSING\n",
        "\n",
        "  #df_cats =  factorize_cats(df_cats)                   #factorize\n",
        "  print(df_cats.shape)\n",
        "  return df_cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {
        "id": "gHP7BG2CtVLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "430f941e-0a4c-40d5-cc6b-19824e950651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1460, 74)\n",
            "(1459, 73)\n",
            "(1460, 36)\n",
            "(1140, 36)\n",
            "(1148, 74)\n"
          ]
        }
      ],
      "source": [
        "df = improve_cats(raw_df_train)\n",
        "df_test = improve_cats(raw_df_test)\n",
        "\n",
        "df_num = drop_n_log(df)\n",
        "df_test = drop_n_log(df_test, True)\n",
        "\n",
        "encoder = TargetEncoder(cols = ['Neighborhood'])\n",
        "df_num['Neighborhood_te'] = encoder.fit_transform(df_num['Neighborhood'], df_num['SalePrice'])\n",
        "df_test['Neighborhood_te'] = encoder.transform(df_test['Neighborhood'])\n",
        "df_cats = make_cats(df_num)\n",
        "\n",
        "\n",
        "\n",
        "df_cats= make_iqr(df_cats)\n",
        "#df_cats = df_cats.drop(columns = ['MSSubClass', 'KitchenAbvGr', 'MoSold','YrSold','BedroomAbvGr', 'WoodDeckSF', 'GarageYrBlt'])\n",
        "\n",
        "\n",
        "df_test = make_iqr(df_test, True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_cats.columns"
      ],
      "metadata": {
        "id": "o6wI8Vy1YQnp",
        "outputId": "2cfe9189-8244-4c84-82fe-1df793384d4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt',\n",
              "       'YearRemodAdd', 'MasVnrArea', 'TotalBsmtSF', '2ndFlrSF', 'GrLivArea',\n",
              "       'Fireplaces', 'GarageArea', 'SalePrice', 'TotalSF', 'PorchSF',\n",
              "       'OutsideArea', 'MonthSold', 'HasBsmt', 'Modern', 'Has2Floors',\n",
              "       'HasGarage', 'HasPool', 'HasVnr', 'Bath', 'Neighborhood_te',\n",
              "       'HouseStyle_e', 'FireplaceQu_e', 'LotShape_e', 'Foundation_e'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 340
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 341,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHityhEMu45R",
        "outputId": "6dca117f-44aa-4a37-9e49-ba8cb1a62546"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['TotalSF', 0.6834851382217757]"
            ]
          },
          "metadata": {},
          "execution_count": 341
        }
      ],
      "source": [
        "#Find second best parameter\n",
        "my_cols = ['SalePrice']#, 'OverallQual']\n",
        "valids = get_valid_cols(df_cats, my_cols, ['OverallQual'])\n",
        "find_best_param(df_cats, valids, my_cols, ['OverallQual'], r2_threshold = 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {
        "id": "IhZGvD9ryfR_"
      },
      "outputs": [],
      "source": [
        "#test on best combination so far\n",
        "#split_run_test(df_cats[['SalePrice', 'OverallQual', 'TotalSF', 'GarageArea', 'LotArea', 'Bath', 'Fireplaces', 'YearRemodAdd', 'HasGarage', 'YearBuilt', 'OverallCond', 'GrLivArea', 'BedroomAbvGr', 'YrSold', 'Modern', 'Has2Floors', '2ndFlrSF', 'WoodDeckSF', 'GarageYrBlt', 'HasVnr', 'LotArea']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqzRu-aUu908",
        "outputId": "15e48c35-817f-4769-8f73-6908a598ed8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['SalePrice', 'OverallQual', 'Neighborhood_te', 'TotalSF', 'Bath', 'LotArea', 'YearRemodAdd', 'HasGarage', 'Fireplaces', 'Foundation_e', 'OverallCond', 'YearBuilt', 'TotalBsmtSF', 'GarageArea'], 0.8895062376753288)\n",
            "train r2: 0.8984664536782044\n",
            "train rmse: 0.010629347948012608\n",
            "\n",
            "test r2: 0.8895062376753288\n",
            "test rmse: 0.010464110305515492\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                 ('linearregression', LinearRegression())]),\n",
              " 'train r2: 0.8984664536782044\\ntrain rmse: 0.010629347948012608\\n\\ntest r2: 0.8895062376753288\\ntest rmse: 0.010464110305515492\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 343
        }
      ],
      "source": [
        "#get current best combination \n",
        "mymod = get_best_cols(df_cats, ['SalePrice', 'OverallQual', 'Neighborhood_te'], r2_threshold = 0.67)\n",
        "print(mymod)\n",
        "split_run_test(df_cats[mymod[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 344,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzAEG1UdvRoY",
        "outputId": "53b870cc-074d-46bc-f740-e76a2f2de114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shuffle: 1\n",
            "(['SalePrice', 'OverallQual', 'Neighborhood_te', 'TotalSF', 'Bath', 'LotArea', 'YearRemodAdd', 'HasGarage', 'FireplaceQu_e', 'PorchSF', 'YearBuilt', 'OverallCond', 'GrLivArea', 'Has2Floors'], 0.8956707132319582)\n",
            "shuffle: 2\n",
            "shuffle: 3\n",
            "(['SalePrice', 'OverallQual', 'Neighborhood_te', 'TotalSF', 'Bath', 'LotArea', 'YearRemodAdd', 'HasGarage', 'Fireplaces', 'PorchSF', 'YearBuilt', 'OverallCond', 'GrLivArea', 'OverallCond'], 0.8968590940177835)\n",
            "shuffle: 4\n",
            "shuffle: 5\n",
            "\n",
            "\n",
            "The result is:\n",
            "(['SalePrice', 'OverallQual', 'Neighborhood_te', 'TotalSF', 'Bath', 'LotArea', 'YearRemodAdd', 'HasGarage', 'Fireplaces', 'PorchSF', 'YearBuilt', 'OverallCond', 'GrLivArea', 'OverallCond'], 0.8968590940177835)\n"
          ]
        }
      ],
      "source": [
        "#get best orders of best combinations\n",
        "result = many_shuffles(df_cats, my_cols = ['SalePrice','OverallQual', 'Neighborhood_te'], num=5, threshold = 0.67)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4sLmWqIHWOE",
        "outputId": "a2705d7c-7a0d-4d83-92ab-d3ecb069d06a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train r2: 0.8973018860425447\n",
            "train rmse: 0.010680601580888701\n",
            "\n",
            "test r2: 0.8968590940177835\n",
            "test rmse: 0.010125431238194005\n",
            "\n"
          ]
        }
      ],
      "source": [
        "my_model, perf_stats = split_run_test(df_cats[result[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observe best result\n",
        "\n",
        "to-do - dataframe with best result"
      ],
      "metadata": {
        "id": "3b6Zx7uKoQRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best on Linear regeression 0.9195"
      ],
      "metadata": {
        "id": "OfwBO_vdTJEg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEhNy-13wBah"
      },
      "source": [
        "train: r2 0.8917100533649739\n",
        "\n",
        "train: root mean squared error: 0.01101263566776913\n",
        "\n",
        "Test:\n",
        "test: r2 0.9195194361430203\n",
        "\n",
        "test: root mean squared error: 0.009303583596568663\n",
        "\n",
        "\n",
        "['SalePrice', 'OverallQual', 'TotalSF', 'GarageArea', 'LotArea', 'Bath', 'Fireplaces', 'YearRemodAdd', 'HasGarage', 'YearBuilt', 'OverallCond', 'GrLivArea', 'BedroomAbvGr', 'FullBath', 'YrSold', 'New', 'Has2Floors', '2ndFlrSF', 'WoodDeckSF', 'GarageYrBlt', 'HasVnr', 'LotArea'] \n",
        "0.9195194361430203)\n",
        "\n",
        "new_params = baths, new, hasgarage, haspool, has2floors, hasvnr, hasbsmt\n",
        "\n",
        "log of 'LotFrontage', 'LotArea', 'GrLivArea', 'SalePrice'\n",
        "\n",
        "\n",
        "drop porches \n",
        "\n",
        "drop basements \n",
        "\n",
        "drop garage \n",
        "\n",
        "drop baths\n",
        "\n",
        "Drop all cats.\n",
        "\n",
        "'LowQualFinSF', 'PoolArea', 'MiscVal', 'TotRmsAbvGrd', '1stFlrSF'])  drop misc\n",
        "\n",
        "iqr\n",
        "['SalePrice', 'LotFrontage', 'LotArea', 'MasVnrArea', 'TotalBsmtSF', 'GrLivArea', 'BedroomAbvGr', 'KitchenAbvGr', 'Fireplaces', 'GarageArea', 'PorchSF']\n",
        "\n",
        "\n",
        " no factorize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcRCD6Jz2rXS"
      },
      "source": [
        "## Another one\n",
        "['SalePrice', 'OverallQual', 'GrLivArea', 'TotalBsmtSF', 'LotArea', 'YearBuilt', 'OverallCond', 'GarageArea', 'BsmtFullBath', 'Fireplaces', 'BedroomAbvGr', 'YearRemodAdd', 'HalfBath']\n",
        "\n",
        "log of ['LotFrontage', 'LotArea', 'GrLivArea', 'SalePrice','GarageArea']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cBg3TdYdSet"
      },
      "source": [
        "\n",
        "(['SalePrice', 'OverallQual', 'GrLivArea', 'TotalBsmtSF', 'OverallCond', 'YearBuilt', 'LotArea', 'GarageArea', 'Fireplaces', 'HalfBath', 'BsmtFullBath', 'BedroomAbvGr', 'GarageYrBlt', 'WoodDeckSF', 'WoodDeckSF', 'BsmtHalfBath'], 0.9218701457673271)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP3EB3wXvXJ-"
      },
      "source": [
        "## LassoLarsCV 0.92\n",
        "\n",
        "(['SalePrice',\n",
        "  'OverallQual',\n",
        "  'TotalSF',\n",
        "  'GarageArea',\n",
        "  'LotArea',\n",
        "  'Foundation',\n",
        "  'Fireplaces',\n",
        "  'OverallCond',\n",
        "  'HalfBath',\n",
        "  'FullBath',\n",
        "  'CentralAir',\n",
        "  'BsmtExposure',\n",
        "  'BsmtFullBath',\n",
        "  'PavedDrive',\n",
        "  'MasVnrType',\n",
        "  'Functional',\n",
        "  'BedroomAbvGr',\n",
        "  'GrLivArea',\n",
        "  '2ndFlrSF',\n",
        "  'Condition1',\n",
        "  'ExterCond'],\n",
        " 0.9236066685585789) - basic log['LotFrontage', 'LotArea', 'GrLivArea', 'SalePrice']. LassoLarsCV"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stacking .92 = .92\n",
        "\n",
        "  estimators = [('LinReg',LinearRegression()), ('Lasso',LassoLarsCV(max_iter=15,eps=0.01)), ('Tree',DecisionTreeRegressor(max_depth=5)),\n",
        "                ('LGBR', LGBMRegressor(max_depth = 5, learning_rate = 0.05))]\n",
        "final = RandomForestRegressor(max_depth=6)\n",
        "\n",
        "train: r2 0.9259061491493182\n",
        "train: root mean squared error: 0.009157887674229528\n",
        "\n",
        "Test:\n",
        "test: r2 0.9217500638734336\n",
        "test: root mean squared error: 0.009142663976721768\n",
        "\n",
        "log = ['LotFrontage', 'LotArea', 'GrLivArea', 'SalePrice']\n",
        "\n",
        "cols = ['SalePrice', 'OverallQual', 'TotalSF', 'MSSubClass', 'GarageArea', 'BsmtHalfBath', 'MSSubClass', 'Fireplaces', 'LotArea', 'OverallCond', 'HalfBath', 'YearRemodAdd', 'OverallCond', 'HalfBath', 'FullBath', 'YearBuilt', 'BsmtFullBath', 'GrLivArea', 'GarageYrBlt', '2ndFlrSF', 'OutsideArea', 'YrSold', 'YrSold', 'PorchSF', 'WoodDeckSF', 'PorchSF', 'MasVnrArea', 'TotalBsmtSF']\n",
        "\n",
        "factorized?"
      ],
      "metadata": {
        "id": "uRYvl16GFYcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best so far - 0.93 stacking of linear regression with factorized cats."
      ],
      "metadata": {
        "id": "_5l54kJAZFBX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To-Do\n",
        "\n",
        "Create a func that pushes conditions, parameters, and results of every model. logging\n"
      ],
      "metadata": {
        "id": "MB0wyW51pFvg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Work with test data"
      ],
      "metadata": {
        "id": "Ixzig_OWnyoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare test data to fit the model"
      ],
      "metadata": {
        "id": "avtRmeTmnog6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 346,
      "metadata": {
        "id": "3KhAZvdCvWuA"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_data = df_test[my_model.feature_names_in_]\n",
        "for col in test_data.columns[test_data.isna().any()].tolist():      #['TotalSF', 'GarageArea','BsmtFullBath']: \n",
        "  test_data[col] = test_data[col].fillna(test_data[col].mode()[0]) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict values"
      ],
      "metadata": {
        "id": "AGKMjGq1n14p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_ys = my_model.predict(test_data)"
      ],
      "metadata": {
        "id": "EOdqT7PznkqZ"
      },
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct dataset for submission"
      ],
      "metadata": {
        "id": "i8TmH-MMoDGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create_dataset\n",
        "ids = np.arange(1461, 2920)\n",
        "my_result = pd.DataFrame({'Id': ids, 'SalePrice': np.e**pred_ys})\n",
        "my_result.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "NwNEhXXZImid",
        "outputId": "dba4554e-8fc0-4b24-fd6b-51638964794a"
      },
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-348-66a5b29e3a59>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#create_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1461\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2920\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmy_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SalePrice'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpred_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmy_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All arrays must be of the same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset"
      ],
      "metadata": {
        "id": "DcqzvZAMoH5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_result.to_csv('submission.csv', index=False)\n",
        "files.download('submission.csv')"
      ],
      "metadata": {
        "id": "C0JMEvGthk3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Work with FTP"
      ],
      "metadata": {
        "id": "ax_02DqcWxIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def connect(address='0.0.0.0', name = 'anonymous', pas = ''):\n",
        "\tftp = ftplib.FTP(address)\n",
        "\tftp.login(name, pas)\n",
        "\treturn ftp\n",
        "\n",
        "def ret(ftp, filename = 'test.csv'):\n",
        "\tfile = io.BytesIO()\n",
        "\tftp.retrbinary('RETR '+filename, file.write)\n",
        "\tfile.seek(0)\n",
        "\tdf = pd.read_csv(file)\n",
        "\treturn df\n",
        "\n",
        "def write(df, ftp, filename = 'test.csv'):\n",
        "  file = io.BytesIO()\n",
        "  df.to_csv(file, index = False)\n",
        "  data = file.getvalue()\n",
        "  ftp.storbinary('STOR '+filename, io.BytesIO(data))\n",
        "  ftp.quit()\n",
        "\n"
      ],
      "metadata": {
        "id": "EUaTlQS_WuA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prepare dataset to upload. df in df"
      ],
      "metadata": {
        "id": "Ub80mMw3-G3F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HG0M6xaRI_hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stats = \"LinearRegression()\" #[('LinReg',LinearRegression()), ('Lasso',LassoLarsCV(max_iter=11,eps=0.01)), ('Tree',DecisionTreeRegressor(max_depth=5)), SGDRegressor())]\"\n",
        "dataset = df_cats[result[0]].copy()\n",
        "predictions = my_result.copy()\n",
        "time = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "\n",
        "\n",
        "#stats_df = pd.DataFrame({'date':[time], 'daset':[predictions.to_dict(orient='records')],\n",
        "#                         'input dataset': [dataset.to_dict(orient='records')], \n",
        "#                         'model':[stats], 'r2_rmse': [perf_stats]})\n",
        "\n",
        "\n",
        "#dfn = pd.json_normalize(eval(str(stats_df.iloc[-1]['daset'])))\n",
        "#dfn.set_index('Id', inplace=True)\n",
        "#"
      ],
      "metadata": {
        "id": "KniqGvf7YiRZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqIURhRAlXTBlEz6Ddyl8o",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}