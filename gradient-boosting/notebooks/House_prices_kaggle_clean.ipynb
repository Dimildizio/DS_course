{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdMhL6H1NSkHuiJvBQMZ5j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimildizio/DS_course/blob/main/gradient-boosting/notebooks/House_prices_kaggle_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders\n",
        "!pip install xgboost\n",
        "!pip install catboost"
      ],
      "metadata": {
        "id": "rbYEJD9c8jsa",
        "outputId": "b76ff7ac-9ecb-4c78-c8ee-2b82fec8232b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.9/dist-packages (2.6.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.2.2)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (0.13.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (0.5.3)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from category_encoders) (1.10.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.5->category_encoders) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from statsmodels>=0.9.0->category_encoders) (23.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.9/dist-packages (1.7.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from xgboost) (1.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from xgboost) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.1.1-cp39-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.9/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.9/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->catboost) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (1.0.7)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (5.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (4.39.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly->catboost) (8.2.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.15.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NalAF5KVnAkc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import timeit\n",
        "import xgboost as xgb\n",
        "\n",
        "from catboost import CatBoostRegressor\n",
        "from category_encoders import TargetEncoder\n",
        "from google.colab import files\n",
        "from lightgbm import LGBMRegressor\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, StackingRegressor, VotingRegressor\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.linear_model import LassoLarsCV, LinearRegression, ElasticNet#, SGDRegressor,LogisticRegression, LogisticRegressionCV, \n",
        "from sklearn.model_selection import train_test_split#, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('max_colwidth', 80)\n",
        "\n",
        "raw_df_train = pd.read_csv('https://raw.githubusercontent.com/Dimildizio/DS_course/main/gradient-boosting/data/train.csv', index_col=0)\n",
        "raw_df_test = pd.read_csv('https://raw.githubusercontent.com/Dimildizio/DS_course/main/gradient-boosting/data/test.csv', index_col=0)"
      ],
      "metadata": {
        "id": "DfG-BTGUnCwK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Work with categories"
      ],
      "metadata": {
        "id": "mEFjDBR9tPZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_cat(df, col):\n",
        "  '''checks if a column is of object or category type'''\n",
        "  return df[col].dtype in ['object', 'category']\n",
        "\n",
        "def improve_cats(dataframe) -> pd.DataFrame:\n",
        "  '''turns dtypes 64->32 and object->category'''\n",
        "  df = dataframe.copy()\n",
        "  for col in df.columns:\n",
        "    if df[col].dtype == 'int64':\n",
        "      df[col] = df[col].astype('int32')\n",
        "    elif df[col].dtype == 'float64':\n",
        "      df[col] = df[col].astype('float32')\n",
        "    elif df[col].dtype == 'object':\n",
        "      df[col] = df[col].astype('category')\n",
        "    else:\n",
        "      print('Unknown data type')\n",
        "      return\n",
        "  return df"
      ],
      "metadata": {
        "id": "Y7amMkDnnIM0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Show statistics"
      ],
      "metadata": {
        "id": "FYDBgi1jtefb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adjusted_r2(yt,yp, colnum):\n",
        "  '''computes adjusted r2 score'''\n",
        "  return 1 - (1 - r2_score(yt, yp)) * ((yt.shape[0]-1) / (yt.shape[0] - colnum+(1e-12)))\n",
        "\n",
        "def print_scores(y_train, y_test, y_pred_train, y_pred_test, colnum):\n",
        "  '''outprints adjusted r2 and rmse results on train and validation'''\n",
        "  train_r2 =  adjusted_r2(y_train, y_pred_train, colnum)\n",
        "  test_r2 = adjusted_r2(y_test,y_pred_test, colnum)\n",
        "  train_rmse = np.sqrt(mean_squared_error(np.log(y_pred_train), np.log(y_train)))\n",
        "  test_rmse = np.sqrt(mean_squared_error(np.log(y_pred_test), np.log(y_test)))\n",
        "  text = f'train r2: {train_r2}\\ntrain rmse: {train_rmse}\\n\\ntest r2: {test_r2}\\ntest rmse: {test_rmse}\\n'\n",
        "  print(text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "6TyxvPDhrYVV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split dataframe to X,y"
      ],
      "metadata": {
        "id": "Mtt5HUcs0Dho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(df, target):\n",
        "  '''splits data'''\n",
        "  X = df.drop(target, axis=1)\n",
        "  y = df[target]\n",
        "  return train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "xNwAn6fRnXVV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Work with model"
      ],
      "metadata": {
        "id": "KwaDXaLitT8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(X_train, y_train):\n",
        "  '''subj'''\n",
        "  estimators = [('LinReg',LinearRegression()), ('Lasso',LassoLarsCV(max_iter=15,eps=0.01)), \n",
        "                ('Tree',DecisionTreeRegressor(max_depth=5)), ('LGBR', LGBMRegressor(max_depth = 5, learning_rate = 0.05)),\n",
        "                ('Elastic',ElasticNet(alpha=0.0005,random_state=42))]\n",
        "  pipe = make_pipeline(RobustScaler(), StackingRegressor(estimators=estimators, final_estimator = RandomForestRegressor(max_depth=6)))\n",
        "  pipe.fit(X_train, y_train)\n",
        "  y3_train = np.exp((np.log(y_train) + np.log(pipe.predict(X_train))) / 2)\n",
        "  pipe.fit(X_train, y3_train)\n",
        "\n",
        "\n",
        "  return pipe"
      ],
      "metadata": {
        "id": "hTLLd3oLohzm"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model2(X_train, y_train):\n",
        "  estimators = [('LinReg',LinearRegression()), ('Lasso',LassoLarsCV(max_iter=15,eps=0.01)), ('Tree',DecisionTreeRegressor(max_depth=5))]\n",
        "\n",
        "  pipe1 = make_pipeline(RobustScaler(), xgb.XGBRegressor(colsample_bytree=0.4,\n",
        "                             gamma=0.045,\n",
        "                             learning_rate=0.05,\n",
        "                             max_depth=10,\n",
        "                             min_child_weight=1.5,\n",
        "                             n_estimators=300,\n",
        "                             reg_alpha=0.65,\n",
        "                             reg_lambda=0.45,\n",
        "                             subsample=0.95))\n",
        "  pipe2 = make_pipeline(RobustScaler(), LassoLarsCV(max_iter=15,eps=0.01))\n",
        "  pipe3 = make_pipeline(RobustScaler(), DecisionTreeRegressor(max_depth=5))\n",
        "  estimators = [('LinReg',LinearRegression()), ('Lasso',LassoLarsCV(max_iter=15,eps=0.01)), \n",
        "                ('Tree',DecisionTreeRegressor(max_depth=5)), ('LGBR', LGBMRegressor(max_depth = 5, learning_rate = 0.05)),\n",
        "                ('Elastic',ElasticNet(alpha=0.0005,random_state=42))]\n",
        "  pipe = make_pipeline(RobustScaler(), StackingRegressor(estimators=estimators, final_estimator = RandomForestRegressor(max_depth=6)))\n",
        "\n",
        "  blend = VotingRegressor(estimators=[('pipe1', pipe1), ('pipe2', pipe2), ('pipe3', pipe3), ('pipe4',pipe)], weights=[0.2, 0.1, 0.1, 0.6])\n",
        "\n",
        "\n",
        "  blend.fit(X_train, y_train)\n",
        "  y3_train = np.exp((np.log(y_train) + np.log(blend.predict(X_train))) / 2)\n",
        "  blend.fit(X_train, y3_train)\n",
        "  \n",
        "\n",
        "  return blend\n"
      ],
      "metadata": {
        "id": "W_8lSGYAOLuQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cat(df, target = 'SalePrice'):\n",
        "  X_train, X_val, y_train, y_val = split_data(df, target)\n",
        "  model = CatBoostRegressor(\n",
        "      iterations=1500,\n",
        "      learning_rate=0.05,\n",
        "      depth=6,\n",
        "      l2_leaf_reg=3,\n",
        "      subsample=0.8,\n",
        "      random_seed=42,\n",
        "      random_strength=0.6,\n",
        "      loss_function = 'RMSE',\n",
        "      eval_metric='RMSE',\n",
        "      verbose=False\n",
        "  )\n",
        "  model.fit(X_train, y_train, eval_set=(X_val, y_val), verbose=False)\n",
        "  score = model.score(X_val, y_val)\n",
        "  y3_train = np.exp((np.log(y_train) + np.log(model.predict(X_train))) / 2)\n",
        "  model.fit(X_train, y3_train, eval_set=(X_val, y_val), verbose=False)\n",
        "\n",
        "  txt = print_scores(y_train, y_val, model.predict(X_train), model.predict(X_val), len(X_train.columns))\n",
        "  return model, txt\n"
      ],
      "metadata": {
        "id": "9We_zL_8nsTW"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_run_test(df, target = 'SalePrice'):\n",
        "  '''splits data and runs model'''\n",
        "  X_train, X_test, y_train, y_test = split_data(df, target)\n",
        "  model = train_model2(X_train, y_train)\n",
        "\n",
        "  y_pred_train = model.predict(X_train)\n",
        "  y_pred_test = model.predict(X_test)\n",
        "  txt = print_scores(y_train, y_test, y_pred_train, y_pred_test, len(X_train.columns))\n",
        "  return model, txt"
      ],
      "metadata": {
        "id": "pvsPPHWZnXv2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_run_test_stack(df, target = 'SalePrice'):\n",
        "  '''splits data and runs model'''\n",
        "  X_train, X_test, y_train, y_test = split_data(df, target)\n",
        "  model = train_model(X_train, y_train)\n",
        "\n",
        "  y_pred_train = model.predict(X_train)\n",
        "  y_pred_test = model.predict(X_test)\n",
        "  txt = print_scores(y_train, y_test, y_pred_train, y_pred_test, len(X_train.columns))\n",
        "  return model, txt"
      ],
      "metadata": {
        "id": "T6Q-hoIruVY2"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_permutations(df):\n",
        "  '''Pick best columns'''\n",
        "  X_train, X_test, y_train, y_test = split_data(df, 'SalePrice')\n",
        "  model = train_model2(X_train, y_train)\n",
        "  result = permutation_importance(model, X_train, y_train, n_repeats=10, random_state=42)\n",
        "  importance_dict = dict(zip(X_train.columns, result.importances_mean))\n",
        "  sorted_importance = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "  print(sorted_importance)\n",
        "  #get_shap(X_train, X_test, model)\n",
        "  #grid(X_train, y_train)\n",
        "  return [x[0] for x in sorted_importance]  \n",
        "  \n",
        "'''def get_shap(X_train, X_test, model):\n",
        "  explainer = shap.Explainer(model.predict, X_train)\n",
        "  shap_values = explainer(X_test)\n",
        "  shap.plots.waterfall(shap_values[0])\n",
        "\n",
        "def grid(X_train, y_train):\n",
        "  estimators = [('LinReg',LinearRegression()), \n",
        "                ('Lasso',LassoLarsCV(max_iter=15,eps=0.01)), \n",
        "                ('Tree',DecisionTreeRegressor(max_depth=5)), \n",
        "                ('LGBR', LGBMRegressor(max_depth=5, learning_rate=0.05)),\n",
        "                ('Elastic',ElasticNet(alpha=0.0005,random_state=42))]\n",
        "                \n",
        "  pipe = make_pipeline(RobustScaler(), \n",
        "                      StackingRegressor(estimators=estimators, \n",
        "                                        final_estimator=RandomForestRegressor(max_depth=6)))\n",
        "\n",
        "  param_grid = {\n",
        "      'stackingregressor__final_estimator__n_estimators': [10, 50, 100],\n",
        "      'stackingregressor__final_estimator__max_depth': [3, 5, 7],\n",
        "      'stackingregressor__final_estimator__min_samples_split': [2, 4, 8],\n",
        "      'stackingregressor__Elastic__l1_ratio': [0.1, 0.5, 0.9],      \n",
        "  }\n",
        "\n",
        "  grid = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
        "  grid.fit(X_train, y_train)\n",
        "  print('grid best params: ', grid.best_params_)\n",
        "  print('grid best score: ', grid.best_score_)'''"
      ],
      "metadata": {
        "id": "5RQ20Ng-n9of",
        "outputId": "a73ce2f8-6ef2-45f2-ffe7-2db776b8d878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"def get_shap(X_train, X_test, model):\\n  explainer = shap.Explainer(model.predict, X_train)\\n  shap_values = explainer(X_test)\\n  shap.plots.waterfall(shap_values[0])\\n\\ndef grid(X_train, y_train):\\n  estimators = [('LinReg',LinearRegression()), \\n                ('Lasso',LassoLarsCV(max_iter=15,eps=0.01)), \\n                ('Tree',DecisionTreeRegressor(max_depth=5)), \\n                ('LGBR', LGBMRegressor(max_depth=5, learning_rate=0.05)),\\n                ('Elastic',ElasticNet(alpha=0.0005,random_state=42))]\\n                \\n  pipe = make_pipeline(RobustScaler(), \\n                      StackingRegressor(estimators=estimators, \\n                                        final_estimator=RandomForestRegressor(max_depth=6)))\\n\\n  param_grid = {\\n      'stackingregressor__final_estimator__n_estimators': [10, 50, 100],\\n      'stackingregressor__final_estimator__max_depth': [3, 5, 7],\\n      'stackingregressor__final_estimator__min_samples_split': [2, 4, 8],\\n      'stackingregressor__Elastic__l1_ratio': [0.1, 0.5, 0.9],      \\n  }\\n\\n  grid = GridSearchCV(pipe, param_grid=param_grid, cv=5)\\n  grid.fit(X_train, y_train)\\n  print('grid best params: ', grid.best_params_)\\n  print('grid best score: ', grid.best_score_)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Work with columns"
      ],
      "metadata": {
        "id": "8GQpobcjtntq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cols(df):\n",
        "  #create Total SF\n",
        "  df[\"TotalSF\"] = df[\"1stFlrSF\"] + df[\"2ndFlrSF\"] + df[\"TotalBsmtSF\"]+df['LotArea']\n",
        "  #create Porch\n",
        "  df['PorchSF'] = df['OpenPorchSF'] + df['EnclosedPorch'] + df['3SsnPorch'] + df['ScreenPorch']\n",
        "  #Create green area\n",
        "  df[\"OutsideArea\"] = df[\"LotArea\"] - df[\"GrLivArea\"] - df[\"GarageArea\"] \n",
        "  #Create month sold * year\n",
        "  df['MonthSold'] = df['YrSold']*12 + df['MoSold'] #-df['YrSold'].min()\n",
        "  #dates_frames  = ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold','MoSold']\n",
        "  #Create booleans\n",
        "  df['Has2Floors'] = df['2ndFlrSF'].apply(lambda x: 1 if x>0 else 0)\n",
        "  df['Has1Floors'] = df['1stFlrSF'].apply(lambda x: 1 if x>0 else 0)\n",
        "  df['HasPorch'] = df['PorchSF'].apply(lambda x: 1 if x>0 else 0)\n",
        "  df['HasWood'] = df['WoodDeckSF'].apply(lambda x: 1 if x>0 else 0)\n",
        "  df['HasFireplace'] = df['Fireplaces'].apply(lambda x: 1 if x>0 else 0)\n",
        "  #create bath\n",
        "  fullbsmtb = df['BsmtFullBath'].apply(lambda x: x if x > 0 else 0)\n",
        "  halfbsmtb = df['BsmtHalfBath'].apply(lambda x: x*0.5 if x > 0 else 0)\n",
        "  fullb = df['FullBath'].apply(lambda x: x if x > 0 else 0)\n",
        "  halfb = df['HalfBath'].apply(lambda x: x*0.5 if x > 0 else 0)\n",
        "  df['Bath'] = fullbsmtb + halfbsmtb + fullb + halfb\n",
        "  return df\n",
        "\n",
        "def log_cols(df, log_cols):\n",
        "  '''adds 1 to all numeric columns and np.logs handpicked columns'''\n",
        "  for column in [col for col in df.columns if not is_cat(df, col)]:\n",
        "    df[column] = df[column]+1\n",
        "  for col in log_cols:\n",
        "    df[col] = np.log(df[col])\n",
        "  return df\n",
        "\n",
        "def plotme(df, cols):\n",
        "  for col in cols:\n",
        "    if col != 'SalePrice':\n",
        "      sns.scatterplot(y = df['SalePrice'], x = df[col])\n",
        "\n",
        "def categorize_cols(df):\n",
        "  \"\"\"fill NaNs\"\"\"\n",
        "  for col in df.columns:\n",
        "    if df[col].isna().any():\n",
        "      if is_cat(df, col):\n",
        "        df[col] = df[col].cat.add_categories(['MISSING'])\n",
        "        df[col] = df[col].fillna('MISSING')\n",
        "        df[col] = df[col].cat.remove_unused_categories()\n",
        "      else:\n",
        "        if col not in ['GarageArea', 'KitchenAbvGr', 'TotRmsAbvGrd', 'LotArea',\\\n",
        "                       'TotalBsmtSF', 'BedroomAbvGr', 'Fireplaces', 'LotFrontage', \\\n",
        "                       'WoodDeckSF', 'MasVnrArea', '2ndFlrSF','GarageArea', 'WoodDeckSF',\\\n",
        "                       'BsmtFinSF1', 'BsmtFinSF2','BsmtUnfSF', 'LowQualFinSF', '1stFlrSF']:\n",
        "          df[col] = df[col].fillna(df[col].mean())\n",
        "        else:\n",
        "          df[col] = df[col].fillna(0)\n",
        "  return df\n",
        "\n",
        "\"\"\"def encode_cols(df, cols):\n",
        "  '''Use Label encoder'''\n",
        "  for col in cols:\n",
        "    encoder = LabelEncoder()\n",
        "    df[col+'_e'] = encoder.fit_transform(df[col])\n",
        "  return df\"\"\"\n",
        "\n",
        "def drop_categories(df):\n",
        "  '''drop cat values'''\n",
        "  cats = [col for col in df.columns if is_cat(df, col)]\n",
        "  return df.drop(columns = cats)\n",
        "\n",
        "def iqr(df, columns, mult=3):\n",
        "  '''cut outliers'''\n",
        "  df = df.copy()\n",
        "  for col in columns:\n",
        "    d=df[col].describe()\n",
        "    val =(d['50%'] + (d['75%']-d['25%'])) * mult\n",
        "    df = df[df[col] <= val]\n",
        "  return df\n",
        "\n",
        "def work_df(df, to_log = ['LotFrontage', 'LotArea', 'GrLivArea', 'GarageArea'], target =[], to_drop = []):\n",
        "  df = df.copy()\n",
        "  df = improve_cats(df)\n",
        "  df = create_cols(df)\n",
        "  df = df.drop(columns = to_drop)\n",
        "  df = categorize_cols(df)\n",
        "\n",
        "  df['OutsideArea'] = df['OutsideArea'].apply(lambda x: x if x>0 else 0)\n",
        "\n",
        "  df = log_cols(df, target+to_log)\n",
        "  return df"
      ],
      "metadata": {
        "id": "eW_Mbnfqttti"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating variable"
      ],
      "metadata": {
        "id": "ghzYg92OyjZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_log = ['LotFrontage', 'LotArea', 'GrLivArea','TotalSF','OutsideArea', \n",
        "               'MonthSold', 'TotalBsmtSF', 'YrSold', 'YearBuilt','YearRemodAdd', \n",
        "               'GarageYrBlt', '2ndFlrSF','GarageArea', 'WoodDeckSF', 'BsmtFinSF1', \n",
        "               'BsmtFinSF2','BsmtUnfSF', 'LowQualFinSF', '1stFlrSF']\n",
        "\n",
        "cols_to_iqr = ['SalePrice','LotFrontage', 'LotArea', 'MasVnrArea', 'TotalBsmtSF', \n",
        "               'GrLivArea', 'BedroomAbvGr', 'KitchenAbvGr', 'Fireplaces', \n",
        "               'GarageArea', 'PorchSF', 'OutsideArea', 'TotalSF', '2ndFlrSF', '1stFlrSF']\n",
        "\n",
        "cols_to_drop = ['OpenPorchSF','EnclosedPorch', '3SsnPorch', 'ScreenPorch', \n",
        "                'PoolArea', 'MiscVal', 'GarageCars', 'BsmtFullBath', 'BsmtHalfBath', \n",
        "                'FullBath', 'HalfBath']"
      ],
      "metadata": {
        "id": "DKJ7DCGf1Qv9"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = work_df(raw_df_train, to_log = cols_to_log, to_drop = cols_to_drop, target = ['SalePrice'])                                                             \n",
        "df_test = work_df(raw_df_test, to_log = cols_to_log, to_drop = cols_to_drop)\n",
        "\n",
        "df = iqr(df, cols_to_iqr)\n",
        "\n",
        "cols = ['Neighborhood']#, 'LotShape']#, 'FireplaceQu']\n",
        "for col in cols:\n",
        "  encoder = TargetEncoder(cols = col)\n",
        "  df[col+'_te'] = encoder.fit_transform(df[col], df['SalePrice'])\n",
        "  df_test[col+'_te'] = encoder.transform(df_test[col])\n",
        "\n",
        "df = drop_categories(df)\n",
        "df_test = drop_categories(df_test)"
      ],
      "metadata": {
        "id": "hB_o1wi2t7HD"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Getting best columns "
      ],
      "metadata": {
        "id": "OGfpw7jkEJuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#to_drop = []#'Modern', 'HasBsmt', 'HasGarage', 'HasPool','HasVnr']\n",
        "df1 = df.copy()           #.drop(columns = to_drop)\n",
        "df_test1 = df_test.copy() #.drop(columns = to_drop)\n",
        "columns = get_permutations(df1) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl4XMqje1yoU",
        "outputId": "981e856a-dd95-4120-ae1c-8470beea4463"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.043e-01, tolerance: 1.142e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.676e-02, tolerance: 1.052e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('MonthSold', 0.543887289983012), ('MoSold', 0.490816150756795), ('YrSold', 0.44628999427373167), ('OverallQual', 0.17471263649485078), ('GrLivArea', 0.13353440726011545), ('Neighborhood_te', 0.08740985162459057), ('Has2Floors', 0.07424221555311337), ('2ndFlrSF', 0.06892984098414806), ('TotalSF', 0.05192511941877963), ('OverallCond', 0.022333367430735884), ('YearBuilt', 0.021946206444635685), ('1stFlrSF', 0.01900616043447446), ('Bath', 0.018587601079643433), ('LotArea', 0.017305691019497072), ('TotalBsmtSF', 0.01494054903138845), ('BsmtFinSF1', 0.013206559290255337), ('YearRemodAdd', 0.010211319578703314), ('GarageCars', 0.0076837269767437875), ('WoodDeckSF', 0.007070297978800944), ('GarageArea', 0.0062750234245133926), ('Fireplaces', 0.003982382647186322), ('ScreenPorch', 0.0032014669260609697), ('MSSubClass', 0.0019466300239541433), ('OpenPorchSF', 0.0018839965308532713), ('GarageYrBlt', 0.0017012501941415458), ('OutsideArea', 0.001631160006574517), ('BsmtFullBath', 0.0015594513042328285), ('KitchenAbvGr', 0.0013025791791185682), ('HasWood', 0.0012921630676340334), ('BedroomAbvGr', 0.0010903173633245889), ('PorchSF', 0.0008028454519699024), ('HalfBath', 0.0008027564071669046), ('HasFireplace', 0.0007986297570208745), ('LotFrontage', 0.0007032804397595016), ('EnclosedPorch', 0.0006635307967574611), ('HasPorch', 0.0006346377740508502), ('MasVnrArea', 0.0005790567931017732), ('TotRmsAbvGrd', 0.0004297666358082597), ('BsmtUnfSF', 0.00035247709782568746), ('BsmtFinSF2', 0.0002766160867560097), ('FullBath', 0.00023721611217027982), ('3SsnPorch', 0.00012872178858278627), ('LowQualFinSF', 6.105098129999265e-05), ('BsmtHalfBath', 4.141294562004516e-05), ('PoolArea', 2.6590115931746094e-05), ('Has1Floors', 0.0), ('MiscVal', -2.5275006590330664e-06)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['SalePrice']+columns\n",
        "model, txt0 = split_run_test(df1[cols])\n",
        "cat, txt1 = train_cat(df1[cols])\n",
        "stack,txt2 = split_run_test_stack(df1[cols])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S1puB0tEnw4",
        "outputId": "5d88ea92-b393-4288-8477-a6ccd35c00c0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train r2: 0.9199342141091336\n",
            "train rmse: 0.008823543897884263\n",
            "\n",
            "test r2: 0.8816284947192414\n",
            "test rmse: 0.010478496487312808\n",
            "\n",
            "train r2: 0.9924919558713039\n",
            "train rmse: 0.002702701628125035\n",
            "\n",
            "test r2: 0.8904629527276704\n",
            "test rmse: 0.010047321322835066\n",
            "\n",
            "train r2: 0.9250417225049554\n",
            "train rmse: 0.00854938229989566\n",
            "\n",
            "test r2: 0.8894851173475649\n",
            "test rmse: 0.01014516972614318\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = model.predict(df_test[columns]) * 0.3 + cat.predict(df_test[columns]) *0.3 + stack.predict(df_test[columns]) *0.4"
      ],
      "metadata": {
        "id": "gYee6lwHtp36"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_test_result = df_test.copy()\n",
        "df_test_result['SalePrice'] = y_pred_test\n",
        "#pd.concat([df_test[columns], pd.DataFrame({'SalePrice':y_pred_test})], axis=1)\n",
        "new_df = pd.concat([df1, df_test_result.sample(frac=0.6, random_state=42)])\n",
        "new_df = new_df.dropna()\n",
        "new_df.reset_index(drop=True)\n",
        "columns = get_permutations(new_df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yGIVRYNAGjyH",
        "outputId": "bc6a22eb-34a7-4084-9a2b-02863c3983ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('MonthSold', 0.2184440660919716), ('MoSold', 0.1980911289207913), ('YrSold', 0.18609830374640932), ('OverallQual', 0.18443723861153266), ('GrLivArea', 0.09536457316898103), ('Neighborhood_te', 0.06448812509745436), ('2ndFlrSF', 0.03404489351815464), ('Has2Floors', 0.02961597671176174), ('Bath', 0.026730074647957135), ('1stFlrSF', 0.024964546505195438), ('TotalSF', 0.02210068894157511), ('TotalBsmtSF', 0.016138396126574472), ('YearBuilt', 0.015149806519218777), ('OverallCond', 0.015079404945304343), ('BsmtFinSF1', 0.009642656044242203), ('YearRemodAdd', 0.009195058089797325), ('GarageCars', 0.008983188871921533), ('GarageArea', 0.006920402311692742), ('WoodDeckSF', 0.004421675491468801), ('HasFireplace', 0.002563749600862053), ('ScreenPorch', 0.0022893904830858514), ('Fireplaces', 0.0021906649542350887), ('BsmtFullBath', 0.0014431850084716813), ('LotArea', 0.0013302639279397788), ('OpenPorchSF', 0.0011985979592420315), ('MSSubClass', 0.0011777009457769716), ('TotRmsAbvGrd', 0.0011735207274006898), ('OutsideArea', 0.0010266452072993037), ('GarageYrBlt', 0.0009409440274585901), ('BedroomAbvGr', 0.0007637178088407692), ('KitchenAbvGr', 0.0007492928827443235), ('BsmtUnfSF', 0.000610841397808537), ('HasPorch', 0.0005351274679134543), ('HasWood', 0.0004871219818846528), ('PorchSF', 0.00048272037579853987), ('EnclosedPorch', 0.00040793298774649545), ('FullBath', 0.00029425483056495506), ('HalfBath', 0.00023474565311830674), ('LotFrontage', 0.000231980985929503), ('BsmtFinSF2', 0.00016478547904933417), ('MasVnrArea', 0.00016011506503953442), ('MiscVal', 6.993852928860456e-05), ('LowQualFinSF', 6.675725032794233e-05), ('PoolArea', 5.520961075704545e-05), ('BsmtHalfBath', 2.5277113191701782e-05), ('Has1Floors', 0.0), ('3SsnPorch', -3.8027820102870536e-07)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, txt0 = split_run_test(new_df[['SalePrice']+columns])\n",
        "cat, txt1 = train_cat(new_df[['SalePrice']+columns])\n",
        "stack,txt2 = split_run_test_stack(new_df[['SalePrice']+columns])\n",
        "y_pred_test = model.predict(df_test[columns]) * 0.3 + cat.predict(df_test[columns]) *0.3 + stack.predict(df_test[columns]) *0.4\n",
        "\n",
        "#model, txt = train_cat(new_df[['SalePrice']+columns])#split_run_test(new_df[['SalePrice']+columns])\n",
        "#y_pred_test = model.predict(df_test[columns])\n"
      ],
      "metadata": {
        "id": "QFAbM8UvH8XC",
        "outputId": "b6bcbd34-4a83-497c-ccac-0e0cb0db103a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train r2: 0.9480514873507241\n",
            "train rmse: 0.007151242463592941\n",
            "\n",
            "test r2: 0.9198842055260552\n",
            "test rmse: 0.008786348960599644\n",
            "\n",
            "train r2: 0.9805288902480642\n",
            "train rmse: 0.0043722459427323595\n",
            "\n",
            "test r2: 0.9253386936731139\n",
            "test rmse: 0.008491453722529144\n",
            "\n",
            "train r2: 0.954023059480296\n",
            "train rmse: 0.00672808988525285\n",
            "\n",
            "test r2: 0.92913754743643\n",
            "test rmse: 0.008264729304207201\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.shape"
      ],
      "metadata": {
        "id": "UqaxaphTP3Zy",
        "outputId": "49640ef0-ba13-4b7e-bca9-e4996893e20d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1459, 36)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = np.arange(1461, 2920)\n",
        "my_result = pd.DataFrame({'Id': ids, 'SalePrice': np.e**y_pred_test})\n",
        "my_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "-ns9cnabty53",
        "outputId": "aa610d48-7146-4ad3-d42f-e917a3d2e742"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Id      SalePrice\n",
              "0     1461  125106.710465\n",
              "1     1462  154352.970134\n",
              "2     1463  178395.187207\n",
              "3     1464  185810.422026\n",
              "4     1465  186628.068959\n",
              "...    ...            ...\n",
              "1454  2915   88650.071326\n",
              "1455  2916   89969.048634\n",
              "1456  2917  171556.761329\n",
              "1457  2918  116292.131362\n",
              "1458  2919  209176.278626\n",
              "\n",
              "[1459 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-648a9f84-ae04-45cd-aebf-a1a6bce5bfae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1461</td>\n",
              "      <td>125106.710465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1462</td>\n",
              "      <td>154352.970134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1463</td>\n",
              "      <td>178395.187207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1464</td>\n",
              "      <td>185810.422026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465</td>\n",
              "      <td>186628.068959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1454</th>\n",
              "      <td>2915</td>\n",
              "      <td>88650.071326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>2916</td>\n",
              "      <td>89969.048634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>2917</td>\n",
              "      <td>171556.761329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>2918</td>\n",
              "      <td>116292.131362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>2919</td>\n",
              "      <td>209176.278626</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1459 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-648a9f84-ae04-45cd-aebf-a1a6bce5bfae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-648a9f84-ae04-45cd-aebf-a1a6bce5bfae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-648a9f84-ae04-45cd-aebf-a1a6bce5bfae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_result.to_csv('submission.csv', index=False)\n",
        "files.download('submission.csv')"
      ],
      "metadata": {
        "id": "0MfNRB6_uoZ4",
        "outputId": "18be6b74-a3af-4154-fdaa-83243a04690b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b31b66d4-d2a7-496c-b471-3cc17d1b5c33\", \"submission.csv\", 34446)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}